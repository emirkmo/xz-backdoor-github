"file_time","event_type","actor_login","repo_name","created_at","updated_at","action","comment_id","body","path","position","line","ref","ref_type","creator_user_login","number","title","labels","state","locked","assignee","assignees","comments","author_association","closed_at","merged_at","merge_commit_sha","requested_reviewers","requested_teams","head_ref","head_sha","base_ref","base_sha","merged","mergeable","rebaseable","mergeable_state","merged_by","review_comments","maintainer_can_modify","commits","additions","deletions","changed_files","diff_hunk","original_position","commit_id","original_commit_id","push_size","push_distinct_size","member_login","release_tag_name","release_name","review_state"
"DateTime","Enum8('CommitCommentEvent' = 1, 'CreateEvent' = 2, 'DeleteEvent' = 3, 'ForkEvent' = 4, 'GollumEvent' = 5, 'IssueCommentEvent' = 6, 'IssuesEvent' = 7, 'MemberEvent' = 8, 'PublicEvent' = 9, 'PullRequestEvent' = 10, 'PullRequestReviewCommentEvent' = 11, 'PushEvent' = 12, 'ReleaseEvent' = 13, 'SponsorshipEvent' = 14, 'WatchEvent' = 15, 'GistEvent' = 16, 'FollowEvent' = 17, 'DownloadEvent' = 18, 'PullRequestReviewEvent' = 19, 'ForkApplyEvent' = 20, 'Event' = 21, 'TeamAddEvent' = 22)","LowCardinality(String)","LowCardinality(String)","DateTime","DateTime","Enum8('none' = 0, 'created' = 1, 'added' = 2, 'edited' = 3, 'deleted' = 4, 'opened' = 5, 'closed' = 6, 'reopened' = 7, 'assigned' = 8, 'unassigned' = 9, 'labeled' = 10, 'unlabeled' = 11, 'review_requested' = 12, 'review_request_removed' = 13, 'synchronize' = 14, 'started' = 15, 'published' = 16, 'update' = 17, 'create' = 18, 'fork' = 19, 'merged' = 20)","UInt64","String","String","Int32","Int32","LowCardinality(String)","Enum8('none' = 0, 'branch' = 1, 'tag' = 2, 'repository' = 3, 'unknown' = 4)","LowCardinality(String)","UInt32","String","Array(LowCardinality(String))","Enum8('none' = 0, 'open' = 1, 'closed' = 2)","UInt8","LowCardinality(String)","Array(LowCardinality(String))","UInt32","Enum8('NONE' = 0, 'CONTRIBUTOR' = 1, 'OWNER' = 2, 'COLLABORATOR' = 3, 'MEMBER' = 4, 'MANNEQUIN' = 5)","DateTime","DateTime","String","Array(LowCardinality(String))","Array(LowCardinality(String))","LowCardinality(String)","String","LowCardinality(String)","String","UInt8","UInt8","UInt8","Enum8('unknown' = 0, 'dirty' = 1, 'clean' = 2, 'unstable' = 3, 'draft' = 4, 'blocked' = 5)","LowCardinality(String)","UInt32","UInt8","UInt32","UInt32","UInt32","UInt32","String","UInt32","String","String","UInt32","UInt32","LowCardinality(String)","String","String","Enum8('none' = 0, 'approved' = 1, 'changes_requested' = 2, 'commented' = 3, 'dismissed' = 4, 'pending' = 5)"
"2024-03-26 17:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-26 17:33:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/bytearrayview","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,8,"","","","none"
"2024-03-26 17:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-26 17:45:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/bytearrayview","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-25 18:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-25 18:20:38","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/bytearrayview","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-25 18:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-25 18:32:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/bytearrayview","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-25 16:00:00","PushEvent","Larhzu","Larhzu/squashfs-tools","2024-03-25 16:07:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_riscv","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-25 15:00:00","CreateEvent","Larhzu","Larhzu/squashfs-tools","2024-03-25 15:53:32","1970-01-01 00:00:00","none",0,"","",0,0,"xz_riscv","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-25 15:00:00","ForkEvent","Larhzu","plougher/squashfs-tools","2024-03-25 15:52:40","1970-01-01 00:00:00","none",0,"","",0,0,"","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-22 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-22 15:47:42","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-22 13:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-22 13:47:34","1970-01-01 00:00:00","none",0,"","",0,0,"bytearrayview","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-22 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz-java","2024-03-22 13:48:10","1970-01-01 00:00:00","none",0,"","",0,0,"array_compare","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-22 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz-java","2024-03-22 13:48:10","1970-01-01 00:00:00","none",0,"","",0,0,"crc64_varhandle2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-22 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz-java","2024-03-22 13:48:10","1970-01-01 00:00:00","none",0,"","",0,0,"crc64_varhandle","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-22 13:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-22 13:48:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/bytearrayview","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,9,"","","","none"
"2024-03-20 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 19:40:10","2024-03-20 19:40:08","created",2010477152,"It's in the master branch now under the 0BSD license. It was [submitted to Linux](https://lore.kernel.org/lkml/20240320183846.19475-1-lasse.collin@tukaani.org/T/#m6420529145b5f53f4e56060b7d9fa4f353717257) too.

Note the changes to xz_wrap.sh in the master branch or in the linked Linux patchset. Those alignment tweaks are an easy way to get a small extra improvement in compression.","",0,0,"","none","Larhzu",1,"[Feature Request]: RISC-V BCJ filter","[]","closed",0,"","[]",3,"NONE","2024-03-20 19:40:08","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-20 19:00:00","IssuesEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 19:40:09","2024-03-20 19:40:08","closed",0,"### Describe the Feature

Thank you for your outstanding work on the project and for completing the RISC-V filter recently! 
However, the RISC-V filter is missing in this repo, xz-embedded.
It would be great to integrate the filter. Is there any plan to do so? I am willing to help.

### Expected Complications

_No response_

### Will I try to implement this new feature?

No","",0,0,"","none","ivq",1,"[Feature Request]: RISC-V BCJ filter","[]","closed",0,"","[]",3,"NONE","2024-03-20 19:40:08","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-20 19:00:00","PullRequestEvent","Larhzu","tukaani-project/xz","2024-03-20 19:04:09","2024-03-20 19:04:08","closed",0,"NVHPC compiler has several issues that make it impossible to build liblzma:
  - the compiler cannot handle unions that contain pointers that are not the first members (in some cases);
  - the compiler cannot handle the assembler code in range_decoder.h (LZMA_RANGE_DECODER_CONFIG has to be set to zero);
  - the compiler fails to produce valid code for delta_decode if the vectorization is enabled, which results in failed tests.

This introduces NVHPC-specific workarounds that address the issues.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [x] All previous and new tests pass


## Pull request type

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [x] Other (please describe): workarounds for the compiler


## What is the current behavior?
It's not possible to build and get the tests pass with any existing release of the NVHPC compiler even when configuring as follows:
```console
$ ./configure --disable-symbol-versions CPPFLAGS='-DLZMA_RANGE_DECODER_CONFIG=0' CFLAGS='-O'
```
(`-O` is the same as the default `-O2` but without SIMD)


## What is the new behavior?
It is possible to build and get the tests pass with any existing release of the NVHPC compiler when configuring as follows:
```console
$ ./configure --disable-symbol-versions
```

## Does this introduce a breaking change?

- [ ] Yes
- [x] No


## Other information

I don't know if there is any interest in supporting NVHPC and I'd understand if there's none.","",0,0,"","none","skosukhin",91,"liblzma: Fix building with NVHPC (NVIDIA HPC SDK).","[]","closed",0,"","[]",5,"CONTRIBUTOR","2024-03-20 19:04:08","1970-01-01 00:00:00","","[]","[]","nvhpc-workarounds","44fe303a5395315819dc1e6ba782b7aa6cf75583","master","a4f2e20d8466369b1bb277c66f75c9e4ba9cc378",0,0,0,"dirty","",0,0,1,8,2,3,"",0,"","",0,0,"","","","none"
"2024-03-20 19:00:00","PullRequestEvent","Larhzu","tukaani-project/xz","2024-03-20 19:04:54","2024-03-20 19:04:53","closed",0,"There are cases when the users want to decide themselves whether they want to have the generic (even on GNU/Linux) or the linux (even if we do not recommend that) symbol versioning variant. The former might be needed to circumvent compiler issues (i.e. the compiler does not support all features that are required for the linux versioning), the latter might help in overriding the assumptions made in the configure script.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [x] Build was run locally and without warnings or errors
- [x] All previous and new tests pass


## Pull request type

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [x] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
It's not possible to override the symbol versioning variant on GNU/Linux:
```console
$ ./configure --enable-symbol-versions=auto | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=yes | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=no | grep 'library symbol versioning'
checking if library symbol versioning should be used... no
$ ./configure --enable-symbol-versions=linux | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=generic | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=something-else | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions --disable-shared | grep 'library symbol versioning'
checking if library symbol versioning should be used... no (not building a shared library)
$ ./configure --with-pic | grep 'library symbol versioning'
checking if library symbol versioning should be used... 
configure: error: 
    On GNU/Linux, building both shared and static library at the same time
    is not supported if --with-pic or --without-pic is used.
    Use either --disable-shared or --disable-static to build one type
    of library at a time. If both types are needed, build one at a time,
    possibly picking only src/liblzma/.libs/liblzma.a from the static build.
```

## What is the new behavior?
It is possible to override the symbol versioning variant:
```console
$ ./configure --enable-symbol-versions=auto | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=yes | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=no | grep 'library symbol versioning'
checking if library symbol versioning should be used... no
$ ./configure --enable-symbol-versions=linux | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (linux)
$ ./configure --enable-symbol-versions=generic | grep 'library symbol versioning'
checking if library symbol versioning should be used... yes (generic)
$ ./configure --enable-symbol-versions=something-else | grep 'library symbol versioning'
checking if library symbol versioning should be used... 
configure: error: unknown symbol versioning variant 'something-else'
$ ./configure --enable-symbol-versions --disable-shared | grep 'library symbol versioning'
checking if library symbol versioning should be used... no (not building a shared library)
$ ./configure --with-pic | grep 'library symbol versioning'
checking if library symbol versioning should be used... 
configure: error: 
    On GNU/Linux, building both shared and static library at the same time
    is not supported if --with-pic or --without-pic is used.
    Use either --disable-shared or --disable-static to build one type
    of library at a time. If both types are needed, build one at a time,
    possibly picking only src/liblzma/.libs/liblzma.a from the static build.
```

## Does this introduce a breaking change?

- [ ] Yes
- [x] No

## Other information

It looks like `--enable-symbol-versions=generic` was an unintended feature that existed before 0682439.","",0,0,"","none","skosukhin",90,"Build: Let the users override the symbol versioning variant.","[]","closed",0,"","[]",3,"CONTRIBUTOR","2024-03-20 19:04:53","1970-01-01 00:00:00","","[]","[]","config-symbol-versioning","91fbb69ecaa994a0c6eacc03d154e094c1f5b413","master","a4f2e20d8466369b1bb277c66f75c9e4ba9cc378",0,0,0,"dirty","",0,0,1,50,41,1,"",0,"","",0,0,"","","","none"
"2024-03-20 18:00:00","DeleteEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 18:25:35","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-20 18:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 18:25:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",20,20,"","","","none"
"2024-03-20 17:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 17:02:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2024-03-20 09:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-20 09:16:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-19 19:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-19 19:48:15","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-18 18:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 18:41:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",18,18,"","","","none"
"2024-03-18 17:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 17:06:33","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-18 15:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 15:37:48","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-18 11:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 11:12:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,8,"","","","none"
"2024-03-18 11:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 11:06:34","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-18 10:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 10:30:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-03-18 10:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-18 10:20:40","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",20,20,"","","","none"
"2024-03-17 19:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-17 19:02:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-17 16:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-17 16:16:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",19,19,"","","","none"
"2024-03-16 18:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-16 18:43:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",17,17,"","","","none"
"2024-03-15 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-03-15 16:08:17","2024-03-15 16:08:15","created",1999984957,"The code selected with 0x100 is the simplest assembly piece and it has
fewer input and output variables too. So it could be something about
the number of variables or the length of the assembly code but this is
just a guess.

Keeping the code disabled with NVIDIA HPC seems the simplest solution
for now. I like to make the code portable as in ""works reliably"" but
getting the best speed has some bias towards FOSS toolchains and
operating systems.

The PRs #90 and #91 are now merged to master along with related commits
that should make the symbol version autodetection work too.

Thank you for reporting the issues and for the patches!
","",0,0,"","none","Larhzu",91,"liblzma: Fix building with NVHPC (NVIDIA HPC SDK).","[]","open",0,"","[]",5,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-15 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-15 16:06:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,5,"","","","none"
"2024-03-15 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-15 15:16:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-15 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-15 15:31:36","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,8,"","","","none"
"2024-03-15 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-15 15:47:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-15 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-15 14:36:58","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-15 13:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-15 13:07:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-15 13:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-15 13:16:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-15 12:00:00","CreateEvent","Larhzu","tukaani-project/xz-embedded","2024-03-15 12:34:48","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-15 12:00:00","PushEvent","Larhzu","tukaani-project/xz-embedded","2024-03-15 12:37:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",16,16,"","","","none"
"2024-03-14 13:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-14 13:28:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/array_compare","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-13 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-03-13 20:45:46","2024-03-13 20:45:45","created",1995747754,"Thanks! I've collected this into pr90_pr91 branch with matching CMake
fixes.

> It looks like `--enable-symbol-versions=generic` was an unintended
> feature that existed before 0682439.

Quite possibly so. I agree it should be configurable.

> `__has_attribute(__symver__)` for the Nvidia compiler is `0` and it
> chokes with `__asm__("".symver ..."")`:

It is clear that the compiler doesn't support symbol versioning in any
form. The linker still does, thus thus the ""generic"" versioning works.

> -	__asm__("".symver "" #intname "","" extnamever);
> +	__asm__("".symver "" #intname "","" extnamever "";"");

As you noticed, the additional symbols didn't appear. The correct way
is to use the ""generic"" versioning which doesn't even attempt to add
those extra symbol versions. This is assuming that the toolchain truly
is targeting glibc (configure thinks it is).

> This could be checked by the configure script, I guess (one should be
> careful with using something non-portable like `readelf` in a
> configure script though).

configure and CMakeLists.txt could check for __NVCOMPILER. I suppose
that would be reasonable. I plan to add that in the near future, unless
the problem is that the build isn't actually targeting glibc and
configure is misdetecting that.

Not very many users should be affected by changing from ""linux"" to
""generic"". The ""linux"" one only helps with binary compatibility with
some executables which hopefully aren't too common.

> Another question, when someone specifies `./configure
> --enable-symbol-versions=yes --disable-shared `

It's simplest to just ignore --enable-symbol-versions in this case.
Symbol versions make no sense in static libraries but they can cause
breakage in some cases. If we rejected the option with static-only
builds it could complicate build scripts that use mostly the same
options for building shared and static liblzma in separate runs.
","",0,0,"","none","Larhzu",90,"Build: Let the users override the symbol versioning variant.","[]","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-13 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-13 20:18:17","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2024-03-13 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-13 20:14:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2024-03-13 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-13 20:00:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/pr90_pr91","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2024-03-13 19:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-03-13 19:52:25","1970-01-01 00:00:00","none",0,"","",0,0,"pr90_pr91","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-13 11:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz-java","2024-03-13 11:16:23","2024-03-13 11:16:22","created",1994143076,"> Actually, I use `try with catch`, so `xzOut.close()` is unnecessary.

True, I didn't notice it, sorry. I haven't regularly used much beyond
Java 5 features yet and I had a break from Java for three years. :-/

If I compress and decompress your two example JSON files, everything
works correctly. Based on your code, I created a complete program that
compresses to jdks.json.xz and the output is fine with both of your
sample inputs. Thus, I cannot reproduce the problem with the
information I currently have.

Note that the error message

    Error 79 - Inappropriate file type or format.

is not from XZ for Java.

import java.io.*;
import java.nio.file.*;
import org.tukaani.xz.*;

class XZEncDemo {
    public void testXzCompress() throws IOException {
        String json = new String(Files.readAllBytes(
                Paths.get(""jdks.json"")));
        compress(json);
    }

    public void compress(String input) {
        try (FileOutputStream fos = new FileOutputStream(""jdks.json.xz"");
                XZOutputStream xzOut = new XZOutputStream(fos, new LZMA2Options())) {
            byte[] jsonData = input.getBytes();
            xzOut.write(jsonData);
        } catch (Throwable throwable) {
            throw new RuntimeException(throwable);
        }
    }

    public static void main(String[] args) throws Exception {
        new XZEncDemo().testXzCompress();
    }
}
","",0,0,"","none","Larhzu",6,"[Bug]: A strange format error in the generated xz file due to spaces","['bug']","open",0,"","[]",4,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-12 16:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-12 16:06:49","1970-01-01 00:00:00","none",0,"","",0,0,"lzma_eopm","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-11 21:00:00","CommitCommentEvent","Larhzu","tukaani-project/xz-java","2024-03-11 21:03:06","2024-03-11 21:03:06","none",139649531,"New commits were added. crc64_varhandle2 has them squashed. Further
work continues on that branch.

The idea seems good to me. Performance isn't affected by these changes.

Thanks!
","",0,0,"","none","Larhzu",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"8c788e66001fc5bc8434c33bbee21c45a6d580c5","",0,0,"","","","none"
"2024-03-11 21:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 21:10:47","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,0,"","","","none"
"2024-03-11 21:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 21:18:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/array_compare","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,5,"","","","none"
"2024-03-11 21:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 21:22:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/array_compare","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-11 20:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-11 20:56:24","1970-01-01 00:00:00","none",0,"","",0,0,"crc64_varhandle2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-11 20:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 20:49:08","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc64_varhandle","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2024-03-11 20:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 20:55:34","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc64_varhandle","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-11 19:00:00","CommitCommentEvent","Larhzu","tukaani-project/xz-java","2024-03-11 19:00:12","2024-03-11 19:00:12","none",139643389,"True. The finish() method isn't performance critical at all so in that
sense it doesn't matter. However, an ArrayUtil class with VarHandles for
different integer sizes and endiannesses could be convenient in general
and perhaps help readability slightly too. I started but haven't
finished yet.

Thanks!
","",0,0,"","none","Larhzu",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"8c788e66001fc5bc8434c33bbee21c45a6d580c5","",0,0,"","","","none"
"2024-03-11 14:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-11 14:29:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc64_varhandle","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-11 12:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-11 12:54:54","1970-01-01 00:00:00","none",0,"","",0,0,"crc64_varhandle","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-09 21:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-09 21:43:10","1970-01-01 00:00:00","none",0,"","",0,0,"array_compare","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-09 09:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-03-09 09:05:20","2024-03-09 09:05:19","created",1986801028,"Would Visual Studio + Clang-cl be worth trying too? The inline x86-64
assembly code in 5.6.x is compatible with GCC and Clang, so I hope that
compiling with Clang-cl would result in better decompression speed than
compiling with MSVC. (LZMA SDK has MSVC compatible assembly but then
one needs to use LZMA SDK's C code and APIs too.)
","",0,0,"","none","Larhzu",18,"[Feature Request]: Create Windows CI Support","[]","open",0,"","[]",12,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-07 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz-java","2024-03-07 17:36:00","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-07 17:00:00","PullRequestEvent","Larhzu","tukaani-project/xz-java","2024-03-07 17:36:07","2024-03-07 17:36:06","closed",0,"","",0,0,"","none","simon04",4,"MANIFEST: add Bundle-License","[]","closed",0,"","[]",0,"NONE","2024-03-07 17:36:06","1970-01-01 00:00:00","","[]","[]","manifest-license","50e41cdf88f9301e18beef470a69078d7d061619","master","bc4b79d7532fd67136197c65f5ad00a24cb72834",0,0,0,"unknown","",0,0,1,1,0,1,"",0,"","",0,0,"","","","none"
"2024-03-07 17:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2024-03-07 17:36:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",17,17,"","","","none"
"2024-03-06 15:00:00","CreateEvent","Larhzu","tukaani-project/xz-java","2024-03-06 15:18:05","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-05 21:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz-embedded","2024-03-05 21:08:21","2024-03-05 21:08:20","created",1979638035,"I got a preliminary version done locally. It may take a few days until it's in the Git repository but it shouldn't take too many days. It likely won't be in Linux 6.9 but hopefully 6.10 is doable. We'll see.","",0,0,"","none","Larhzu",1,"[Feature Request]: RISC-V BCJ filter","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-05 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-05 21:23:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-03-05 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz-java","2024-03-05 19:17:11","2024-03-05 19:17:10","created",1979470307,"I've been preparing a few unrelated changes and including this Delta filter improvement among those. I hope the changes get to master tomorrow. (This is a special case and not the normal way in the project. Sorry.)

I benchmarked the Delta filter changes. Encoding time was reduced by 60-70 % when distance=1 and over 50 % with long distances. That makes sense as with longer distances more bytes go via the history buffer.

Decoding time reduced up to 50 % with long distances but only 5 % with distance=1. It's still a clear improvement. I suppose short distance is slower because `buf[off + i] += buf[off + i - distance];` has dependency on the previous iteration; it cannot parallelize like with longer distances.

I wonder if JVM is smart enough to vectorize the decoder loops when distance is large enough and appropriate multiple of a power of two. For example, distance=240 is a little faster than 248.

In any case, thanks for the improvement and sorry that it has taken three years to get it included.","",0,0,"","none","Larhzu",11,"delta coding performance","[]","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-05 11:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz-java","2024-03-05 11:53:39","2024-03-05 11:53:37","created",1978589726,"Sorry for the delayed reply. Turns out I didn't have email notifications enabled for the xz-java project.

The problem is that your code lacks `xzOut.close()`.

If you didn't want to close `fos` then `xzOut.finish()` would be the right call. But in this example you want to close `fos` too and `xzOut.close()` does that.","",0,0,"","none","Larhzu",6,"[Bug]: A strange format error in the generated xz file due to spaces","['bug']","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-04 17:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-03-04 17:24:14","1970-01-01 00:00:00","none",0,"","",0,0,"riscv_comment_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-04 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-03-04 17:53:45","1970-01-01 00:00:00","none",0,"","",0,0,"riscv_comment_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-03-04 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-03-04 17:53:36","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-02-29 14:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-29 14:47:48","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_nls_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-29 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-29 14:47:30","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,0,"","","","none"
"2024-02-29 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-29 14:38:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_nls_fix","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,2,"","","","none"
"2024-02-28 18:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-28 18:03:11","1970-01-01 00:00:00","none",0,"","",0,0,"memavail","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-28 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 18:12:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/memavail","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-28 16:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-28 16:34:30","1970-01-01 00:00:00","none",0,"","",0,0,"xz_memlimit_warnings","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-28 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 16:36:02","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.6","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,9,"","","","none"
"2024-02-28 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 16:34:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-02-28 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 16:27:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_memlimit_warnings","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-28 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 15:52:27","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_nls_fix","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-28 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-28 15:33:02","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_nls_fix","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-28 11:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-28 11:37:11","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_nls_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-28 10:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-02-28 10:59:53","2024-02-28 10:59:52","created",1968736930,"> Is there anything wrong with it or how much ram I'm supposing to
> give to the process?

I realized only now what made you ask this question. :-( At the default
verbosity level, the message only tells what the limit is but not how
much is needed. One needs -vv to see what would actually be required
but there is no hint about the need for -vv.

> As a user I would not like to see that by default, but in verbose
> mode or debug mode. But it is a matter of fact that putting that in
> verbose/debug mode means that a lot of users won't discover that, and
> then not increase the memory limit if they need it.
> 
> So for me is fine as-is.

You summarized the problem well. The on-going thread on xz-devel might
be worth reading too about the identified pros and cons of different
options, including the problems with the current behavior:

***@***.***/msg00655.html

Threaded compression has been supported in for nine years but only now
is the threaded mode enabled by default. Thus more people are seeing
these messages now.

Historically, memory usage limits in xz have been a controversial
topic. Threaded compression with automatic number of threads and
threaded decompression with automatic or user-defined number of threads
require a memory limit, otherwise the memory usage could become
ridiculous in some cases. That could cause security issues (denial of
service).

The current automatic limit is 25 % of total RAM (in 32-bit xz
executables also at most 1400 MiB). Some people think it's a bit too
low, some think it's a bit too high.

There is also a Linux-specific suggestion of using MemAvailable from
/proc/meminfo to determine how much memory could be used. For example,
using 80 % of MemAvailable. That could often allow more than 25 % of
RAM. This idea wasn't discussed and polished for XZ Utils 5.6.0 though
but it likely should be revisited later. And if done on Linux, a
similar thing likely should be done on a few other OSes too.

> I opened the issue because in my opinion the required memory is
> too high. 

While I don't know about your use case, in general it can be worth
considering if -9 is the best compression preset to use. -9 uses 64 MiB
dictionary and 192 MiB block size. Perhaps --block-size=96MiB would
give good enough compression while allowing more threads and thus more
speed if the file size isn't huge (gigabytes).

Or using the default -6 (8 MiB dict, 24 MiB blocks) or a bit higher -7
(16 MiB dict, 48 MiB blocks) to get better parallelization with
medium-sized files at the expense of worse compression.

The default block_size = 3 * dict_size is somewhat arbitrary. It's a
compromise between compression ratio and memory usage. If memory usage
doesn't matter, block_size = dict_size is the best. Multiplier in the
range 1-4 is likely a good choice in typical cases.

xz --help includes a warning about memory usage with presets 7-9. When
it was written, computers with 256-512 MiB RAM weren't obsolete. With
threading that warning has some point again.

Note that -9 and its 64 MiB dictionary isn't the maximum possible
compression setting. It's just the highest preset level. The encoder
supports up to 1536 MiB. Some use 256 MiB together with a fast preset
because *with some types of data* it can be both faster than -9 and
compress the same (or even better):

    xz --lzma2=preset=1,dict=256MiB

So it's about understanding the use case and doing some experimenting.

> I'd suggest to put a link or an explanation about why the provided
> memory limit is not enough. That would avoid a lot of tickets here, I
> think.

I recognize that there is a problem and it could be documented
somewhere and perhaps the message from xz should be clearer too. If the
thread count reduction was shown at only -vv then it likely would be
clearer already except that fewer people would be aware of the reduced
thread count. Right now I don't know what is the best solution. It
might be that in the short term the message is put behind -v or -vv to
solve one set of problems and the solution is tweaked later.

Thanks!
","",0,0,"","none","Larhzu",89,"[Bug]: xz: Reduced the number of threads from ... to not exceed the memory usage limit of ... MiB","['bug']","closed",0,"","[]",5,"NONE","2024-02-28 08:21:38","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-27 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-02-27 17:13:45","2024-02-27 17:13:44","created",1967203067,"> As a side note, with -M 30000000000 (30GB) I can run until 22 threads
> without issues.
> 
> With -M 90000000000 (90GB) I can run it with 64 threads without
> issues.

Try adding `-vv` to the command line. It will show some information
about memory usage.

With `-9` the _compressor_ in threaded mode needs 1250 MiB per thread. A
new thread is started every 192 MiB of uncompressed input (3 * 64 MiB
where 64 MiB is the dictionary size at `-9`). So if the input file isn't
huge, not many threads will be actually used.

With lower presets memory usage goes down and threads are started more
frequently. For example, `-6` starts a new thread every 24 MiB of input
by default.
","",0,0,"","none","Larhzu",89,"[Bug]: xz: Reduced the number of threads from ... to not exceed the memory usage limit of ... MiB","['bug']","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-26 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-26 21:07:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-22 20:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2024-02-22 20:05:57","2024-02-22 20:05:56","closed",0,"# Short version

Public domain has (real or perceived) legal issues in some jurisdictions. To avoid those issues, a widely-accepted public-domain-equivalent license that requires no attribution is considered for future versions. Feedback is wanted to know if this idea is good.


# Why the XZ projects are in the public domain

[LZMA SDK](https://7-zip.org/sdk.html) used to be available under the GNU LGPL and a few other license choices.
In late 2008, LZMA SDK became public domain (PD). Since XZ Utils, XZ Embedded, and XZ for Java are derived from the LZMA SDK code, I felt that it made no sense to have more restrictions on the XZ projects code than what LZMA SDK had. Thus the XZ projects have been PD as well.

For example, the [MIT License](https://spdx.org/licenses/MIT.html), [BSD 2-Clause ""Simplified"" License](https://spdx.org/licenses/BSD-2-Clause.html), or [ISC License](https://spdx.org/licenses/ISC.html) would have been more restrictive than PD as those require keeping the copyright notice and license notice when distributing copies. Pure PD has no such requirements.

I knew even in 2008 that PD might be legally complicated in some jurisdictions but I didn't see ideal alternatives (a common advice was to not create a new license). In practice it seemed that PD projects were accepted in major distros with strict policies (like Debian and Fedora). A few discussions around the problems of PD have occurred over the years though and in general it's waste of everyone's time.


# Public-domain-equivalent licenses

In 2008 there were no _widely-recognized_ and _widely-accepted_ [public-domain-equivalent licenses](https://en.wikipedia.org/wiki/Public-domain-equivalent_license). Nowadays there are at least [BSD Zero Clause License](https://spdx.org/licenses/0BSD.html) (0BSD) and [MIT No Attribution license](https://spdx.org/licenses/MIT-0.html) (MIT-0) which look good.

A few other PD-equivalent licenses exist too. For example:

* [WTFPL](https://spdx.org/licenses/WTFPL.html) uses unprofessional language (and lacks a warranty disclaimer in case it matters).

* [CC0](https://creativecommons.org/publicdomain/zero/1.0/) is also a PD dedication with a fallback license. It explicitly lacks patent license which has made [Fedora consider it unacceptable for free software in 2022](https://www.mail-archive.com/legal@lists.fedoraproject.org/msg02944.html) (still fine for files other than code).

* [The Unlicense](https://unlicense.org/) is a PD dedication with a fallback license. Compared to 0BSD and MIT-0, a PD dedication doesn't seem to add much practical value but it can fuel discussions about how the PD-dedication, fallback license, and warranty disclaimer interact with each other and so on.

Both 0BSD and MIT-0 are simple modifications to existing license texts and thus more than one person might have created the same variants independently over the years. The difficult thing is making the license texts widely accepted. 0BSD came from [toybox](https://www.landley.net/toybox/) which is [included in Android](https://www.landley.net/toybox/faq.html#opensource). MIT-0 got visibility because [Amazon uses it for example code](https://github.com/aws/mit-0). 0BSD is slightly shorter than MIT-0 while both should have the same legal effect. 0BSD got wide recognition a little earlier:

* 0BSD in [SDPX license list v2.2 on 2015-09-30](https://spdx.org/licenses/archive/archived_ll_v2.2/index.html) and [OSI approval on 2015-10-14](https://opensource.org/license/0bsd/)

* MIT-0 in [SDPX license list v3.1 in 2018](https://spdx.org/licenses/archive/archived_ll_v3.1/index.html) and [OSI approval in 2020](https://opensource.org/license/mit-0/)

GitHub has over four times [0BSD-licensed repositories](https://github.com/search?q=license%3A0bsd&type=repositories) than [MIT-0-licensed repositories](https://github.com/search?q=license%3Amit-0&type=repositories).

[Google doesn't allow contributions to PD projects](https://opensource.google/documentation/reference/patching#forbidden) or certain PD-equivalent projects: WTFPL, CC0, and The Unlicense are explicitly mentioned as _prohibited_. However, 0BSD is explicitly listed as _allowed_. (It's spelled as BSD0 on that page but it links to 0BSD.) MIT-0 isn't mentioned at all.

So clearly the legal department in one large company is happy with 0BSD. And since Android contains 0BSD-licensed code, a few other companies must be OK with 0BSD too. Even [Microsoft has released code under 0BSD](https://github.com/microsoft/tslib).

With the above considerations, my impression is that 0BSD is currently be the best of the well-known public-domain-equivalent licenses for software although the difference to MIT-0 is minuscule. The reasons to prefer 0BSD are that it's more popular, clearly accepted by legal departments of more than one large company, and that it's slightly shorter while being equivalent in legal meaning.


# The Plan

The change would affect future versions only. The public domain code in the old releases would obviously remain in the public domain.

For simplicity, all currently-PD code would be marked as 0BSD (with per-file SPDX license identifiers). If one wishes to know which parts are available as PD, one can look at the old releases or Git commit history. Those aren't going away.

We have already asked a few authors that they indeed are OK that their code would be under 0BSD. It feels a bit silly to ask since PD allows this already, but this way only a fairly small amount of code will rely solely on PD dedications. In any case, some code would remain that is from PD-only source.

Switching to 0BSD should affect users and distributors very little. PD code can be distributed without any notices about where the code came from. The same can be done with 0BSD.

(There is one tiny difference still: With 0BSD-licensed code, one shouldn't claim that it is in the public domain. Code under 0BSD is copyrighted, thus it's not literally in the public domain. Example: It is fine to take PD code and re-release it under The Unlicense. But one cannot re-release someone else's 0BSD-licensed code under The Unlicense because The Unlicense has a PD dedication and one cannot dedicate code into PD if one isn't its copyright holder. 0BSD to MIT-0 should be fine because there is no PD dedication in MIT-0.)


# Questions

1. Would using 0BSD instead of PD make legal considerations easier for distributors and contributors, even if some code still relies on PD dedications?

2. Should the XZ projects switch from PD to 0BSD for future releases?

When answering, if you represent an organization, please mention it. Otherwise the answer is assumed be an opinion of a private person.

Thank you!","",0,0,"","none","Larhzu",79,"Switch from public domain to BSD Zero Clause License?","[]","closed",0,"","[]",1,"MEMBER","2024-02-22 20:05:56","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-22 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-22 17:22:55","1970-01-01 00:00:00","none",0,"","",0,0,"windres_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-22 17:22:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-02-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-22 17:17:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/windres_fix","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-22 13:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-22 13:25:56","1970-01-01 00:00:00","none",0,"","",0,0,"landlock_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-22 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-22 13:39:29","1970-01-01 00:00:00","none",0,"","",0,0,"landlock_fix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-22 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-22 13:39:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-02-22 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-22 13:38:30","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/NEWS_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-22 12:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-22 12:46:19","1970-01-01 00:00:00","none",0,"","",0,0,"rc_config","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-22 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-22 12:45:55","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-21 19:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-21 19:53:17","1970-01-01 00:00:00","none",0,"","",0,0,"rc_config","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-21 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-21 16:08:34","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/NEWS_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-21 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-21 16:05:11","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/NEWS_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-21 14:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-21 14:58:43","1970-01-01 00:00:00","none",0,"","",0,0,"w32_update","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-20 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-20 19:04:40","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",14,6,"","","","none"
"2024-02-19 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-02-19 20:01:53","2024-02-19 20:01:52","created",1953092508,"On 2024-02-18 vector-is wrote:
> I'm looking for binaries for Windows.

The thought of starting to provide official binaries again has been
considered for a while. The package build script etc. have been updated
recently and hopefully get merged to master this week. There are some
non-technical considerations to decide but there is a possibility (so
it's still very uncertain) that XZ Utils 5.6.0 might get a Windows
binary package as well.

-- 
Lasse Collin
","",0,0,"","none","Larhzu",81,"Where can I download Latest compiled binaries ?","[]","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-19 19:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-19 19:40:16","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_updates","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-19 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 17:50:53","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2024-02-19 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 17:43:33","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 17:32:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,8,"","","","none"
"2024-02-19 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 16:53:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 15:56:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 15:40:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",21,5,"","","","none"
"2024-02-19 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 14:30:53","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,1,"","","","none"
"2024-02-19 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 14:48:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 12:22:37","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 11:38:54","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 11:38:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-19 10:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 10:25:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",15,14,"","","","none"
"2024-02-19 10:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 10:01:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,4,"","","","none"
"2024-02-19 10:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-19 10:01:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-18 21:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-18 21:14:43","1970-01-01 00:00:00","none",0,"","",0,0,"sandbox3","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-18 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-18 21:59:17","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-02-18 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-18 16:13:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",22,4,"","","","none"
"2024-02-18 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-02-18 14:15:49","2024-02-18 14:15:47","created",1951338942,"Examples: GNU/Linux distributions like Arch Linux, Debian, Fedora,
Gentoo, Slackware, and Ubuntu include XZ Utils. FreeBSD includes
XZ Utils in the base system. OpenBSD provides a prebuilt package.

https://archlinux.org/

https://www.debian.org/

https://fedoraproject.org/

https://www.gentoo.org/

http://www.slackware.com/

https://ubuntu.com/

https://www.freebsd.org/

https://www.openbsd.org/

I hope this helps.

If you were looking for binaries for non-free operating systems like
Windows, then I don't have a recommendations for up-to-date binaries.
The XZ Utils home page has binaries for 5.2.9. I'm hoping to include
updated simplified build instructions for Windows in XZ Utils 5.6.0, if
I have time.
","",0,0,"","none","Larhzu",81,"Where can I download Latest compiled binaries ?","[]","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-18 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-18 13:05:29","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2024-02-18 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-18 12:37:13","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-18 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-18 12:20:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2024-02-17 23:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 23:43:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",18,12,"","","","none"
"2024-02-17 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 21:09:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2024-02-17 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 20:27:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 20:15:15","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 19:46:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",15,11,"","","","none"
"2024-02-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 17:05:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,9,"","","","none"
"2024-02-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 17:10:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 17:14:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox3","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",15,7,"","","","none"
"2024-02-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 17:17:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 17:42:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-02-17 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 15:53:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,8,"","","","none"
"2024-02-17 14:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-17 14:03:20","1970-01-01 00:00:00","none",0,"","",0,0,"cstdfix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-17 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 14:04:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",15,8,"","","","none"
"2024-02-17 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 14:23:33","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 14:03:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-17 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 13:50:40","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-02-17 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-17 13:40:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,8,"","","","none"
"2024-02-16 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-16 21:27:52","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_updates","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2024-02-16 20:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-16 20:42:05","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_updates","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-16 19:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-16 19:38:51","1970-01-01 00:00:00","none",0,"","",0,0,"cstdfix","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-16 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-16 16:03:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox3","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-16 15:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-16 15:51:34","1970-01-01 00:00:00","none",0,"","",0,0,"sandbox3","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-16 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-16 15:57:32","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox3","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,6,"","","","none"
"2024-02-16 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-16 15:54:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-15 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-15 20:34:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-15 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-15 11:48:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",90,7,"","","","none"
"2024-02-14 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 19:15:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2024-02-14 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-02-14 18:46:19","2024-02-14 18:46:18","created",1944400549,"Thank you to everyone for the discussion and feedback! The core parts of the XZ Utils master branch are now under 0BSD as is the 5.5.2beta release. Assuming that people are fine with it in XZ Utils, similar change will be done later in XZ for Java and XZ Embedded.","",0,0,"","none","Larhzu",79,"Switch from public domain to BSD Zero Clause License?","[]","open",0,"","[]",1,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-14 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-02-14 17:56:27","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:22:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:38:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:28:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:46:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:12:17","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 17:06:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 16:45:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",38,0,"","","","none"
"2024-02-14 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 15:26:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",34,34,"","","","none"
"2024-02-14 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 15:07:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",34,34,"","","","none"
"2024-02-14 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 13:35:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",40,37,"","","","none"
"2024-02-14 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 13:20:13","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-14 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-14 12:58:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-13 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 21:23:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",33,33,"","","","none"
"2024-02-13 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 20:46:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",14,14,"","","","none"
"2024-02-13 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 15:02:36","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-13 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 14:41:31","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",29,29,"","","","none"
"2024-02-13 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 12:38:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-13 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 12:11:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-13 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 12:05:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-02-13 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-13 11:26:58","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",35,33,"","","","none"
"2024-02-12 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-12 21:30:54","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-02-12 15:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-02-12 15:11:42","1970-01-01 00:00:00","none",0,"","",0,0,"misc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-02-12 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-12 15:14:56","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/misc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",22,22,"","","","none"
"2024-02-09 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-02-09 21:26:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-02-08 16:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2024-02-08 16:03:28","2024-02-08 16:03:27","opened",0,"# Short version

Public domain has (real or perceived) legal issues in some jurisdictions. To avoid those issues, a widely-accepted public-domain-equivalent license that requires no attribution is considered for future versions. Feedback is wanted to know if this idea is good.


# Why the XZ projects are in the public domain

[LZMA SDK](https://7-zip.org/sdk.html) used to be available under the GNU LGPL and a few other license choices.
In late 2008, LZMA SDK became public domain (PD). Since XZ Utils, XZ Embedded, and XZ for Java are derived from the LZMA SDK code, I felt that it made no sense to have more restrictions on the XZ projects code than what LZMA SDK had. Thus the XZ projects have been PD as well.

For example, the [MIT License](https://spdx.org/licenses/MIT.html), [BSD 2-Clause ""Simplified"" License](https://spdx.org/licenses/BSD-2-Clause.html), or [ISC License](https://spdx.org/licenses/ISC.html) would have been more restrictive than PD as those require keeping the copyright notice and license notice when distributing copies. Pure PD has no such requirements.

I knew even in 2008 that PD might be legally complicated in some jurisdictions but I didn't see ideal alternatives (a common advice was to not create a new license). In practice it seemed that PD projects were accepted in major distros with strict policies (like Debian and Fedora). A few discussions around the problems of PD have occurred over the years though and in general it's waste of everyone's time.


# Public-domain-equivalent licenses

In 2008 there were no _widely-recognized_ and _widely-accepted_ [public-domain-equivalent licenses](https://en.wikipedia.org/wiki/Public-domain-equivalent_license). Nowadays there are at least [BSD Zero Clause License](https://spdx.org/licenses/0BSD.html) (0BSD) and [MIT No Attribution license](https://spdx.org/licenses/MIT-0.html) (MIT-0) which look good.

A few other PD-equivalent licenses exist too. For example:

* [WTFPL](https://spdx.org/licenses/WTFPL.html) uses unprofessional language (and lacks a warranty disclaimer in case it matters).

* [CC0](https://creativecommons.org/publicdomain/zero/1.0/) is also a PD dedication with a fallback license. It explicitly lacks patent license which has made [Fedora consider it unacceptable for free software in 2022](https://www.mail-archive.com/legal@lists.fedoraproject.org/msg02944.html) (still fine for files other than code).

* [The Unlicense](https://unlicense.org/) is a PD dedication with a fallback license. Compared to 0BSD and MIT-0, a PD dedication doesn't seem to add much practical value but it can fuel discussions about how the PD-dedication, fallback license, and warranty disclaimer interact with each other and so on.

Both 0BSD and MIT-0 are simple modifications to existing license texts and thus more than one person might have created the same variants independently over the years. The difficult thing is making the license texts widely accepted. 0BSD came from [toybox](https://www.landley.net/toybox/) which is [included in Android](https://www.landley.net/toybox/faq.html#opensource). MIT-0 got visibility because [Amazon uses it for example code](https://github.com/aws/mit-0). 0BSD is slightly shorter than MIT-0 while both should have the same legal effect. 0BSD got wide recognition a little earlier:

* 0BSD in [SDPX license list v2.2 on 2015-09-30](https://spdx.org/licenses/archive/archived_ll_v2.2/index.html) and [OSI approval on 2015-10-14](https://opensource.org/license/0bsd/)

* MIT-0 in [SDPX license list v3.1 in 2018](https://spdx.org/licenses/archive/archived_ll_v3.1/index.html) and [OSI approval in 2020](https://opensource.org/license/mit-0/)

GitHub has over four times [0BSD-licensed repositories](https://github.com/search?q=license%3A0bsd&type=repositories) than [MIT-0-licensed repositories](https://github.com/search?q=license%3Amit-0&type=repositories).

[Google doesn't allow contributions to PD projects](https://opensource.google/documentation/reference/patching#forbidden) or certain PD-equivalent projects: WTFPL, CC0, and The Unlicense are explicitly mentioned as _prohibited_. However, 0BSD is explicitly listed as _allowed_. (It's spelled as BSD0 on that page but it links to 0BSD.) MIT-0 isn't mentioned at all.

So clearly the legal department in one large company is happy with 0BSD. And since Android contains 0BSD-licensed code, a few other companies must be OK with 0BSD too. Even [Microsoft has released code under 0BSD](https://github.com/microsoft/tslib).

With the above considerations, my impression is that 0BSD is currently be the best of the well-known public-domain-equivalent licenses for software although the difference to MIT-0 is minuscule. The reasons to prefer 0BSD are that it's more popular, clearly accepted by legal departments of more than one large company, and that it's slightly shorter while being equivalent in legal meaning.


# The Plan

The change would affect future versions only. The public domain code in the old releases would obviously remain in the public domain.

For simplicity, all currently-PD code would be marked as 0BSD (with per-file SPDX license identifiers). If one wishes to know which parts are available as PD, one can look at the old releases or Git commit history. Those aren't going away.

We have already asked a few authors that they indeed are OK that their code would be under 0BSD. It feels a bit silly to ask since PD allows this already, but this way only a fairly small amount of code will rely solely on PD dedications. In any case, some code would remain that is from PD-only source.

Switching to 0BSD should affect users and distributors very little. PD code can be distributed without any notices about where the code came from. The same can be done with 0BSD.

(There is one tiny difference still: With 0BSD-licensed code, one shouldn't claim that it is in the public domain. Code under 0BSD is copyrighted, thus it's not literally in the public domain. Example: It is fine to take PD code and re-release it under The Unlicense. But one cannot re-release someone else's 0BSD-licensed code under The Unlicense because The Unlicense has a PD dedication and one cannot dedicate code into PD if one isn't its copyright holder. 0BSD to MIT-0 should be fine because there is no PD dedication in MIT-0.)


# Questions

1. Would using 0BSD instead of PD make legal considerations easier for distributors and contributors, even if some code still relies on PD dedications?

2. Should the XZ projects switch from PD to 0BSD for future releases?

When answering, if you represent an organization, please mention it. Otherwise the answer is assumed be an opinion of a private person.

Thank you!","",0,0,"","none","Larhzu",79,"Switch from public domain to BSD Zero Clause License?","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-31 19:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-31 19:58:27","2024-01-31 19:58:26","created",1919835900,"When one is otherwise happy with the default stylesheet, it's enough to unset the `webfonts` attribute. It is explained on the [next page](https://docs.asciidoctor.org/asciidoctor/latest/html-backend/default-stylesheet/#disable-or-modify-the-web-fonts) in the documentation. Maybe referring to that would be better in the warning than the docs about custom stylesheet. A _commented-out_ link to Google Fonts will still remain but it is only a comment. (Note that I'm only a happy Asciidoctor user, not its developer.)","",0,0,"","none","Larhzu",4540,"Warn users about the use of Google Fonts","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-31 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-31 19:25:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/arm64_crc32","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2024-01-30 19:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-30 19:52:46","2024-01-30 19:52:44","created",1917781079,"I like that the above ideas make the brackets part of the link. It makes the link a larger target to hit.

Both (A) and (C) are good. I agree with someth2say about the problem with (D). If I was forced to choose between (A) and (C), I might choose (A) because I feel having the number in normal font size is fine in the footnote list. But I'm equally happy with (C).

If the same footnote is referenced from more than one location, Wikipedia links to each location in the footnote list using letters (the caret isn't a link then). Having back-references to all locations is nice but I don't have a strong opinion if Asciidoctor should do a similar thing. I just want to mention this detail to ensure that the inclusion or omission of the feature is an intentional choice instead of ""oops no one thought about it"". :-)

The default theme on Wikipedia uses superscript in bold and italic:

> 1\. ^ [<sup>***a***</sup>](#) [<sup>***b***</sup>](#) [<sup>***c***</sup>](#) Footnote text.

Using letters might add some language-specific complexity. For example, Wikipedia uses an arrow instead of a caret and cyrillic letters in Ukrainian (I don't speak the language):

> 1\. ↑ [<sup>***а***</sup>](#) [<sup>***б***</sup>](#) [<sup>***в***</sup>](#) Footnote text.

Using numbers might avoid the language-specific style. Also omitting the caret or arrow gets close to the (A) style:

(E)
> 1\. [<sup>***1***</sup>](#) [<sup>***2***</sup>](#) [<sup>***3***</sup>](#) Footnote text with multiple references.
> [2\.](#) Footnote text with single reference.

I suppose that style works but it doesn't seem ideal. Using numbers for two purposes in the same context could be a little confusing. So letters could be nicer if the language-specific part isn't a problem. An example without bold:

(F)
> 1\. [<sup>*a*</sup>](#) [<sup>*b*</sup>](#) [<sup>*c*</sup>](#) Footnote text with multiple references.
> [2\.](#) Footnote text with single reference.

With brackets the links are easier to hit but I guess it takes too much space and looks a bit weird:

(G)
> 1\. [<sup>[a]</sup>](#) [<sup>[b]</sup>](#) [<sup>[c]</sup>](#) Footnote text with multiple references.
> [2\.](#) Footnote text with single reference.
","",0,0,"","none","Larhzu",4517,"Conform styling of footnote","['design']","open",0,"","[]",3,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-30 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-01-30 18:12:33","2024-01-30 18:12:32","created",1917620035,"```
for (buf_end = ((size - align_amount) - 8) + buf; buf < buf_end;
		buf += 8)

```

I suspect that `clang -fsanitize=undefined` will complain at runtime. If `size` equals 1 and `align_amount` equals 0 or 1, it ends up calculating `buf - 8` or `buf - 7`. That is, the pointer arithmetic may go beyond the beginning of the buffer, which the C standard doesn't allow (but one element past the end is allowed).

Although it should work in practice on ARM64 (unless the buffer is at a weird address where the address would overflow but that's unlikely), I think it should be possible to avoid the problem without a performance penalty.","",0,0,"","none","Larhzu",77,"Speed up CRC32 calculation on ARM64","[]","open",0,"","[]",18,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-25 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-01-25 13:54:38","1970-01-01 00:00:00","none",0,"","",0,0,"doxygen_tweak","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-25 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-25 13:54:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-01-25 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-25 13:54:50","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",12,7,"","","","none"
"2024-01-24 18:00:00","CreateEvent","Larhzu","tukaani-project/xz","2024-01-24 18:07:03","1970-01-01 00:00:00","none",0,"","",0,0,"doxygen_tweak","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-24 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-24 14:41:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",91,7,"","","","none"
"2024-01-23 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 16:23:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/threads_by_default","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",77,1,"","","","none"
"2024-01-23 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 16:30:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/threads_by_default","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-23 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 16:40:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2024-01-23 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 14:00:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/riscv_filter","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-23 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 14:13:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/riscv_filter","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-23 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-23 14:38:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/riscv_filter","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,10,"","","","none"
"2024-01-22 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-22 22:11:09","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/riscv_filter","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2024-01-14 15:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-01-14 15:44:15","2024-01-14 15:44:13","created",1890987168,"Seems to work fine at the moment. The hosting provider had reported that a denial of service attack happened 2-3 days ago.

The 5.4.2 release is available on GitHub and also on [Sourceforge](https://sourceforge.net/projects/lzmautils/files/). Future release will use github.com as the primary download URL for unrelated reasons.
","",0,0,"","none","Larhzu",78,"[Bug]: Unable to install via conan, tukanni.org is down","['bug']","closed",0,"","[]",1,"NONE","2024-01-14 15:44:13","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-14 15:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2024-01-14 15:44:14","2024-01-14 15:44:14","closed",0,"### Describe the bug

Trying to install xz_utils via conan - 
```
xz_utils/5.4.2: Sources downloaded from 'conancenter'
xz_utils/5.4.2: Calling source() in C:\Users\ContainerAdministrator\.conan2\p\xz_ut55e9abba365d4\s\src
xz_utils/5.4.2: ERROR: Error downloading file https://tukaani.org/xz/xz-5.4.2.tar.gz: 'HTTPSConnectionPool(host='tukaani.org', port=443): Read timed out. (read timeout=60)'
```

Seems like https://tukaani.org is down for the past week

### Version

5.4.2

### Operating System

Windows 11

### Relevant log output

_No response_","",0,0,"","none","snweiss",78,"[Bug]: Unable to install via conan, tukanni.org is down","['bug']","closed",0,"","[]",1,"NONE","2024-01-14 15:44:13","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-11 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-01-11 14:25:40","2024-01-11 14:25:38","created",1887297605,"@parheliamm:
> Unaligned memory access is a default feature by ARM64, so there is no need to consider align it first.

I would expect aligned access to be faster still. In general, when unaligned access is fast on some hardware, it's fast in context of other methods for unaligned access. That is, it's much faster than doing byte-by-byte access. When the access crosses cache line or page boundaries, it may have penalties that don't occur with aligned access.

You could test with something like `uint64_t buf[2048]` and then comparing speeds of `lzma_crc32(buf, sizeof(buf) - 1, 0)` and `lzma_crc32(buf + 1, sizeof(buf) - 1, 0)`. If there is no difference then it's great news.

> I don't have big-endian test environments, so I cannot predict the behavior and unit test on big-endian.
> I think support little-endian-only is a good idea. I will modify the code.

Linux has [CRC32 assembly](https://github.com/torvalds/linux/blob/master/arch/arm64/lib/crc32.S) for both endiannesses. Maybe it can help in learning what extra steps are needed for big endian support. Having said that, little-endian-only version is fine for now, especially since it sounds that no one can test the big endian code anyway.
","",0,0,"","none","Larhzu",77,"Speed up CRC32 calculation on ARM64","[]","open",0,"","[]",8,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-11 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2024-01-11 13:37:58","1970-01-01 00:00:00","none",0,"","",0,0,"crc_edits","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-11 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-11 13:08:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_edits","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-11 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-11 12:40:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_edits","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2024-01-10 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-10 16:02:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_edits","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",78,6,"","","","none"
"2024-01-10 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-10 16:19:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_edits","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-10 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2024-01-10 16:23:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_edits","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2024-01-09 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2024-01-09 19:43:46","2024-01-09 19:43:45","created",1883673406,"Thanks! A quick few early comments (I or Jia will comment more later):

The `Data` pointer seems pointless. I don't see a reason to cast away the const qualifier.

ARM64 processors tend to support unaligned memory access but would it still be worth it (better speed) to align the `buf` first with calls to `__builtin_aarch64_crc32b`? See how aligning is done in the generic code.

I'm not sure but I guess the input `crc` variable doesn't need byte-swapping but reading the input in loop will need it. So it should use `read64le` instead, or `aligned_read64le` if `buf` is first aligned. This should be investigated or the code should be marked little-endian-only if we aren't sure.

`getauxval` is a libc function (not inline) so it's unsafe to combine it with ifunc. That is, ifunc would need to stay disabled on ARM64.

Are ARM64 processors without CRC32 common enough that runtime detection is worth it? Even they are, `#ifdef __ARM_FEATURE_CRC32` could be used at compile time to detect if CRC32 can be assumed to be supported.

The crc_edits branch is still under consideration so that may change where the code will go, possibly making things simpler.
","",0,0,"","none","Larhzu",77,"Speed up CRC32 calculation on ARM64","[]","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-09 18:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-09 18:50:30","2024-01-09 18:50:29","created",1883602016,"> It's a limitation of CSS.

Unfortunately yes.

Firefox has [`-moz-first-node`](https://developer.mozilla.org/en-US/docs/Web/CSS/:-moz-first-node) and `-moz-last-node` which together would do the right thing, but it's useless here because it would be bad to have different appearence in different browsers. [Here is some discussion about these selectors.](https://github.com/w3c/csswg-drafts/issues/3216)

> One possible docinfo workaround in the interim is to use JavaScript

Thanks! I will keep that in mind. The other workarounds are starting to feel OK now that I understand the overall issue better.

> With my proposal, if you want to ensure there is a background, you have to add a role to the code that is surrounded by only text (for example, ``` [.span]`code` ```)

In theory someone might have a document with `` [.green]`--green-option` `` in a table cell so adding `:not([class])` to CSS would make the gray background appear. I suppose any change has some chance of backward incompatibility. For example, `:not(.keep-background)` has a small chance of namespace conflict.

Using `` [.span]#`code`# `` is two more characters to type. It increases the HTML size more but this needs no stylesheet changes. (`` _{empty}_ `code` `` has smaller HTML size but it's otherwise a little odd. `` __ __ `empty` `` would be the simplest to type but it affects asciidoctor-pdf output so this method shouldn't be used.)

Since there already are workarounds with similar-enough complexity as your suggestion, I guess it's not worth changing the stylesheet solely to add a new workaround variant.

Custom table roles can be a workaround in some cases. The current `:only-child` magic can be overriden for specific columns in docinfo:

```
table.keep-bg-1 > tbody > tr > td:nth-child(1) > p > code,
table.keep-bg-2 > tbody > tr > td:nth-child(2) > p > code,
table.keep-bg-3 > tbody > tr > td:nth-child(3) > p > code,
table.no-bg-in-first-only > tbody > tr > td:nth-child(n+2) > p > code {
  padding: .1em .5ex;
  background: #f7f7f8;
}
```

This may be nicer than needing to mark individual monospace strings in the cells.

> We could add a CSS class to the cell that is a monospace style, but that's a (minor) breaking change and can only be done in a minor or major release. This may be inconvenient, but it's just where we are.

Hasty frequent changes would be far more inconvenient. :-) The stability of the HTML output is appreciated.

> I think it's perfectly reasonable to add more information into the HTML to avoid this kind of situation, which we can do in the new HTML converter, as I mentioned.

Great! I know it will take time until the new HTML converter is out but it's good to hear that this detail has been taken into consideration.

Thanks!
","",0,0,"","none","Larhzu",4535,"Inconsistent style in table cells with some monospaced text","[]","open",0,"","[]",9,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-04 23:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-04 23:27:44","2024-01-04 23:27:42","created",1877901091,"I apologize if I'm wrong but I suspect that my main point hasn't been understood. In my first message, the first column of the table looks great without the gray background; I don't want to change the style in the first column. However, in the second column, there are _three_ monospace `cook` strings but only _two_ of them have a gray background.

I originally noticed this in a table where the cells had a few sentences of text. In one cell the gray background was missing from a monospaced word in the middle of a sentence. In the second cell, a monospaced word in a similar sentence did have the gray background. The generated HTML looked similar for both cells and I was confused for a moment. Then I realized that the word in the second cell had the gray background because another sentence in the same cell had an _emphasized_ word in it. It wasn't intuitive that emphasizing a word in one sentence affects the style of a word in another sentence.

Is it an intentional and desired part of the design that only two of the three `cook` strings have a gray background in the example table?

If yes, then your suggestion about applying the style only when the code span has no role might be a good workaround (it's better than using `_{empty}_` to avoid matching `:only-child`). It would still feel a bit sad considering how much attention to small details the design has in general.

> With that said, I still think that a normal cell with a single code span should look the same as a monospace table cell.

I agree now. The idea in my previous message isn't good.

(The rest of this message was written with the assumption that the three cooks example is not desired behavior and that it's worth fixing.)

Below is another attempt at code. It would use the same `p.tableblock.monospaced > code` selector as my previous prototype.

```
--- a/lib/asciidoctor/converter/html5.rb
+++ b/lib/asciidoctor/converter/html5.rb
@@ -907,8 +907,8 @@ def convert_table node
               when :literal
                 cell_content = %(<div class=""literal""><pre>#{cell.text}</pre></div>)
               else
-                cell_content = (cell_content = cell.content).empty? ? '' : %(<p class=""tableblock"">#{cell_content.join '</p>
-<p class=""tableblock"">'}</p>)
+                cell_content = cell.content.map {|e| %(<p class=""tableblock#{' monospaced' if e.match?(/^<code[> ]((?!<\/code>).)*<\/code>$/m)}"">#{e}</p>) }
+                cell_content = cell_content.join(""\n"")
               end
             end

```

It checks if a paragraph in a cell consist of a single `<code>` element. Other elements inside the `<code>` are allowed so that emphasis works:

```
| `command _argument_`
```

It checks that there is no `</code>` in the middle to keep the gray backgrounds if the content begins and ends in monospace text:

```
| `foo` or `bar`
```

That checks rejects nested `<code>` tags too but perhaps that's OK. The current stylesheet uses a gray background in that case but omits padding from the outermost `<code>` element. So there is a tiny difference in this odd corner case. Nested `<code>` can occur at least if a cell has `m` style and backticks are still used although I suspect this might be considered invalid AsciiDoc syntax:

```
m| `--option`
```

Changing the HTML output by adding the `monospaced` class shouldn't affect compatibility with old custom stylesheets. An old stylesheet just wouldn't get the style fix to the three cooks example.

A new stylesheet would have the new selector. If a new stylesheet was used with HTML from an old Asciidoctor version then unwanted gray backgrounds would appear.

I don't see other compatibility considerations now but it doesn't mean there aren't any.

Is this kind of change wanted at all? Is using a regex to match the `<code>` tags too hackish?

I apologize for being so insistent if my thoughts on this actually are on a wrong track. Thanks for reading!
","",0,0,"","none","Larhzu",4535,"Inconsistent style in table cells with some monospaced text","[]","open",0,"","[]",4,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-03 19:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-03 19:04:57","2024-01-03 19:04:56","created",1875832749,"> The point I was trying to make is that if this improvement were to be made, it would need to be done fully.

I did get your point, sorry if my message wasn't clear enough. I appreciate that you are looking for complete solutions. I understand that it's not possible to cover all use cases at the same time.

I'm happy enough with a simpler partial solution in my stylesheet customizations and I won't spend much time refining that part further. For the most polished prints there is asciidoctor-pdf anyway.

> When that is set, the CSS would need to modify all the elements that are colorized so they use as an appropriate amount of ink to be legible (we have to think of the dark gray of the primary text as a color).

For what it's worth (probably not much), I feel the grays with the alpha values 0.8, 0.85, and 0.9 might be safest to become `#000` when printing to paper with an unknown printer (a monochrome printer might dither grays ugly, a color printer might mix color-ink to produce grays). The alpha value isn't the only thing that differs in those selectors so flattening to black isn't a too bad compromise. The alpha 0.6 could maybe become dark gray instead of black.

With color printers, having some color in the headings might even be nice, as long as it's not too light.

There are too many possibly-useful combinations.
","",0,0,"","none","Larhzu",4531,"Stylesheet: Avoid gray body text in @media print","[]","open",0,"","[]",4,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 22:00:00","IssuesEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 22:59:06","2024-01-02 22:59:05","opened",0,"Test case with the default stylesheet:

```
= Title

The `cook` command supports the following options:

[%autowidth]
|===
| `--cold`    | Allow `cook` to make cold foods.
| `--hot`     | Allow `cook` to make hot foods. Cannot be combined with `--cold`.
| `--sweet`   | Allow `cook` to make desserts. _{empty}_
|===
```

On the first row, `cook` doesn't have the gray background. On the other two rows it has the background.

It happens because of this:

```
p.tableblock > code:only-child {
  background: none;
  padding: 0;
}
```

I get that it can make the first column in the table look better. The current implementation makes semantics and style mix a bit though because one may need to add an empty extra element to get the correct style when there is also non-monospace content in the table cell.

It's only a minor thing that is easy to work around once one is aware of it. The small details just grab one's attention when everything else looks very polished already. :-)
","",0,0,"","none","Larhzu",4535,"Inconsistent style in table cells with some monospaced text","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 21:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 21:06:48","2024-01-02 21:06:47","created",1874569632,"Thanks! I see the question isn't as simple as I had thought and I may have had wrong assumptions too.

Anyway, my intent wasn't to suggest making all text black. My point was to ensure that the main content would print as black and thus have good legibility if browser or printer driver doesn't convert gray to black automatically. The amount of text in figure captions, admonitions etc. typically isn't that much, so even if those were too light for good printing, the overall result could have been good for casual prints still.

I had assumed that black body text in print-to-PDF use would be desirable because I assumed that PDFs are typically generated so that they are good for printing (things like clickable links are just extra features on top). I hadn't used asciidoctor-pdf apart from a quick test, and now that I looked more closely I see it uses `#333` by default and black text needs `--theme=default-for-print`. So now I realize that there are people who prefer gray body text even in PDF, thus using black body text for HTML-to-PDF conversion isn't the trivially-obvious choice like I had thought.

> Keep in mind, you can use [docinfo](https://docs.asciidoctor.org/asciidoc/latest/docinfo/) to provide additional print styles without any change to core.

Thanks! I'm already making a few other changes to the default stylesheet where docinfo alone isn't convenient enough. I'm trying to still keep it easy to stay in sync with upstream changes. A few tiny fixes/improvements were such that I thought they could make sense upstream but clearly the printing related idea isn't such.

Since I have a simple but decent solution for my taste (using CSS custom properties), I don't plan to spend more time on `@media print` improvements for now. Feel free to close this issue. Thanks!
","",0,0,"","none","Larhzu",4531,"Stylesheet: Avoid gray body text in @media print","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 21:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 21:29:21","2024-01-02 21:29:20","created",1874590386,"> It's a common misconception that a license has to be repeated in its entirety in every source file.

Maybe it is common but I know it's not true. Having just one copy is indeed fine in the source tree.

> If this presents a problem for you in your particular usage (which I understand), you're free to write a postprocessor extension (or similar) to inject it into the output.

The MIT license is the only thing that gives me and others a legal permission to distribute the stylesheet (or any other file from Asciidoctor), thus I will follow the requirements in the license carefully. Adding the copyright notice and license is indeed a trivial thing for me to do. I merely thought that it would have been convenient default for users in general as well.

I apologize for the noise. Thanks for the great software!
","",0,0,"","none","Larhzu",4532,"Stylesheet: License should be included","['declined']","closed",0,"","[]",2,"NONE","2023-12-30 01:37:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 20:00:00","CreateEvent","Larhzu","Larhzu/asciidoctor","2024-01-02 20:53:07","1970-01-01 00:00:00","none",0,"","",0,0,"stylesheet_footnote","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 20:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 20:59:20","2024-01-02 20:59:19","created",1874552664,"> If you would like to add the `#footnotes .footnote a:first-of-type:active` to the following selector, I'll merge it.

It's #4534. Hopefully it's OK.

> Related to this, we are considering revamping the appearance of footnotes in a future release. See #4517.

Thanks! I don't think I have much to add, I find both C and A to be good choices.
","",0,0,"","none","Larhzu",4530,"Stylesheet: Underline active footnote link","['improvement','design']","open",0,"Larhzu","['Larhzu']",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2024-01-02 20:00:00","PullRequestEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 20:57:15","2024-01-02 20:57:13","opened",0,"Consider the following document:

    = Title

    Foo.footnote:[Bar]

The link after Foo is underlined in active state but the link before Bar wasn't before this commit.

Note that the related

    #footnotes .footnote a:first-of-type {
      ...
      text-decoration: none;
      ...
    }

is later in the stylesheet but this way the code is slightly smaller.

Fixes: https://github.com/asciidoctor/asciidoctor/issues/4530","",0,0,"","none","Larhzu",4534,"resolves #4530 by underlining active footnote link","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","stylesheet_footnote","634b0042ad99671bb726ddbb1acbb86d4961b737","main","7d856042fdd278f87d4c480180440e519fa1e97c",0,0,0,"unknown","",0,1,1,3,2,2,"",0,"","",0,0,"","","","none"
"2024-01-02 19:00:00","ForkEvent","Larhzu","asciidoctor/asciidoctor","2024-01-02 19:59:31","1970-01-01 00:00:00","none",0,"","",0,0,"","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 22:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-12-28 22:55:52","1970-01-01 00:00:00","none",0,"","",0,0,"xz_pledge","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 17:00:00","IssuesEvent","Larhzu","asciidoctor/asciidoctor","2023-12-28 17:08:11","2023-12-28 17:08:10","opened",0,"Test case:

```
= Title

Foo.footnote:[Bar]
```

The link after Foo is underlined in active state (keeping the mouse button pressed down) but the link before Bar isn't underlined in active state.

The following could be added for consistency with `sup.footnote a:active` (and `#toc a:active`):

```
#footnotes .footnote a:first-of-type:active {
  text-decoration: underline;
}
```

Then the section anchors would be the only links without underline in active state, which looks fine to me.","",0,0,"","none","Larhzu",4530,"Stylesheet: Underline active footnote link","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 17:00:00","IssuesEvent","Larhzu","asciidoctor/asciidoctor","2023-12-28 17:18:13","2023-12-28 17:18:11","opened",0,"The body text is transparent black on white background, resulting in gray text (equivalent to `#333`):

```
body {
  background: #fff;
  color: rgb(0 0 0 / 0.8);
  ...
}
```

The reasons to use gray instead of black text on screen don't apply to printing. The main body text should be black (`#000`) when printing to avoid dithering.

Browsers might convert gray text to black when printing. Some printer drivers might do it too. So even now the gray text might print as black in some cases. It would be good to ensure good results in all cases still.

For example, Firefox 121 converts gray text to black if the gray color is specified as `#333` or `#666` and _Print backgrounds_ is unchecked in the Firefox' print options. However, if the same colors are specified as transparent black text like `rgb(0 0 0 / 0.8)` or `rgb(0 0 0 / 0.6)` then the text remains gray even if _Print backgrounds_ is unchecked. These can be tested by printing to PDF and taking a screenshot from a PDF viewer.

I'm not sure which elements should use black text when printing. `h1`, `body`, `pre`, `code`, and the various table-related elements that use `rgb(0 0 0 / 0.8)` should probably be black when printing. But perhaps a few other elements should be black too.

(A side note: I find `rgb(0 0 0 / 0.8)` (`#333`) too light on some displays (it hurts legibility). Somewhere from `rgb(0 0 0 / 0.87)` (`#222`) to `rgb(0 0 0 / 0.93)` (`#121212`) would look better to me. But I know it depends on the display, display brightness, user preference etc. so I don't dare to propose any changes.)
","",0,0,"","none","Larhzu",4531,"Stylesheet: Avoid gray body text in @media print","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 17:00:00","IssuesEvent","Larhzu","asciidoctor/asciidoctor","2023-12-28 17:25:00","2023-12-28 17:24:58","opened",0,"The default stylesheet, that gets embedded into the HTML output by default, only includes the following line that refers to the license or copyright info:

```
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
```

The MIT license requires that the copyright notice and the license itself must be included in all substantial portions of the licensed work. The stylesheet is clearly a substantial portion of Asciidoctor (it's much more than a dozen simple lines of code).

My interpretation is that to legally distribute the HTML-with-the-default-stylesheet output of Asciidoctor one would need to include the copyright and license info manually. This obviously won't usually get done.

Including the copyright notice and the license text in full would make the stylesheet slightly bigger but it seems the most practical option. Including only an URL to the license isn't enough:

1. The document might be read offline.
2. The document must stay redistributable in the future even if the license URL no longer worked for whatever reason.

The copyright notice should include the end year like ""2012-2023"" instead of ""2012-present"" as (at least in theory) copyright is meant to expire some day and ""present"" will become inaccurate when the document gets old.

I understand this can feel annoying and also be somewhat annoying to implement in practice (keeping the notice up to date). So I sympathize but still think this is worth doing.
","",0,0,"","none","Larhzu",4532,"Stylesheet: License should be included","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 16:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-12-28 16:50:45","1970-01-01 00:00:00","none",0,"","",0,0,"memcmplen_arm64","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-12-28 16:54:14","2023-12-28 16:54:12","created",1871341248,"The 8-byte version is now enabled in memcmplen.h for ARM64 in the master branch. It will be included in XZ Utils 5.6.0. Thanks!","",0,0,"","none","Larhzu",75,"Performance improvements on ARM64","[]","closed",0,"","[]",3,"NONE","2023-12-28 16:54:12","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-28 16:00:00","PullRequestEvent","Larhzu","tukaani-project/xz","2023-12-28 16:54:13","2023-12-28 16:54:13","closed",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:

- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [x] Build was run locally and without warnings or errors
- [x] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:

- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [x] Build related changes
- [ ] Documentation content changes
- [x] Other (please describe): 


## What is the current behavior?

<!-- Please describe the current behavior that you are modifying. -->


<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?

<!-- Please describe the behavior or changes that are being added by this
PR. -->

- Change LZMA_MEMCMPLEN_EXTRA to 8 on ARM64
- select enable-unsafe-type-punning if enable_unaligned_access enabled
  -

## Does this introduce a breaking change?

- [ ] Yes
- [ ] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

Performance improvements on ARM64 with 2 commits:

    vanilla:
    Compressor name         Compress. Decompress. Compr. size  Ratio Filename
    memcpy                   5102 MB/s  5183 MB/s   211957760 100.00 silesia.tar
    xz 5.2.5 -0              15.9 MB/s  51.6 MB/s    62579868  29.52 silesia.tar
    xz 5.2.5 -1              11.8 MB/s  57.5 MB/s    58408297  27.56 silesia.tar
    xz 5.2.5 -2              7.53 MB/s  59.9 MB/s    56708167  26.75 silesia.tar
    xz 5.2.5 -3              5.02 MB/s  61.6 MB/s    55745576  26.30 silesia.tar
    xz 5.2.5 -4              3.15 MB/s  62.7 MB/s    52106950  24.58 silesia.tar
    xz 5.2.5 -5              2.29 MB/s  65.1 MB/s    49960648  23.57 silesia.tar
    xz 5.2.5 -6              1.94 MB/s  65.5 MB/s    49196155  23.21 silesia.tar
    xz 5.2.5 -7              1.83 MB/s  65.7 MB/s    48926731  23.08 silesia.tar
    xz 5.2.5 -8              1.87 MB/s  66.4 MB/s    48768992  23.01 silesia.tar
    xz 5.2.5 -9              1.85 MB/s  66.5 MB/s    48747544  23.00 silesia.tar



Patched:

```
Compressor name         Compress. Decompress. Compr. size  Ratio Filename
memcpy                   5209 MB/s  5265 MB/s   211957760 100.00 silesia.tar
xz 5.2.5 -0              16.4 MB/s  51.9 MB/s    62579868  29.52 silesia.tar
xz 5.2.5 -1              12.0 MB/s  57.8 MB/s    58408297  27.56 silesia.tar
xz 5.2.5 -2              8.26 MB/s  60.2 MB/s    56708167  26.75 silesia.tar
xz 5.2.5 -3              5.14 MB/s  61.6 MB/s    55745576  26.30 silesia.tar
xz 5.2.5 -4              3.29 MB/s  62.7 MB/s    52106950  24.58 silesia.tar
xz 5.2.5 -5              2.42 MB/s  64.9 MB/s    49960648  23.57 silesia.tar
xz 5.2.5 -6              2.03 MB/s  65.6 MB/s    49196155  23.21 silesia.tar
xz 5.2.5 -7              1.93 MB/s  65.6 MB/s    48926731  23.08 silesia.tar
xz 5.2.5 -8              1.94 MB/s  66.3 MB/s    48768992  23.01 silesia.tar
xz 5.2.5 -9              1.91 MB/s  66.4 MB/s    48747544  23.00 silesia.tar
done... (cIters=1 dIters=1 cTime=1.0 dTime=2.0 chunkSize=1706MB cSpeed=0MB)
```

","",0,0,"","none","parheliamm",75,"Performance improvements on ARM64","[]","closed",0,"","[]",3,"NONE","2023-12-28 16:54:12","1970-01-01 00:00:00","3d5f9ac24fc72a6933485e0a92cd1b95947176f3","[]","[]","master","913541910857519860e830b21a3937a0b7fceaaa","master","183a62f0b540ff4d23cc19b2b6bc2525f0bd64df",0,0,0,"dirty","",0,0,2,8,1,2,"",0,"","",0,0,"","","","none"
"2023-12-28 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-12-28 16:48:53","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-12-20 19:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-12-20 19:51:50","1970-01-01 00:00:00","none",0,"","",0,0,"memcmplen_arm64","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-20 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-12-20 19:51:59","2023-12-20 19:51:58","created",1865048052,"I created a branch memcmplen_arm64 which should do the same as your first commit and also adds MSVC support on ARM64 (untested).

The commit message of your second commit has significantly higher numbers on the memcpy line. I'm not familiar with lzbench but I wonder if 10 % difference in memcpy could indicate that there was something different on the test computer and thus the benchmark results could be slightly different too. The difference in compression speed is small so it would be good to be sure that it's not due to noise.

In any case, the second patch cannot be accepted. Unfortunately you have misunderstood the problem with type punning. It's about the C programming language and how modern compilers optimize while still staying within the exact requirements of the C standard. Unsafe use of type punning breaks strict aliasing rules and might result in broken executables. The instruction set being used doesn't matter; even if unaligned access wasn't supported by the hardware, type punning would be problematic with modern compilers when accessing aligned data.

The memcpy method used by tuklib_integer.h should compile to a single instruction with modern GCC and Clang/LLVM versions when building for a target that supports fast unaligned access. Thus the use of type punning shouldn't make a difference on ARM64. However, it's possible that compilers do something slightly differently still and thus there could be a difference in practice, or the violation of aliasing rules allows compilers to do something that happens to work but could cause problems some day. It's a bit annoying situation but I don't know any better way.

Thanks!","",0,0,"","none","Larhzu",75,"Performance improvements on ARM64","[]","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-20 16:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-12-20 16:28:36","1970-01-01 00:00:00","none",0,"","",0,0,"xz_pledge","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-02 17:00:00","IssueCommentEvent","Larhzu","asciidoctor/asciidoctor","2023-12-02 17:27:41","2023-12-02 17:27:39","created",1837209053,"Your fix is definitely better. Thanks!

> Please don't bundle issues.

I apologize. I won't do it again.
","",0,0,"","none","Larhzu",4523,"Stylesheet: Avoid a second border below the main heading","['bug']","open",0,"mojavelinux","['mojavelinux']",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-01 22:00:00","IssuesEvent","Larhzu","asciidoctor/asciidoctor","2023-12-01 22:10:43","2023-12-01 22:10:41","opened",0,"These apply to both v2.0.x and main branches.

If `<div class=""details"">` is missing when using `:toc: left` or `:toc: right`, an extra border is drawn below the main heading if the viewport is narrow (when the TOC is shown below the heading).

A minimal test case (use a narrow browser window):

```
:toc: left

= Foo

== Bar
```

It seems simple to fix based on `toc` vs. `toc2` class:

```
-#header > h1:first-child + #toc {
+#header > h1:first-child + #toc.toc {
```

I tried to test that it doesn't break any other combinations and didn't find any issues but of course it's possbile that I missed a corner case still.

Unrelated but it's so tiny thing that I mention it here anyway: The following could be added for consistency with `sup.footnote a:active` (and `#toc a:active`).

```
#footnotes .footnote a:first-of-type:active {
  text-decoration: underline;
}
```

Thanks!
","",0,0,"","none","Larhzu",4523,"Stylesheet: Avoid a second border below the main heading","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-01 17:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-12-01 17:14:18","2023-12-01 17:14:19","created",1412378423,"Just listing the names in ""Authors:"" works best. I suspect that I didn't write the exact fuzz.c but it's based on the example programs in doc/examples which I did write. With these particular files, the author info doesn't matter to me, it's just that someone auditing where the code came from might care about ""Authors:"" convering everyone.","tests/ossfuzz/fuzz_decode_alone.c",0,0,"","none","Larhzu",73,"Improve existing oss-fuzz coverage","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","0fffb448ab9f0a51007f1b03fb3290436ed6dc15","[]","[]","master","9394218ec8062f5aa608141f3e42f9694d4a950a","master","35558adf9c45e5597f2c8dbd969885dd484038d2",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,41 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       fuzz_decode_alone.c
+/// \brief      Fuzz test program for liblzma lzma_alone_decoder()
+//
+//  Author:     Maksym Vatsyk
+//
+//  Based on Lasse Collin's original fuzz.c fuzzer for liblzma",8,"9394218ec8062f5aa608141f3e42f9694d4a950a","cc0f39c288b99977edab4079feddac7a0426c6ab",0,0,"","","","none"
"2023-12-01 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-12-01 17:19:16","2023-12-01 17:19:14","created",1836491554,"Thanks to both of you for your work so far!

There are a few things I would like to understand better. I have only skimmed OSS-Fuzz's docs so I might be asking silly questions, sorry.

1. Seems that [renaming a fuzz target](https://google.github.io/oss-fuzz/faq/#what-happens-when-i-rename-a-fuzz-target-) requires renaming the accumulated corpora too.

2. Does adding more fuzzers mean that the project-specific fuzzing resources (processor time) will be divided between the fuzzers? With a quick look I didn't find any advice about resource usage in OSS-Fuzz docs and it's not discussed much in this thread either.

3. The value of code coverage in fuzzing is unclear. *If* extending coverage by a few simple lines of code could slow down fuzzing of more important parts of the code, does it make sense to extend fuzzing coverage in that case? I'm thinking of cases where an old-school code review shouldn't take a lot of time (code snippets that are about 200 lines each and do nothing unusually complicated). Or perhaps these should be fuzzed at first but disabled after some time if they find nothing?

Examples of remaining significant overlap in the new fuzzing targets:

* fuzz_encode_alone.c would test end of payload marker (EOPM) encoding in LZMA but otherwise it doesn't test much that won't be tested by fuzz_encode_stream.c. They both use the LZMA encoder in the end. So it seems that fuzz_encode_alone.c isn't useful and could _maybe_ even be harmful due to resource usage unless the fuzzers are smart enough to spot when code paths become identical.

* fuzz_decode_alone.c splits into three different decoders depending on the input. Yet the three decoders are fuzzed separately too (stream, alone, lzip). So the only extra fuzzed thing is the small auto_decoder.c.

I don't know enough about the fuzzing methods to know what actually makes sense. I would like to be assured that adding all these fuzzers adds real value.

Thanks!
","",0,0,"","none","Larhzu",73,"Improve existing oss-fuzz coverage","[]","open",0,"","[]",11,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-12-01 17:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-12-01 17:14:19","2023-12-01 17:14:19","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [x] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [ ] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [x] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->


<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

- Total number of fuzzers increased from 1 to 12
- 6 new fuzzers for decompressing supported archive types
- 5 new fuzzers for compressing data into supported archive types
- Added LZMA Raw test files based on the existing `.lzma` ones

## Does this introduce a breaking change?

- [x] Yes
- [ ] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->
This pull request will temporarily break existing oss-fuzz setup until the `oss-fuzz` repo accepts [a corresponding pull request](https://github.com/google/oss-fuzz/pull/11279) with the updated fuzzer configuration on their side.

## Other information

<!-- Any other information that is important to this PR. -->
The improvements to the fuzzing setup were made as a part of Google ISE project.","",0,0,"","none","mvatsyk-lsg",73,"Improve existing oss-fuzz coverage","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","0fffb448ab9f0a51007f1b03fb3290436ed6dc15","[]","[]","master","9394218ec8062f5aa608141f3e42f9694d4a950a","master","35558adf9c45e5597f2c8dbd969885dd484038d2",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-11-23 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-11-23 15:39:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-11-17 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-11-17 17:36:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/suffix_fix","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-11-16 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-16 19:55:32","2023-11-16 19:55:30","created",1815219616,"> an ifunc WILL compile and link successfully in a dynamically built program, but musl does not implement ifunc (GNU glibc only extension)

Yes, I relealized this as I wrote in my next message. Since GCC upstream knows that musl doesn't support ifunc, I wonder if Clang/LLVM should know it too and then warn or error if the ifunc attribute is used. That is, I wonder if this could be a Clang/LLVM bug.

> a crude hack to detect musl is to detect /lib/ld-musl-*

In Autoconf, checking if `$host_os` equals `linux-musl` probably is the correct method. I don't know right now how to detect it in CMake.

According to musl's FAQ, there intentionally is no easy `#ifdef` to detect musl in C code.

Hacks like checking file paths wouldn't work when cross-compiling.

On the second thought, uClibc might not support ifunc either. It could be better to detect glibc, so `linux-gnu` in case of Autoconf (maybe FreeBSD too). But once again I don't know right now how to detect the libc in CMake.","",0,0,"","none","Larhzu",70,"[Bug]: MUSL CMAKE unsupported relocation type 37","['bug']","open",0,"","[]",7,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-16 13:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-16 13:15:23","2023-11-16 13:15:22","created",1814416890,"> Those links are **tied to a same named file** - _xz-5.4.5.tar.gz_. That represents a reasonable source of confusion.

I hadn't realized this. When hovers of the link, it points to _v5.4.5.tar.gz_. If copy the link and use it with `wget` I will get _v5.4.5.tar.gz_. But if I click the link with Firefox, the name gets converted to _xz-5.4.5.tar.gz_.

Having a way to get a tarball of the git tag is useful in general and for some projects it's all they need. But for many other projects it's confusing especially since the link is forcefully named _Source code_. The icons differ but a cube vs. a zipper doesn't convey any meaning to me at least.","",0,0,"","none","Larhzu",71,"Missing `configure` file","['bug']","closed",0,"","[]",5,"NONE","2023-11-16 12:52:41","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-16 13:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-16 13:39:53","2023-11-16 13:39:51","created",1814455227,"INSTALL.generic [does mention](https://github.com/tukaani-project/xz/blob/f481523baac946fa3bc13d79186ffaf0c0b818a7/INSTALL.generic#L85) `make uninstall`. Note that for it to work you practically need to keep the matching build tree around. Builds made with different options or builds of different package versions can install and thus uninstall a different set of files.

`--prefix` sets the location where the files are expected to be when the programs or libraries are used. This matters because some paths may get hardcoded (like translations or library search path (rpath)).

`DESTDIR` allows doing a kind of fake install to a temporary directory from which a distro-specific package (`.deb`, `.rpm`, `.txz` etc.) can be created. In general one cannot run the program in the `DESTDIR` directory.

One option is to use

```
./configure --prefix=/home/foo/local-xz
make install
```

and then put /home/foo/local-xz/bin to `PATH`. This way uninstallation is simple: just `rm -r /home/foo/local-xz`.

In case of XZ Utils, if you only want the latest `xz` command line tool, build it against static liblzma without translation support. In case of `xz` there will then be no dependencies that rely on `--prefix`. With many other packages it's not so; this tip is specific to XZ Utils. You can also use the `-j` option with `make` to use multiple processor cores for a shorter build time.

```
./configure --disable-shared --disable-nls
make -j4
cp src/xz/xz /home/foo/bin/
```

The `/home/foo/bin/` is a directory of your choosing. That is, no need to use `make install` if you only need `xz`.","",0,0,"","none","Larhzu",72,"Uninstallation | Support by script or documented in the `INSTALL.generic` file","[]","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-15 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-15 17:47:14","2023-11-15 17:47:13","created",1812989020,"My above comment is wrong. The failure is from the dynamic linker, not static linker, sorry.

Perhaps it's that GCC knows that ifunc isn't supported with musl. [config.gcc](https://gcc.gnu.org/git?p=gcc.git;a=blob;f=gcc/config.gcc;h=c1460ca354e8f7baea3229312b17c63bd45f760a;hb=HEAD#l3637) doesn't set `default_gnu_indirect_function` with musl. Maybe Clang/LLVM needs to learn this too if it currently doesn't warn.","",0,0,"","none","Larhzu",70,"[Bug]: MUSL CMAKE unsupported relocation type 37","['bug']","open",0,"","[]",4,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-15 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-15 14:51:53","2023-11-15 14:51:51","created",1812682440,"In CMake-based build, the test for attributes both compiles and links. Perhaps the problem is that linker can omit the function as it's not used in the program.

CMakeLists.txt line 810:

```
int main(void) { return 0; }
```

I wonder if this would help:","",0,0,"","none","Larhzu",70,"[Bug]: MUSL CMAKE unsupported relocation type 37","['bug']","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-15 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-11-15 14:59:47","2023-11-15 14:59:45","created",1812696950,"Thank you for letting us know. If you are able to continue, please let us know too to ensure that no duplicate work will happen (unlikely but still).","",0,0,"","none","Larhzu",64,"Crc32 clmul","[]","closed",0,"","[]",12,"CONTRIBUTOR","2023-10-13 12:54:05","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-08 19:00:00","PullRequestEvent","Larhzu","plougher/squashfs-tools","2023-11-08 19:36:30","2023-11-08 19:36:29","opened",0,"This sets LZMA2 options pb=2, lp=2, lc=2 as the default with the ARM64 filter as those are good for ARM64 code (all instructions are 4 bytes and 4-byte aligned). pb=2 is a default from the preset. lc=2 is needed because the sum lc+lp must not exceed 4 and the default is lc=3.

The ARM64 filter requires liblzma >= 5.4.0. It will build against older liblzma but then the filter won't be available. An alternative could have been to use

    #ifndef LZMA_FILTER_ARM64
    #define LZMA_FILTER_ARM64 LZMA_VLI_C(0x0A)
    #endif

which would allow building against older liblzma and make the filter available once liblzma is upgraded, without requiring a recompilation of squashfs-tools.

The help text lists `arm64` even if built against pre-5.4.0.

Linux 6.7 will hopefully include the ARM64 filter.
https://lkml.org/lkml/2023/11/8/775","",0,0,"","none","Larhzu",268,"Add ARM64 filter support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","xz_arm64","33e03bdda9b86bef7f61e521744f109af1b71951","master","181710a0c14e49a65503bc169f25126f1a1bf77d",0,0,0,"unknown","",0,1,1,24,4,2,"",0,"","",0,0,"","","","none"
"2023-11-08 19:00:00","CreateEvent","Larhzu","Larhzu/squashfs-tools","2023-11-08 19:32:39","1970-01-01 00:00:00","none",0,"","",0,0,"xz_arm64","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-08 19:00:00","ForkEvent","Larhzu","plougher/squashfs-tools","2023-11-08 19:13:29","1970-01-01 00:00:00","none",0,"","",0,0,"","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-01 11:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-11-01 11:52:22","1970-01-01 00:00:00","none",0,"","",0,0,"threads_by_default","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-11-01 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-11-01 11:54:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/threads_by_default","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-30 16:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-30 16:45:29","1970-01-01 00:00:00","none",0,"","",0,0,"visibility_hidden","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-30 16:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-30 16:45:29","1970-01-01 00:00:00","none",0,"","",0,0,"always_inline","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-30 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-30 16:44:53","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,3,"","","","none"
"2023-10-30 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-30 16:32:30","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/always_inline","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-10-30 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-30 16:11:37","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/always_inline","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-30 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-30 16:07:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/visibility_hidden","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",20,2,"","","","none"
"2023-10-30 15:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-30 15:48:07","1970-01-01 00:00:00","none",0,"","",0,0,"always_inline","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-27 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-27 12:07:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,0,"","","","none"
"2023-10-26 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-26 18:48:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",14,14,"","","","none"
"2023-10-26 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-26 16:43:42","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,10,"","","","none"
"2023-10-26 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-26 15:59:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",14,14,"","","","none"
"2023-10-26 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-26 15:42:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",53,14,"","","","none"
"2023-10-25 20:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-25 20:40:55","1970-01-01 00:00:00","none",0,"","",0,0,"cflags_fsanitize2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-25 20:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-25 20:40:55","1970-01-01 00:00:00","none",0,"","",0,0,"cflags_fsanitize","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-25 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-25 17:31:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2023-10-25 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-25 17:18:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cflags_fsanitize2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-25 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-25 17:09:10","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cflags_fsanitize2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-25 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-25 17:04:15","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cflags_fsanitize2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-25 16:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-25 16:13:56","1970-01-01 00:00:00","none",0,"","",0,0,"cflags_fsanitize2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-25 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-25 16:23:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cflags_fsanitize2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-23 17:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-23 17:57:09","1970-01-01 00:00:00","none",0,"","",0,0,"cflags_fsanitize","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-23 13:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-23 13:44:34","1970-01-01 00:00:00","none",0,"","",0,0,"sandbox_update","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-23 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-23 13:44:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,0,"","","","none"
"2023-10-23 12:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-23 12:20:29","1970-01-01 00:00:00","none",0,"","",0,0,"crc_edits","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-23 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-23 12:44:34","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/visibility_hidden","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-22 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 18:16:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2023-10-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 17:35:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2023-10-22 16:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-22 16:04:55","1970-01-01 00:00:00","none",0,"","",0,0,"clock_gettime","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-22 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 16:11:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",31,8,"","","","none"
"2023-10-22 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 16:07:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/visibility_hidden","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,2,"","","","none"
"2023-10-22 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 16:05:21","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",13,7,"","","","none"
"2023-10-22 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 16:04:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2023-10-22 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-22 15:59:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-10-22 14:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-22 14:30:51","1970-01-01 00:00:00","none",0,"","",0,0,"visibility_hidden","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-20 18:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-10-20 18:34:04","1970-01-01 00:00:00","none",0,"","",0,0,"tuklib_integer_memcpy","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-20 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-20 17:01:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",30,7,"","","","none"
"2023-10-18 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-18 16:12:38","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,4,"","","","none"
"2023-10-18 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-18 11:32:47","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_clmul","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-18 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-18 11:06:50","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_clmul","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",15,15,"","","","none"
"2023-10-17 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-17 22:13:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/crc_clmul","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",22,22,"","","","none"
"2023-10-16 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-16 18:39:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-16 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-16 17:55:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-16 15:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-16 15:02:47","1970-01-01 00:00:00","none",0,"","",0,0,"build_werror2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-16 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-16 15:28:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-15 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-15 19:23:37","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,4,"","","","none"
"2023-10-15 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-15 15:23:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-14 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-14 17:21:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,4,"","","","none"
"2023-10-13 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-10-13 16:04:29","2023-10-13 16:04:28","created",1761756282,"I'm glad this has been merged. Thanks!

A few thoughts about 32-bit x86: Testing on modern 64-bit processor running 32-bit code was what I had in mind, so that part is fine. The results look strange though.

The 32-bit assembly code implements the same algorithm as the generic C code. The CLMUL version should easily be faster with 1024-byte buffers, even if those were unaligned.

With GCC 3.3/3.4 I remember that GCC couldn't fit all hot variables in registers and the resulting extra stack access was bad for speed. On x86-64 this isn't a problem anymore. My expectation is that the 32-bit x86 assembly code for CRC32 should have similar speed as the generic C code has on x86-64. I don't have clear expectations of the speed of the C code on 32-bit x86.

On 32-bit x86, CRC64 benefits more from CLMUL because 32-bit x86 doesn't have 64-bit general-purpose registers. With the generic method, including the assembly implementation, the 64-bit CRC value needs two registers and updating it needs more instructions.

I wondered if eight xmm registers could be a limiting factor on 32-bit x86. However, on x86-64 exactly eight xmm registers are used by both CRC32 and CRC64 CLMUL implementations with GCC 13.2.1. So I suppose the number of xmm registers shouldn't be a problem.

We (or likely it's mostly Jia) will do a few tests later.

Thanks again!
","",0,0,"","none","Larhzu",64,"Crc32 clmul","[]","closed",0,"","[]",8,"CONTRIBUTOR","2023-10-13 12:54:05","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-11 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-11 17:02:32","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-11 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-11 16:17:55","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,2,"","","","none"
"2023-10-11 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-11 16:17:11","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/clock_gettime","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",12,6,"","","","none"
"2023-10-11 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-11 16:16:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,3,"","","","none"
"2023-10-09 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-09 22:31:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-09 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-09 19:30:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2023-10-09 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-09 19:46:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-09 16:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-09 16:00:00","1970-01-01 00:00:00","none",0,"","",0,0,"sandbox_update","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-09 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-09 16:24:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sandbox_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-10-06 22:00:00","CommitCommentEvent","Larhzu","tukaani-project/xz","2023-10-06 22:24:16","2023-10-06 22:24:16","none",129371739,"> Actually, that doesn't match my experience (and I just rechecked just to be sure), AFAIK `_WIN32` isn't defined by the compiler in Cygwin.

OK, that's good to know, thanks. Now I wonder why the (harmless) commits 0deb1bb60addd1306b525e0ac0ad2a84eb0390d9 and 44d70cb154225e47eebf15a3cfbdf3794cbb4593 were made and left me believe that `_WIN32` is or might be defined. The commit messages are a bit confusing. :-( I remember that around those times I even tested on Cygwin.

> I wonder if the MSYS environment defines `CYGWIN` as well

It likely does since Modules/Platform/MSYS-Initialize.cmake includes Platform/CYGWIN-Initialize which sets `CYGWIN`. But checking for `MSYS` shouldn't hurt, I hope.

> But even if I didn't merge it, the incomplete/unverified/possibly subtly incompatible Meson file lives on elsewhere in their wrapdb, unmaintained by me, used by some other Meson projects.

I had to look at wrapdb now. Seems that there is XZ Utils 5.2.12 under the name liblzma but not XZ Utils 5.4.x. **If** I understood correctly:

- meson.build contains the old bug reporting address (my personal email address) which was changed in 5.2.9. So it's obvious that the wrap file is updated without a throrough compare with upstream changes.

- It assumes that the target is little endian and supports fast unaligned access.

- Check for `optreset` has been commented out. OpenBSD's man page says that GNU-style `optind = 0` is supported but FreeBSD and NetBSD don't. So maybe parsing the environment vars `XZ_OPT` and `XZ_DEFAULTS` is broken on those.

- liblzma has an unneeded depedency on libintl on systems where it's not part of libc.

- I don't see anything about installing the xz translation files even though translation support is built.

At glance I guess it is good enough in practice for the most common use cases (GNU/Linux and Windows). :-) It's clear that it has take some effort to get it to the current shape even though it would have a long way to become polished and feature complete. 5.4.x has a few new #defines so that might explain why 5.4.x isn't there yet.

Oh well. At least the windres workaround in CMake should be correct now. Thanks again!","",0,0,"","none","Larhzu",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"0570308ddd9c0e39e85597ebc0e31d4fc81d436f","",0,0,"","","","none"
"2023-10-06 17:00:00","CommitCommentEvent","Larhzu","tukaani-project/xz","2023-10-06 17:08:13","2023-10-06 17:08:13","none",129350555,"> I'm not entirely 100% sure here, but I think MINGW OR CYGWIN might be the right thing; cygwin in general doesn't set WIN32 I think, as it's mostly considered unixy.

It's unfortunate that it's not documented very clearly but it seems that [you are right](https://gitlab.kitware.com/cmake/cmake/-/commit/a429e4b9b1a56470c6c119a077910d2f090c21d0). So perhaps the CMake-based build has been broken on Cygwin for quite some time.

(In C code, `_WIN32` is #defined on Cygwin, which slightly adds to the confusion.)

Grepping the sources gave me a feeling that `MSYS` should be listed in addition to `CYGWIN` to cover MSYS and MSYS2.

I used `STREQUAL` instead of `MATCHES`. I suppose other Clang-based compiler strings in CMake aren't relevant in this particular case. I understand that `MATCHES` might be better in generic situations (it misses ""IntelLLVM"" though).

I have committed a fix to master. Thanks!

> And usually it's worse if one provides multiple build systems, but their functionality isn't entirely equal, either in how the build works, or worse, the header/pkgconfig install layout differs, or ABI details like sonames or such differ between various builds.

Most of these apply to XZ Utils for now. w32_update has a commit to install the pkgconfig file. On GNU/Linux even that differs slightly due to CMake not adding `-pthread` since pthreads are in libc in modern glibc versions. That difference shouldn't matter in practice, luckily.

Soname differences are hard to avoid with Libtool vs. anything else on certain platforms.

I wonder if not supporting Meson is a problem in the long term. I have seen one or two quickly-written files for building liblzma with Meson which work for x86-64 and maybe something else but can be suboptimal or maybe even subtly broken in some other cases. Maybe it's just the way things are, upstreams cannot worry about everything.

> There was something that seemed like action towards getting this resolved last year, but then maintainance stopped again.

That's a showstopper issue indeed. I didn't read in detail but I suppose there's a reason why Libtool was designed to work like it does, it's an old tool and some decisions might be less relevant on today's platforms. The big deal is that Libtool has had lack of developer resources for many years.

Thanks!","",0,0,"","none","Larhzu",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"0570308ddd9c0e39e85597ebc0e31d4fc81d436f","",0,0,"","","","none"
"2023-10-06 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-06 17:02:55","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",14,12,"","","","none"
"2023-10-06 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-10-06 17:02:42","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-10-05 21:00:00","CommitCommentEvent","Larhzu","tukaani-project/xz","2023-10-05 21:09:44","2023-10-05 21:09:44","none",129271457,"Thanks for llvm-windres and improving the GNU windres compatibility! They way GNU windres handles the arguments doesn't feel right but it cannot be fixed in backward compatible way. It was confusing to figure it out as quoting has to work in both /bin/sh and cmd.exe. The docs don't directly say that `--use-temp-file` affects options handling but eventually I ended up trying that too.

Using `MINGW` instead of `WIN32`: I understand the point. Would Cygwin be affected then though? I suppose Cygwin needs the windres workaround too. So should it be `MINGW OR CYGWIN` or `WIN32 AND NOT MSVC`? Or are there more targets that match `WIN32` too? Sorry, I'm quite clueless here.

(There are more Windows-related improments to CMake-based build coming. I pushed some to the [w32_update](https://github.com/tukaani-project/xz/tree/w32_update) branch but it's not finished or polished yet. E.g. build.bash hasn't actually been tested on MSYS2 (and it's hardcoded for GCC too). Completely revised build instructions (CMake + MinGW-w64 + plain Command Prompt) for less experienced developers are coming too. For a long time I thought that CMake-based build would be for MSVC only but in the past two weeks I have started to think that it doesn't lack too many things anymore so maybe it should be polished to make it truly good on a few other common targets too.

I have heard comments saying that we should use Meson but years ago CMake support was requested due to Windows so that was started back then. Maintaining very many build systems isn't practical. Autotools cannot be dropped because those are likely the most supported method on less known platforms (for example, being EBCDIC compatible matters or at least did a few years ago) although Libtool's shared library versioning oddities [have bothered me](https://lists.gnu.org/archive/html/libtool/2011-06/msg00006.html) a long time.)","",0,0,"","none","Larhzu",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"0570308ddd9c0e39e85597ebc0e31d4fc81d436f","",0,0,"","","","none"
"2023-10-05 20:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-10-05 20:00:36","2023-10-05 20:00:36","created",1347909884,"It has macros for the generic versions too so ""for CRC32 and CRC64"" would be better.","src/liblzma/check/crc_common.h",4,4,"","none","Larhzu",64,"Crc32 clmul","[]","open",0,"","[]",0,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","3d1e9bdfe7252e79124cfde8e3e8116a5df10272","[]","[]","crc32-clmul","d3a0c78f9ecf93bfd8ad053a15a17777d233949b","master","01e34aa1171b04f8b28960b1cc6135a903e0c13d",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,239 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       crc_common.h
+/// \brief      Some functions and macros for CRC32CLMUL and CRC64CLMUL",4,"d3a0c78f9ecf93bfd8ad053a15a17777d233949b","25785cf998b8f8c844fbe9a2450f6e8060046bd6",0,0,"","","","none"
"2023-10-05 20:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-10-05 20:46:52","1970-01-01 00:00:00","none",0,"","",0,0,"w32_update","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-10-05 20:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-10-05 20:00:37","2023-10-05 20:00:36","created",0,"Added an implementation for crc32 that makes use of clmul.
Code for this implementation was written by Ilya Kurdyukov and can be found here.
https://github.com/ilyakurdyukov/crc-clmul-sim

Also refactored crc64_clmul to use the new macros created for crc32_clmul.
As well as moved similar functions to crc_clmul_common to eliminate duplicate code.

I tested this on files doubling in size starting from 1 byte up to 1 Gigabyte.
During testing I found that crc32_clmul can run up to 70% faster than crc32_generic,
and has an average speed increase of 58.4% for sizes greater than 16 bytes.

I also used this to test the reworked version of crc64_clmul.
This version of crc64_clmul is an average of 3.9% faster than the original implementation.
This speed increase is due to some inline assembly as well as changing around the order of some if statements. 


## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [X] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
crc32\_fast currently only uses a generic implementation.


## What is the new behavior?
I added an implementation for crc32 that makes use of clmul in crc32_fast.c 
Also refactored crc64_clmul implementation to use the same macros as crc32_clmul


## Does this introduce a breaking change?

- [ ] Yes
- [X] No


## Other information

Here is the output from both tests that gave me the statistics above.

the number of unique files tested on and the number of times the crc is run
decrease as the bytes get larger so the benchmark does not take too long.

The 64 and 32 spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
For example (50% is twice as fast, 200% is twice as slow)
```
64 generic: #		64 clmul: +
32 generic: =		32 clmul: *

#bytes, #files,   #crc's,  64spd+,  32spd+: 0%          50%          100%        150%         200%
    16,  30000, 20648881,  39.96%,  24.24%: |           |      +*    | =    #    |            |
    32,  30000, 12782640,  55.79%,  36.26%: |           |   +*       |  =        #            |
    64,  30000,  7255012,  72.19%,  50.27%: |           +*           | =         |       #    |
   128,  30000,  3890368,  82.53%,  69.13%: |       +*  |            |    =      |            |#
   256,  30000,  2018311,  82.19%,  68.21%: |        +  |            |   =       |            |#
   512,  30000,  1028488,  79.37%,  63.75%: |         + |            |  =        |            #
    1K,  30000,   519217,  78.11%,  62.22%: |         + |            |   =       |           #|
    2K,  30000,   260870,  76.74%,  61.71%: |          +|            |  =        |          # |
    4K,  30000,   130752,  76.78%,  60.15%: |          +|            |  =        |          # |
    8K,  30000,    65456,  76.24%,  60.59%: |          +|            |  =        |          # |
   16K,  30000,    32748,  76.66%,  60.03%: |          +|            |  =        |          # |
   32K,  30000,    16379,  76.78%,  60.04%: |          +|            |  =        |          # |
   64K,  16384,     8190,  76.62%,  59.76%: |          +|            |  =        |          # |
  128K,   8192,     4095,  76.52%,  59.71%: |          +|            |  =        |          # |
  256K,   4096,     2047,  76.32%,  59.78%: |          +|            |  =        |          # |
  512K,   2048,     1023,  84.70%,  60.09%: |        +  |         =  |           |            |       #
    1M,   1024,      511,  76.71%,  60.29%: |          +|            |  =        |          # |
    2M,    512,      255,  76.47%,  59.96%: |          +|            |  =        |          # |
    4M,    256,      127,  76.42%,  60.03%: |          +|            |  =        |          # |
    8M,    128,       63,  76.33%,  60.22%: |          +|            |  =        |          # |
   16M,     64,       31,  76.55%,  60.23%: |          +|            |  =        |          # |
   32M,     32,       15,  76.14%,  60.66%: |          +|            |  =        |          # |
   64M,     16,       10,  76.53%,  59.99%: |          +|            |  =        |          # |
  128M,      8,       10,  76.27%,  60.28%: |          +|            |  =        |          # |
  256M,      4,       10,  76.42%,  59.96%: |          +|            |  =        |          # |
  512M,      2,       10,  76.45%,  60.23%: |          +|            |  =        |          # |
    1G,      1,       10,  76.64%,  60.19%: |          +|            |  =        |          # |
total average:             75.13%,  58.44%

```


The 64old and 64new spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
```
64 generic: #     64 clmul old: +     64 clmul new: *

#bytes, #files,   #crc's, old64spd+, new64spd+: 0%          50%          100%        150%         200%
     1,  30000, 48806446,  -97.328%,  -88.708%, |           | #          | * +       |            |
     2,  30000, 44739242,  -57.943%,  -48.621%, |           |     #      |* +        |            |
     4,  30000, 38347922,   -9.964%,   -4.811%, |           |          #*|+          |            |
     8,  30000, 29826161,   -0.558%,    3.477%, |           |           *+           |            |
    16,  30000, 20648881,   39.017%,   41.582%, |           |        +   |         # |            |
    32,  30000, 12782640,   54.057%,   54.848%, |           |      +     |           |    #       |
    64,  30000,  7255012,   69.551%,   70.777%, |           |  *+        |           |            | #
   128,  30000,  3890368,   81.047%,   81.603%, |          *+            |           |            |            #
   256,  30000,  2018311,   81.129%,   81.619%, |          +|            |           |            |           #
   512,  30000,  1028488,   77.798%,   79.257%, |           *+           |           |            |         #
    1K,  30000,   519217,   75.448%,   77.138%, |           |*+          |           |            |       #
    2K,  30000,   260870,   73.763%,   75.518%, |           |*+          |           |            |     #
    4K,  30000,   130752,   73.392%,   75.773%, |           |* +         |           |            |     #
    8K,  30000,    65456,   74.341%,   76.026%, |           |*+          |           |            |      #
   16K,  30000,    32748,   68.951%,   70.712%, |           |  *+        |           |            | #
   32K,  30000,    16379,   73.761%,   76.129%, |           |*+          |           |            |      #
   64K,  16384,     8190,   74.789%,   76.561%, |           |*+          |           |            |      #
  128K,   8192,     4095,   74.834%,   75.900%, |           |*+          |           |            |      #
  256K,   4096,     2047,   74.508%,   76.488%, |           |*+          |           |            |      #
  512K,   2048,     1023,   74.781%,   75.998%, |           |*+          |           |            |      #
    1M,   1024,      511,   74.523%,   76.610%, |           |*+          |           |            |      #
    2M,    512,      255,   74.871%,   76.690%, |           |*+          |           |            |      #
    4M,    256,      127,   74.656%,   76.658%, |           |*+          |           |            |      #
    8M,    128,       63,   74.151%,   76.085%, |           |*+          |           |            |      #
   16M,     64,       31,   74.802%,   76.263%, |           |*+          |           |            |      #
   32M,     32,       15,   74.671%,   76.244%, |           |*+          |           |            |      #
   64M,     16,       10,   74.626%,   76.459%, |           |*+          |           |            |      #
  128M,      8,       10,   74.738%,   76.497%, |           |*+          |           |            |      #
  256M,      4,       10,   74.395%,   76.110%, |           |*+          |           |            |      #
  512M,      2,       10,   74.904%,   76.549%, |           |*+          |           |            |      #
    1G,      1,       10,   74.709%,   76.477%, |           |*+          |           |            |      #
total average:              57.949%,   60.255%, 
speed increase new vs old:  3.979%
```
","",0,0,"","none","hansjans162",64,"Crc32 clmul","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3d1e9bdfe7252e79124cfde8e3e8116a5df10272","[]","[]","crc32-clmul","d3a0c78f9ecf93bfd8ad053a15a17777d233949b","master","01e34aa1171b04f8b28960b1cc6135a903e0c13d",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-10-05 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-10-05 19:58:56","2023-10-05 19:58:55","created",1749561568,"I'm sorry for the delay. Neither Jia or I have been able to look at this in the past days. :-( We are both happy to see CLMUL version of CRC32 and it's great if you plan to do ARM64 versions too. :-)

The inline function version is definitely nicer when the speed is the same. So those changes should be squashed accordingly, thanks!

For a moment I thought that keeping crc_macros.h as is and adding crc_clmul.h would be nicer but, as Jia has pointed out, crc_common.h defines CRC_GENERIC and such too so I guess it is better this way. Many small bits of code depend on each other in such ways that it seems impossible to make things look very pretty.

In my experience it's nice if file renames are done as separate commits with only the mandatory edits. For example, the `\file` comment at the top would need changing to crc_common.h, and similarly the #include lines in the two .c files, Makefile.inc, and CMakeLists.txt. Any other changes would be in later commit(s).

Small commits in are preferred whenever doing so makes sense.

I wonder if it made sense to have crc_clmul.c with both CRC32 and CRC64 because then the binary wouldn't end up with two copies of is_clmul_supported() and crc_simd_body(). However, it's possible that crc_simd_body() has to be inlined if the function call overhead is too high for tiny input buffers.

I feel it might be good to merge this after the inline function change has been squashed so that we have some good version committed in xz.git. So feel free to try the crc_clmul.c idea if you wish but it's not required for merging.

Have you tested on 32-bit x86? If not, it's fine. :-) If yes: I haven't checked performance on 32-bit x86 in years and wonder if the assembly files still make sense compared to what GCC and Clang can do (for processors that don't support CLMUL). Those files were written in GCC 3.3/3.4 times. It shouldn't be hard to make 32-bit x86 autodetect between the assembly code and CLMUL so I can do it if it is worth it.

Thanks!","",0,0,"","none","Larhzu",64,"Crc32 clmul","[]","open",0,"","[]",4,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-30 19:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-09-30 19:22:05","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_lfs","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-27 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-27 20:20:40","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,0,"","","","none"
"2023-09-27 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-27 17:52:09","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/w32_update","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-27 16:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-27 16:58:13","1970-01-01 00:00:00","none",0,"","",0,0,"w32_update","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-26 21:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-26 21:59:43","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_lfs","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-26 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 20:17:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/clock_gettime","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",31,6,"","","","none"
"2023-09-26 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 20:17:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",27,2,"","","","none"
"2023-09-26 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 19:50:54","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,3,"","","","none"
"2023-09-26 18:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-09-26 18:48:56","2023-09-26 18:48:56","created",1337645597,"I kept searching but I cannot find anything to confirm my memory. So I apologize for the noise. I updated the comment in the master.","src/liblzma/check/crc32_table.c",12,23,"","none","Larhzu",64,"Crc32 clmul","[]","open",0,"","[]",0,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","02b70e056186a4e754742dc67d00f165006c4367","[]","[]","crc32-clmul","9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","master","519e47c2818acde571fadc79551294527fe6cc22",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,11 +12,24 @@
 
 #include ""common.h""
 
+
+// FIXME: Compared to crc32_fast.c this has to check for __x86_64__ too
+// so that in 32-bit builds crc32_x86.S won't break due to a missing table.
+#if (defined(__x86_64__) && defined(__SSSE3__) \
+			&& defined(__SSE4_1__) && defined(__PCLMUL__)) \
+		|| (defined(__e2k__) && __iset__ >= 6)
+// No table needed but something has to be exported to keep some toolchains
+// happy. Also use a declaration to silence compiler warnings.
+extern const char lzma_crc32_dummy;",12,"9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","d49c14a92077e2cf8055d06e7dad204c40410f30",0,0,"","","","none"
"2023-09-26 18:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-09-26 18:48:57","2023-09-26 18:48:56","created",0,"Added an implementation for crc32 that makes use of clmul.
Code for this implementation was written by Ilya Kurdyukov and can be found here.
https://github.com/ilyakurdyukov/crc-clmul-sim

Also refactored crc64_clmul to use the new macros created for crc32_clmul.
As well as moved similar functions to crc_clmul_common to eliminate duplicate code.

I tested this on files doubling in size starting from 1 byte up to 1 Gigabyte.
During testing I found that crc32_clmul can run up to 70% faster than crc32_generic,
and has an average speed increase of 58.4% for sizes greater than 16 bytes.

I also used this to test the reworked version of crc64_clmul.
This version of crc64_clmul is an average of 3.9% faster than the original implementation.
This speed increase is due to some inline assembly as well as changing around the order of some if statements. 


## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [X] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
crc32\_fast currently only uses a generic implementation.


## What is the new behavior?
I added an implementation for crc32 that makes use of clmul in crc32_fast.c 
Also refactored crc64_clmul implementation to use the same macros as crc32_clmul


## Does this introduce a breaking change?

- [ ] Yes
- [X] No


## Other information

Here is the output from both tests that gave me the statistics above.

the number of unique files tested on and the number of times the crc is run
decrease as the bytes get larger so the benchmark does not take too long.

The 64 and 32 spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
For example (50% is twice as fast, 200% is twice as slow)
```
64 generic: #		64 clmul: +
32 generic: =		32 clmul: *

#bytes, #files,   #crc's,  64spd+,  32spd+: 0%          50%          100%        150%         200%
    16,  30000, 20648881,  39.96%,  24.24%: |           |      +*    | =    #    |            |
    32,  30000, 12782640,  55.79%,  36.26%: |           |   +*       |  =        #            |
    64,  30000,  7255012,  72.19%,  50.27%: |           +*           | =         |       #    |
   128,  30000,  3890368,  82.53%,  69.13%: |       +*  |            |    =      |            |#
   256,  30000,  2018311,  82.19%,  68.21%: |        +  |            |   =       |            |#
   512,  30000,  1028488,  79.37%,  63.75%: |         + |            |  =        |            #
    1K,  30000,   519217,  78.11%,  62.22%: |         + |            |   =       |           #|
    2K,  30000,   260870,  76.74%,  61.71%: |          +|            |  =        |          # |
    4K,  30000,   130752,  76.78%,  60.15%: |          +|            |  =        |          # |
    8K,  30000,    65456,  76.24%,  60.59%: |          +|            |  =        |          # |
   16K,  30000,    32748,  76.66%,  60.03%: |          +|            |  =        |          # |
   32K,  30000,    16379,  76.78%,  60.04%: |          +|            |  =        |          # |
   64K,  16384,     8190,  76.62%,  59.76%: |          +|            |  =        |          # |
  128K,   8192,     4095,  76.52%,  59.71%: |          +|            |  =        |          # |
  256K,   4096,     2047,  76.32%,  59.78%: |          +|            |  =        |          # |
  512K,   2048,     1023,  84.70%,  60.09%: |        +  |         =  |           |            |       #
    1M,   1024,      511,  76.71%,  60.29%: |          +|            |  =        |          # |
    2M,    512,      255,  76.47%,  59.96%: |          +|            |  =        |          # |
    4M,    256,      127,  76.42%,  60.03%: |          +|            |  =        |          # |
    8M,    128,       63,  76.33%,  60.22%: |          +|            |  =        |          # |
   16M,     64,       31,  76.55%,  60.23%: |          +|            |  =        |          # |
   32M,     32,       15,  76.14%,  60.66%: |          +|            |  =        |          # |
   64M,     16,       10,  76.53%,  59.99%: |          +|            |  =        |          # |
  128M,      8,       10,  76.27%,  60.28%: |          +|            |  =        |          # |
  256M,      4,       10,  76.42%,  59.96%: |          +|            |  =        |          # |
  512M,      2,       10,  76.45%,  60.23%: |          +|            |  =        |          # |
    1G,      1,       10,  76.64%,  60.19%: |          +|            |  =        |          # |
total average:             75.13%,  58.44%

```


The 64old and 64new spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
```
64 generic: #     64 clmul old: +     64 clmul new: *

#bytes, #files,   #crc's, old64spd+, new64spd+: 0%          50%          100%        150%         200%
     1,  30000, 48806446,  -97.328%,  -88.708%, |           | #          | * +       |            |
     2,  30000, 44739242,  -57.943%,  -48.621%, |           |     #      |* +        |            |
     4,  30000, 38347922,   -9.964%,   -4.811%, |           |          #*|+          |            |
     8,  30000, 29826161,   -0.558%,    3.477%, |           |           *+           |            |
    16,  30000, 20648881,   39.017%,   41.582%, |           |        +   |         # |            |
    32,  30000, 12782640,   54.057%,   54.848%, |           |      +     |           |    #       |
    64,  30000,  7255012,   69.551%,   70.777%, |           |  *+        |           |            | #
   128,  30000,  3890368,   81.047%,   81.603%, |          *+            |           |            |            #
   256,  30000,  2018311,   81.129%,   81.619%, |          +|            |           |            |           #
   512,  30000,  1028488,   77.798%,   79.257%, |           *+           |           |            |         #
    1K,  30000,   519217,   75.448%,   77.138%, |           |*+          |           |            |       #
    2K,  30000,   260870,   73.763%,   75.518%, |           |*+          |           |            |     #
    4K,  30000,   130752,   73.392%,   75.773%, |           |* +         |           |            |     #
    8K,  30000,    65456,   74.341%,   76.026%, |           |*+          |           |            |      #
   16K,  30000,    32748,   68.951%,   70.712%, |           |  *+        |           |            | #
   32K,  30000,    16379,   73.761%,   76.129%, |           |*+          |           |            |      #
   64K,  16384,     8190,   74.789%,   76.561%, |           |*+          |           |            |      #
  128K,   8192,     4095,   74.834%,   75.900%, |           |*+          |           |            |      #
  256K,   4096,     2047,   74.508%,   76.488%, |           |*+          |           |            |      #
  512K,   2048,     1023,   74.781%,   75.998%, |           |*+          |           |            |      #
    1M,   1024,      511,   74.523%,   76.610%, |           |*+          |           |            |      #
    2M,    512,      255,   74.871%,   76.690%, |           |*+          |           |            |      #
    4M,    256,      127,   74.656%,   76.658%, |           |*+          |           |            |      #
    8M,    128,       63,   74.151%,   76.085%, |           |*+          |           |            |      #
   16M,     64,       31,   74.802%,   76.263%, |           |*+          |           |            |      #
   32M,     32,       15,   74.671%,   76.244%, |           |*+          |           |            |      #
   64M,     16,       10,   74.626%,   76.459%, |           |*+          |           |            |      #
  128M,      8,       10,   74.738%,   76.497%, |           |*+          |           |            |      #
  256M,      4,       10,   74.395%,   76.110%, |           |*+          |           |            |      #
  512M,      2,       10,   74.904%,   76.549%, |           |*+          |           |            |      #
    1G,      1,       10,   74.709%,   76.477%, |           |*+          |           |            |      #
total average:              57.949%,   60.255%, 
speed increase new vs old:  3.979%
```
","",0,0,"","none","hansjans162",64,"Crc32 clmul","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","02b70e056186a4e754742dc67d00f165006c4367","[]","[]","crc32-clmul","9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","master","519e47c2818acde571fadc79551294527fe6cc22",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-09-26 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 18:47:28","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-26 17:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-09-26 17:10:47","2023-09-26 17:10:48","created",1337543950,"Unfortunately I cannot find a reference right now but I have a feeling that some toolchain on some proprietary UNIX-like OS didn't like object files that don't export anything. The trick for the Windows build is fine because it's not a problem there with the GNU toolchain. That is, an empty translation unit in C and an object file that exports nothing are related but distinct issues. typedef works for avoiding empty translation units but not empty object files.

I might remember wrong and in that case I'm sorry for the noise. But if I'm wrong and the commit in the master is retained then its comment should be updated as no symbols are exported after that commit.","src/liblzma/check/crc32_table.c",12,23,"","none","Larhzu",64,"Crc32 clmul","[]","open",0,"","[]",0,"CONTRIBUTOR","1970-01-01 00:00:00","1970-01-01 00:00:00","3126c60d923f711abd06e5a87f4295b057808479","[]","[]","crc32-clmul","9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","master","519e47c2818acde571fadc79551294527fe6cc22",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,11 +12,24 @@
 
 #include ""common.h""
 
+
+// FIXME: Compared to crc32_fast.c this has to check for __x86_64__ too
+// so that in 32-bit builds crc32_x86.S won't break due to a missing table.
+#if (defined(__x86_64__) && defined(__SSSE3__) \
+			&& defined(__SSE4_1__) && defined(__PCLMUL__)) \
+		|| (defined(__e2k__) && __iset__ >= 6)
+// No table needed but something has to be exported to keep some toolchains
+// happy. Also use a declaration to silence compiler warnings.
+extern const char lzma_crc32_dummy;",12,"9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","d49c14a92077e2cf8055d06e7dad204c40410f30",0,0,"","","","none"
"2023-09-26 17:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-09-26 17:10:48","2023-09-26 17:10:48","created",0,"Added an implementation for crc32 that makes use of clmul.
Code for this implementation was written by Ilya Kurdyukov and can be found here.
https://github.com/ilyakurdyukov/crc-clmul-sim

Also refactored crc64_clmul to use the new macros created for crc32_clmul.
As well as moved similar functions to crc_clmul_common to eliminate duplicate code.

I tested this on files doubling in size starting from 1 byte up to 1 Gigabyte.
During testing I found that crc32_clmul can run up to 70% faster than crc32_generic,
and has an average speed increase of 58.4% for sizes greater than 16 bytes.

I also used this to test the reworked version of crc64_clmul.
This version of crc64_clmul is an average of 3.9% faster than the original implementation.
This speed increase is due to some inline assembly as well as changing around the order of some if statements. 


## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [X] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
crc32\_fast currently only uses a generic implementation.


## What is the new behavior?
I added an implementation for crc32 that makes use of clmul in crc32_fast.c 
Also refactored crc64_clmul implementation to use the same macros as crc32_clmul


## Does this introduce a breaking change?

- [ ] Yes
- [X] No


## Other information

Here is the output from both tests that gave me the statistics above.

the number of unique files tested on and the number of times the crc is run
decrease as the bytes get larger so the benchmark does not take too long.

The 64 and 32 spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
For example (50% is twice as fast, 200% is twice as slow)
```
64 generic: #		64 clmul: +
32 generic: =		32 clmul: *

#bytes, #files,   #crc's,  64spd+,  32spd+: 0%          50%          100%        150%         200%
    16,  30000, 20648881,  39.96%,  24.24%: |           |      +*    | =    #    |            |
    32,  30000, 12782640,  55.79%,  36.26%: |           |   +*       |  =        #            |
    64,  30000,  7255012,  72.19%,  50.27%: |           +*           | =         |       #    |
   128,  30000,  3890368,  82.53%,  69.13%: |       +*  |            |    =      |            |#
   256,  30000,  2018311,  82.19%,  68.21%: |        +  |            |   =       |            |#
   512,  30000,  1028488,  79.37%,  63.75%: |         + |            |  =        |            #
    1K,  30000,   519217,  78.11%,  62.22%: |         + |            |   =       |           #|
    2K,  30000,   260870,  76.74%,  61.71%: |          +|            |  =        |          # |
    4K,  30000,   130752,  76.78%,  60.15%: |          +|            |  =        |          # |
    8K,  30000,    65456,  76.24%,  60.59%: |          +|            |  =        |          # |
   16K,  30000,    32748,  76.66%,  60.03%: |          +|            |  =        |          # |
   32K,  30000,    16379,  76.78%,  60.04%: |          +|            |  =        |          # |
   64K,  16384,     8190,  76.62%,  59.76%: |          +|            |  =        |          # |
  128K,   8192,     4095,  76.52%,  59.71%: |          +|            |  =        |          # |
  256K,   4096,     2047,  76.32%,  59.78%: |          +|            |  =        |          # |
  512K,   2048,     1023,  84.70%,  60.09%: |        +  |         =  |           |            |       #
    1M,   1024,      511,  76.71%,  60.29%: |          +|            |  =        |          # |
    2M,    512,      255,  76.47%,  59.96%: |          +|            |  =        |          # |
    4M,    256,      127,  76.42%,  60.03%: |          +|            |  =        |          # |
    8M,    128,       63,  76.33%,  60.22%: |          +|            |  =        |          # |
   16M,     64,       31,  76.55%,  60.23%: |          +|            |  =        |          # |
   32M,     32,       15,  76.14%,  60.66%: |          +|            |  =        |          # |
   64M,     16,       10,  76.53%,  59.99%: |          +|            |  =        |          # |
  128M,      8,       10,  76.27%,  60.28%: |          +|            |  =        |          # |
  256M,      4,       10,  76.42%,  59.96%: |          +|            |  =        |          # |
  512M,      2,       10,  76.45%,  60.23%: |          +|            |  =        |          # |
    1G,      1,       10,  76.64%,  60.19%: |          +|            |  =        |          # |
total average:             75.13%,  58.44%

```


The 64old and 64new spd+ show the percentage speed increase over the generic.
The percentage on the graph show the combined average for all types.
```
64 generic: #     64 clmul old: +     64 clmul new: *

#bytes, #files,   #crc's, old64spd+, new64spd+: 0%          50%          100%        150%         200%
     1,  30000, 48806446,  -97.328%,  -88.708%, |           | #          | * +       |            |
     2,  30000, 44739242,  -57.943%,  -48.621%, |           |     #      |* +        |            |
     4,  30000, 38347922,   -9.964%,   -4.811%, |           |          #*|+          |            |
     8,  30000, 29826161,   -0.558%,    3.477%, |           |           *+           |            |
    16,  30000, 20648881,   39.017%,   41.582%, |           |        +   |         # |            |
    32,  30000, 12782640,   54.057%,   54.848%, |           |      +     |           |    #       |
    64,  30000,  7255012,   69.551%,   70.777%, |           |  *+        |           |            | #
   128,  30000,  3890368,   81.047%,   81.603%, |          *+            |           |            |            #
   256,  30000,  2018311,   81.129%,   81.619%, |          +|            |           |            |           #
   512,  30000,  1028488,   77.798%,   79.257%, |           *+           |           |            |         #
    1K,  30000,   519217,   75.448%,   77.138%, |           |*+          |           |            |       #
    2K,  30000,   260870,   73.763%,   75.518%, |           |*+          |           |            |     #
    4K,  30000,   130752,   73.392%,   75.773%, |           |* +         |           |            |     #
    8K,  30000,    65456,   74.341%,   76.026%, |           |*+          |           |            |      #
   16K,  30000,    32748,   68.951%,   70.712%, |           |  *+        |           |            | #
   32K,  30000,    16379,   73.761%,   76.129%, |           |*+          |           |            |      #
   64K,  16384,     8190,   74.789%,   76.561%, |           |*+          |           |            |      #
  128K,   8192,     4095,   74.834%,   75.900%, |           |*+          |           |            |      #
  256K,   4096,     2047,   74.508%,   76.488%, |           |*+          |           |            |      #
  512K,   2048,     1023,   74.781%,   75.998%, |           |*+          |           |            |      #
    1M,   1024,      511,   74.523%,   76.610%, |           |*+          |           |            |      #
    2M,    512,      255,   74.871%,   76.690%, |           |*+          |           |            |      #
    4M,    256,      127,   74.656%,   76.658%, |           |*+          |           |            |      #
    8M,    128,       63,   74.151%,   76.085%, |           |*+          |           |            |      #
   16M,     64,       31,   74.802%,   76.263%, |           |*+          |           |            |      #
   32M,     32,       15,   74.671%,   76.244%, |           |*+          |           |            |      #
   64M,     16,       10,   74.626%,   76.459%, |           |*+          |           |            |      #
  128M,      8,       10,   74.738%,   76.497%, |           |*+          |           |            |      #
  256M,      4,       10,   74.395%,   76.110%, |           |*+          |           |            |      #
  512M,      2,       10,   74.904%,   76.549%, |           |*+          |           |            |      #
    1G,      1,       10,   74.709%,   76.477%, |           |*+          |           |            |      #
total average:              57.949%,   60.255%, 
speed increase new vs old:  3.979%
```
","",0,0,"","none","hansjans162",64,"Crc32 clmul","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3126c60d923f711abd06e5a87f4295b057808479","[]","[]","crc32-clmul","9d7e8e7ee1c5d81f27bf8efee28521d0882808e9","master","519e47c2818acde571fadc79551294527fe6cc22",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-09-26 16:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-26 16:11:56","1970-01-01 00:00:00","none",0,"","",0,0,"build_werror","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-26 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 16:40:26","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-09-26 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 16:34:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/build_werror","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-26 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 14:25:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-26 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 12:02:58","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-26 10:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-26 10:53:44","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-09-24 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 22:50:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,2,"","","","none"
"2023-09-24 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 22:50:09","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/clock_gettime","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",8,6,"","","","none"
"2023-09-24 15:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-09-24 15:04:37","1970-01-01 00:00:00","none",0,"","",0,0,"xz_w2k","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-24 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 15:04:24","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,0,"","","","none"
"2023-09-24 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 15:00:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/clock_gettime","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,3,"","","","none"
"2023-09-24 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 15:00:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,2,"","","","none"
"2023-09-24 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 14:48:29","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_w2k","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,2,"","","","none"
"2023-09-24 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-24 14:10:25","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-23 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-23 21:21:44","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/clock_gettime","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-23 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-23 20:58:54","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuklib_integer_memcpy","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-23 00:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-23 00:26:00","1970-01-01 00:00:00","none",0,"","",0,0,"clock_gettime","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-22 23:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-22 23:22:13","1970-01-01 00:00:00","none",0,"","",0,0,"tuklib_integer_memcpy","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-22 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-22 18:27:05","2023-09-22 18:27:05","created",1731869205,"xz_w2k includes simple commits that remove pre-W2k support. Very likely it will be merged but I didn't want to put it to master directly.

The getopt.in.h question will be reconsidered. I don't know yet if it will be changed.

I think everything from this PR and discussion has been handled now. Thanks a lot!","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","closed",0,"","[]",15,"CONTRIBUTOR","2023-09-06 09:10:46","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-22 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-09-22 17:32:35","1970-01-01 00:00:00","none",0,"","",0,0,"xz_for_msvc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-22 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-22 17:31:10","2023-09-22 17:31:09","created",1731790698,"I merged xz_for_msvc to master except the tuklib_physmem W2k commits.","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","closed",0,"","[]",14,"CONTRIBUTOR","2023-09-06 09:10:46","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-22 17:30:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",24,0,"","","","none"
"2023-09-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-22 17:21:02","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-22 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-22 17:11:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",24,24,"","","","none"
"2023-09-21 23:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-21 23:59:23","2023-09-21 23:59:22","created",1730509933,"Thanks! Now I realized that I had misidentified the problem. `S_ISREG` is enough but it has to be used with `_fstat64`. With `_stat64`, `con` is a regular file. So the method used for DJGPP is at the wrong location for Windows.

I pushed a commit to xz_for_msvc which should fix it. I tested it with MinGW-w64.

There is another special case in the DJGPP-specific code but I think it's not needed on Windows. It's possible that the output filename is the same as the input filename. On DOS with only 8.3 names it can happen if an overlong name is given on the command line. But it can happen on modern Windows too if 8.3 names are enabled. For example:

```
echo foo | xz > foobar~1zoo
xz --suffix=zoo --decompress --force foobar~1zoo
```

It should fail because it cannot remove `foobar~1` because the file is already open. It's the same file as `foobar~1zoo` due to 8.3 names.
","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","closed",0,"","[]",13,"NONE","2023-09-06 09:10:46","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-21 23:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-21 23:45:46","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-21 21:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-21 21:09:58","2023-09-21 21:09:57","created",1730306555,"The getopt.in.h change is in xz_for_msvc branch now. Thanks!","",0,0,"","none","Larhzu",63,"Fix getopt.in.h for MSVC","[]","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-21 21:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-21 21:12:38","2023-09-21 21:12:37","created",1730309551,"Thanks again for testing!

I included the unistd.h fix from PR 63 in the xz_for_msvc branch.

With CMake 3.27 and its new default [policy CMP0149](https://cmake.org/cmake/help/latest/policy/CMP0149.html) the xz_for_msvc branch uses the latest Windows SDK by default.

CMakeLists.txt currently requires a C99 compiler:

```
set(CMAKE_C_STANDARD 99)
set(CMAKE_C_STANDARD_REQUIRED ON)
```

If the first line was set to C11 and the second line was omitted then CMake would attempt to find a C11 compiler but would accept older standard too if C11 isn't available. So that would be a way to get C11 mode when using new enough MSVC. But maybe it's not nice if it limits SDK choices.

Since it works now, maybe it's fine to leave it as it is.

About he commit to tuklib_physmem.c that avoids building the pre-W2k code: I suspect that this

```
#if defined(_WIN32_WINNT_WIN2K) && _WIN32_WINNT >= _WIN32_WINNT_WIN2K
```

isn't correct. Now the old code will never be built.

`_WIN32_WINNT` is about exposing newer features from the API headers, it doesn't mean that the program will automatically require that version of Windows. Earlier the builds used `#define _WIN32_WINNT 0x0500` (which is `_WIN32_WINNT_WIN2K`) to make `MEMORYSTATUSEX` visible in the API headers. Those binaries could still run even on Win95 if msvcrt.dll was available because `GlobalMemoryStatusEx` was loaded dynamically.

Maybe at this point it could be best to just omit pre-W2K support from that file. Even when it was written, it was just a fun distraction to check if Windows build of xz could easily run even on Win95 and it did.

The win95 threading option, despite its name, exist for WinXP support. Those APIs just happen to be in Win95 already. The threading APIs from WinVista are closer to pthreads than the older APIs but, as far as I know, there shouldn't be any significant difference in practice in case of liblzma since it needs only a small subset of features. Requiring WinVista would simplify things though but on the other hand the support for the ancient things already exists and works fine.

`GetTickCount64` in mytime.c needs WinVista so MSVC builds of the xz command line tool will need at least WinVista.

`GetFileType` needs a `HANDLE` so one would first need `CreateFile` and so on. It's unfortunate if `_stat64` doesn't return any info in `st_mode` or `st_dev` or other member. I think I won't work on this problem now. If I have understood correctly, it helps slightly that the problem can only occur if using `--suffix` as the default suffixes have a dot and thus if the input file is valid then the output is too since both `con` and `con.xz` are invalid names for regular files.
","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","closed",0,"","[]",11,"NONE","2023-09-06 09:10:46","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-21 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-21 21:06:38","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",29,25,"","","","none"
"2023-09-21 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-21 16:21:13","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",21,21,"","","","none"
"2023-09-19 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-19 11:04:22","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-09-18 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-18 19:50:19","2023-09-18 19:50:18","created",1724271696,"> Would you consider renaming ""getopt.in.h"" to ""getopt.h""?

getopt.in.h is done like that in Gnulib. A package that uses Gnulib may have many .in.h files. Which files will be needed is detected when running `configure` and copied to .h name. Gnulib has replacements for many system headers to aid portability. With the .in.h -> .h method only the specificic headers can be overriden.

Obviously XZ Utils only include getopt from Gnulib at the moment. In the early days I didn't know if more modules would be needed. So moving the getopt files to lib/getopt/ and putting that to include path when needed could be fine if we are certain that the module list won't grow. If many Gnulib modules (or similar things from other sources) were needed then this wouldn't work because the include path would grow too long and the modules can have intermodule dependencies too.

I will discuss this with Jia. We plan to update getopt code with the current Gnulib too (it's still LGPLv2.1 so no license changes).

I have seen your other messages. I will get back to them later this week.
","",0,0,"","none","Larhzu",63,"Fix getopt.in.h for MSVC","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-18 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-18 16:37:28","2023-09-18 16:37:27","created",1723915860,"The CVE has been marked as disputed so I'm closing this issue.","",0,0,"","none","Larhzu",61,"Fix for CVE-2020-22916","[]","closed",0,"","[]",4,"NONE","2023-09-18 16:37:27","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-18 16:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2023-09-18 16:37:28","2023-09-18 16:37:27","closed",0,"https://nvd.nist.gov/vuln/detail/CVE-2020-22916

This link seems to be inaccessible：https://github.com/snappyJack/CVE-request-XZ-5.2.5-has-denial-of-service-vulnerability

Is there a fix for CVE xz?
[1] If not, what is the repair plan for xz?
[2] If yes, can you indicate which submissions fix CVE-2020-22916?


","",0,0,"","none","TheStoryEnd",61,"Fix for CVE-2020-22916","[]","closed",0,"","[]",4,"NONE","2023-09-18 16:37:27","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-15 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-15 17:16:20","2023-09-15 17:16:19","created",1721603163,"The snappyJack repository is available again. It contains a corrupt .lzma file which uses a tiny 256-byte dictionary. So decompression needs very little memory. The reporter claims that decompressing it ""could cause endless output"".

Both XZ Utils and even the long-deprecated LZMA Utils produce 114,881,179 bytes of output from the payload before reporting an error. This is not ""endless output"". The decompression speed is good too.

There is no denial of service or other bug with this file.
","",0,0,"","none","Larhzu",61,"Fix for CVE-2020-22916","[]","open",0,"","[]",3,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-14 13:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-14 13:47:56","2023-09-14 13:47:55","created",1719489932,"Thanks!

It's fixed in the master branch now. The problem is that `crc64_clmul` uses 16-byte-aligned reads and this unavoidably trips the address sanitizer. The CI builds used `-fsanitize=address` but ci.yml worked around the problem with `--disable-clmul-crc`. Now there is `__attribute__((__no_sanitize_address__))` so the workaround isn't needed anymore.

After 5.4.x (including the current master branch) you will need `--disable-ifunc` to make `-fsanitize=address` work. This is because `__attribute__((__ifunc(..)))` isn't compatible with address sanitizer. See [this](https://sourceware.org/glibc/wiki/GNU_IFUNC), search for ""asan"". The ifunc code likely won't be included in 5.4.x releases.
","",0,0,"","none","Larhzu",62,"[Bug]: test failure because of a global-buffer-overflow","['bug']","closed",0,"","[]",1,"NONE","2023-09-14 13:43:08","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-14 13:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2023-09-14 13:43:09","2023-09-14 13:43:08","closed",0,"### Describe the bug

Our [Gentoo Tinderbox](https://blogs.gentoo.org/ago/2020/07/04/gentoo-tinderbox/) reported a test failure at [bug 914170](https://bugs.gentoo.org/914170)

By looking at test-suite.log I can see:

```
==1161==ERROR: AddressSanitizer: global-buffer-overflow on address 0x5614ecd418a0 at pc 0x7f8d20216905 bp 0x7ffd6a482040 sp 0x7ffd6a482038
READ of size 16 at 0x5614ecd418a0 thread T0
    #0 0x7f8d20216904 in crc64_clmul /var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/src/liblzma/check/crc64_fast.c:284:40
    #1 0x5614ecd2a53c in test_lzma_crc64 /var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/tests/test_check.c:106:2
    #2 0x5614ecd2a237 in tuktest_run_test /var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/tests/tuktest.h:596:4
    #3 0x5614ecd29cec in main /var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/tests/test_check.c:383:2
    #4 0x7f8d1fe23c89  (/lib64/libc.so.6+0x23c89)
    #5 0x7f8d1fe23d44 in __libc_start_main (/lib64/libc.so.6+0x23d44)
    #6 0x5614ecc553f0 in _start (/var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4-abi_x86_64.amd64/tests/.libs/test_check+0x203f0)

0x5614ecd418a0 is located 32 bytes before global variable '.str.42' defined in '/var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/tests/test_check.c:78' (0x5614ecd418c0) of size 51
  '.str.42' is ascii string 'assert_uint: '%s == %lu' but expected '... %s %lu''
0x5614ecd418a9 is located 0 bytes after global variable 'test_string' defined in '/var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/tests/test_check.c:22' (0x5614ecd418a0) of size 9
SUMMARY: AddressSanitizer: global-buffer-overflow /var/tmp/portage/app-arch/xz-utils-5.4.4/work/xz-5.4.4/src/liblzma/check/crc64_fast.c:284:40 in crc64_clmul
Shadow bytes around the buggy address:
  0x5614ecd41600: 07 f9 f9 f9 f9 f9 f9 f9 00 00 00 05 f9 f9 f9 f9
  0x5614ecd41680: 00 00 00 03 f9 f9 f9 f9 00 00 00 00 00 00 00 04
  0x5614ecd41700: f9 f9 f9 f9 06 f9 f9 f9 06 f9 f9 f9 07 f9 f9 f9
  0x5614ecd41780: 00 07 f9 f9 00 04 f9 f9 00 02 f9 f9 00 00 00 00
  0x5614ecd41800: 00 06 f9 f9 f9 f9 f9 f9 00 00 00 00 00 02 f9 f9
=>0x5614ecd41880: f9 f9 f9 f9[00]01 f9 f9 00 00 00 00 00 00 03 f9
  0x5614ecd41900: f9 f9 f9 f9 00 00 00 00 00 00 f9 f9 f9 f9 f9 f9
  0x5614ecd41980: 03 f9 f9 f9 00 04 f9 f9 00 00 00 00 00 00 07 f9
  0x5614ecd41a00: f9 f9 f9 f9 04 f9 f9 f9 00 00 00 02 f9 f9 f9 f9
  0x5614ecd41a80: 00 00 00 00 00 00 f9 f9 f9 f9 f9 f9 00 00 00 00
  0x5614ecd41b00: 00 00 07 f9 f9 f9 f9 f9 00 00 00 03 f9 f9 f9 f9
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
==1161==ABORTING
```

I didn't look deeply into this issue so I don't know if the bug is in the unittest itself or in the involed libraries/daemons, if so please check for any security implications. I'm not doing a private report since it is already public on gentoo bugzilla.
If I can do further, please let me know.

### Version

5.4.4

### Operating System

Gentoo

### Relevant log output

_No response_","",0,0,"","none","asarubbo",62,"[Bug]: test failure because of a global-buffer-overflow","['bug']","closed",0,"","[]",0,"NONE","2023-09-14 13:43:08","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-14 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-14 13:43:08","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-09-13 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-13 18:11:26","2023-09-13 18:11:25","created",1718095305,"There's now a little more information in the NVD. The [entry in Debian](https://security-tracker.debian.org/tracker/CVE-2020-22916) is somewhat informative:

> Bogus CVE, original URL is gone and resource limits are a natural constraint for any unpacker

That makes me wonder if it could have been a file which uses a 4 GiB LZMA2 dictionary and thus needs lots of RAM even in single-threaded mode. xz has had memory usage limiting options for such files since the first stable version because high memory usage could be a denial of service. Strict limits (which would make xz refuse to decompress) aren't enabled by default because of the strong feedback I got before 5.0.0 was released: a too low limit can also result in a denial of service. The [Memory usage](https://tukaani.org/xz/man/xz.1.html#DESCRIPTION:_Memory_usage) section on the xz man page has been there since 5.0.0 too.

This was just a guess; the CVE could be about something else, of course. With the information I currently have, I consider this CVE to be incorrect (not a bug or a security issue).
","",0,0,"","none","Larhzu",61,"Fix for CVE-2020-22916","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-13 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-13 18:13:22","2023-09-13 18:13:21","created",1718097831,"Thanks for testing! There are more commits in `xz_for_msvc` now, including CMake support. It would be awesome if you could test it with MSVC again. If you don't have time etc. then feel free to say so or ignore this. :-)

I think xzdec should build now with VS2013. xz is set to require VS2015 (_MSC_VER >= 1900, that is, MSVC_VERSION >= 1900 in CMake). I don't know if a more recent VS version should be recommended in the docs, like, if there are compatibility fixes that matter.

`_Noreturn` needs `/std:c11` or `/std:c17`. CMake likely doesn't set it because CMakeLists.txt only requires a C99 compiler. There is `__declspec(noreturn)` too for this case.

I wonder if C11/C17 mode would be preferred for other reasons, for example, if standards conformance would be stricter and thus risk of weird bugs would be lower. [Microsoft docs](https://learn.microsoft.com/en-us/cpp/overview/install-c17-support?view=msvc-170) say that C11/C17 needs an updated Windows SDK and UCRT though. I don't have much clue about these. Would using C11/C17 mode affect how old Windows versions can run the resulting binaries?

About `con` and friends. At least with MinGW-w64 builds it seems to be a problem (possibly a security issue). `xz -d -S_xz con_xz` decompresses to console even though `open` is used with `O_EXCL`. I'm not sure how to fix. I would expect Windows to have an API to check for problematic filenames instead of apps needing to roll their own checking code. The code used with DJGPP isn't compatible with anything else.
","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","closed",0,"","[]",7,"NONE","2023-09-06 09:10:46","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-12 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-12 20:54:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",24,22,"","","","none"
"2023-09-11 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-11 16:08:40","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2023-09-08 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-08 21:16:51","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2023-09-08 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-09-08 16:18:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/xz_for_msvc","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,4,"","","","none"
"2023-09-05 20:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-09-05 20:35:37","1970-01-01 00:00:00","none",0,"","",0,0,"xz_for_msvc","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-09-05 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-09-05 20:37:58","2023-09-05 20:37:57","created",1707277854,"Thanks for the updates!

Based on this PR I created a branch `xz_for_msvc`. I put some of the commits in your name even though they were modified a little. If you prefer otherwise please let me know.

Unless I missed something, `xz_for_msvc` should have everything from this PR except `__declspec(noreturn)` and the VS2013 fallback for `snprintf`.

I feel the noreturn could be handled in a more generic way. `noreturn` from `<stdnoreturn.h>` could be ideal. According to docs, it seems to be supported by VS2015 too. It's currently not used in XZ Utils, only the GNU C `__attribute__((__noreturn__))` is, but this could be changed.

Unless there is a good reason, I feel VS2013 support shouldn't be added to the command line tools to keep the MSVC patches as simple as easily possible. By the time this code is in a stable XZ Utils release, VS2013 will only have 5-7 months of support remaining (if April 2024 is the true end date for VS2013 support).

The changes to file_io.* I made quite differently and it's quite possible that my approach cannot work. It would be great if you could test it and tell if it works or can be made to work. Otherwise I will adapt your version from this PR.

DOS/DJGPP build checks for special filenames like `prn` in file_io.c which could happen in weird cases like `xz -S_xz -d prn_xz`. I wonder if something like that should be done on Windows builds too (not just MSVC).","",0,0,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",5,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-08-31 16:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 16:51:34","2023-08-31 16:51:34","created",1311924159,"I changed the code in the master branch so that these pragmas shouldn't be needed anymore.","src/xz/util.c",17,151,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -142,6 +146,13 @@ round_up_to_mib(uint64_t n)
 }
 
 
+#ifdef _MSC_VER
+#pragma warning(push)
+#pragma warning(disable: 4474) // 'snprintf' : too many arguments passed for format string",17,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","cbba399e8581f1e38d31bf3f2b886e2e20d976dc",0,0,"","","","none"
"2023-08-31 16:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 16:51:35","2023-08-31 16:51:34","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-31 16:50:31","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:28:55","2023-08-31 15:28:55","created",1311816823,"Perhaps it's fine to use plain `int` here as that is what `_open` needs. Then there is no need to `typedef int mode_t` at all. The only other `mode_t` occurrence isn't used on Windows.","src/xz/file_io.c",54,961,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -933,7 +957,11 @@ io_open_dest_real(file_pair *pair)
 #ifndef TUKLIB_DOSLIKE
 		flags |= O_NONBLOCK;
 #endif
+#ifdef _MSC_VER
+		const mode_t mode = _S_IREAD | _S_IWRITE;",54,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","ee009e6e85f31d8f0d7690b1282cb0412704cd35",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:31:07","2023-08-31 15:31:08","created",1311819580,"I changed these assertions to use `IO_BUFFER_SIZE`. Then the changes to `io_read` and `io_write_buf` to limit to `UINT32_MAX` shouldn't be needed either.","src/xz/file_io.c",75,1189,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -1158,13 +1186,20 @@ extern size_t
 io_read(file_pair *pair, io_buf *buf, size_t size)
 {
 	// We use small buffers here.
-	assert(size < SSIZE_MAX);
+	assert(size < (size_t)SSIZE_MAX);",75,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","ee009e6e85f31d8f0d7690b1282cb0412704cd35",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:32:24","2023-08-31 15:32:24","created",1311821279,"`SSIZE_MAX` isn't needed anymore after the change in the master branch.","src/xz/file_io.c",20,58,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -39,6 +39,30 @@ static bool warn_fchown;
 
 #include ""tuklib_open_stdxxx.h""
 
+#ifdef _MSC_VER
+#define close	_close
+#if _MSC_VER >= 1500
+#define lseek	_lseeki64
+#else
+#define lseek	_lseek
+#endif
+#define open	_open
+#define read	_read
+#define setmode	_setmode
+#define unlink	_unlink
+#define write	_write
+#define S_ISDIR(m)	(((m) & _S_IFMT) == _S_IFDIR)
+#define S_ISREG(m)	(((m) & _S_IFMT) == _S_IFREG)
+#endif
+
+#ifndef SSIZE_MAX",20,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","ee009e6e85f31d8f0d7690b1282cb0412704cd35",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:37:14","2023-08-31 15:37:15","created",1311827013,"VS older than 2013 update 2 cannot build anything from XZ Utils so this `#if` isn't needed. In practice maybe even VS2013 isn't worth worrying as it will go out of support in April 2024.","src/xz/file_io.c",6,44,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -39,6 +39,30 @@ static bool warn_fchown;
 
 #include ""tuklib_open_stdxxx.h""
 
+#ifdef _MSC_VER
+#define close	_close
+#if _MSC_VER >= 1500",6,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","ee009e6e85f31d8f0d7690b1282cb0412704cd35",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:39:01","2023-08-31 15:39:01","created",1311829147,"Cygwin and also MinGW-w64 have `unistd.h` so this should be `#ifdef _MSC_VER`.","lib/getopt.c",4,32,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -29,7 +29,9 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
+#ifndef _WIN32",4,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","cbba399e8581f1e38d31bf3f2b886e2e20d976dc",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:46:20","2023-08-31 15:46:21","created",1311838606,"`mytime_now()` doesn't need to be super precise and it doesn't need to be relative to any known point in time. Unless I'm missing something, `return GetTickCount64();` should be all that is needed to implement `mytime_now()`. The only downside is that it's not available on ancient Windows versions but at some point pre-Vista support likely could be removed anyway to simplify the code a little.","src/xz/mytime.c",4,15,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,7 +12,7 @@
 
 #include ""private.h""
 
-#ifdef HAVE_CLOCK_GETTIME",4,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","cbba399e8581f1e38d31bf3f2b886e2e20d976dc",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:48:32","2023-08-31 15:48:33","created",1311841270,"I suggest using `#define fileno _fileno` like in xzdec.c to avoid repetition.","src/xz/private.h",15,40,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -34,16 +36,28 @@
 #endif
 
 #ifndef STDIN_FILENO
+#ifdef _MSC_VER
+#	define STDIN_FILENO (_fileno(stdin))",15,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","cbba399e8581f1e38d31bf3f2b886e2e20d976dc",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-08-31 15:53:41","2023-08-31 15:53:42","created",1311847441,"This is needed only if VS2013 support is really wanted. `_snprintf` doesn't conform to C99 while `snprintf` in VS2015 should conform. So there is a minor risk to use `_snprintf`.","src/xz/private.h",44,93,"","none","Larhzu",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -75,3 +89,7 @@
 #ifdef HAVE_DECODERS
 #	include ""list.h""
 #endif
+
+#if defined(_MSC_VER) && _MSC_VER < 1900",44,"cbba399e8581f1e38d31bf3f2b886e2e20d976dc","cbba399e8581f1e38d31bf3f2b886e2e20d976dc",0,0,"","","","none"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:28:56","2023-08-31 15:28:55","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:31:08","2023-08-31 15:31:08","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:37:15","2023-08-31 15:37:15","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:39:02","2023-08-31 15:39:01","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:46:21","2023-08-31 15:46:21","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-08-31 15:48:33","2023-08-31 15:48:33","created",0,"To support files larger than 4 GiB on Windows, all calls of stat() and lseek() have to be redirected to 64-bit filesize capable calls.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass

Note: Compile warnings are inevitable for MSVC when some variables can be either 64-bit (target x64) or 32-bit (target Win32) at compile time. Those warnings need extensive changes to clean up.

## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): 

Make xz buildable with MSVC.
Add 64-bit filesize support on Windows.

## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->

xz does not build with MSVC.
xz would refuse to handle files larger than 4 GiB.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->

xz can be built with MSVC.
xz can handle files larger than 4 GiB on Windows.


## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->

I have added extensive MSVC build support in my own repo https://github.com/kiyolee/xz-win-build.
In addition to building xz, I have added support to build all tests as well.
This PR only covers code changes that were done while setting up my own repo.","",0,0,"","none","kiyolee",60,"Make xz buildable with MSVC and add 64-bit filesize support","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","734dde3af15d05450c7965ceb209cb6cd908df5f","[]","[]","xz-win-build","cbba399e8581f1e38d31bf3f2b886e2e20d976dc","master","74c3449d8b816a724b12ebce7417e00fb597309a",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-08-31 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-31 15:14:58","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-08-02 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-02 15:24:48","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-08-01 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-01 16:11:50","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-08-01 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-01 16:11:50","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-08-01 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-08-01 15:26:42","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-07-18 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-07-18 14:42:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",33,33,"","","","none"
"2023-07-18 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-07-18 14:42:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,4,"","","","none"
"2023-07-03 11:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-07-03 11:40:18","2023-07-03 11:40:18","created",1618043803,"It works with these:
  - GCC `-fuse-ld=bfd`
  - GCC `-fuse-ld=gold`
  - Clang `-fuse-ld=lld`

In these cases the symbols are there:

```
$ readelf -W --dyn-syms src/liblzma/.libs/liblzma.so.5 \
    | grep lzma_stream_encoder_mt_memusage
   127: 000000000000db90   222 FUNC    GLOBAL DEFAULT   13 lzma_stream_encoder_mt_memusage@@XZ_5.2
   128: 000000000000db90   222 FUNC    GLOBAL DEFAULT   13 lzma_stream_encoder_mt_memusage@XZ_5.1.2alpha
   129: 000000000000db90   222 FUNC    GLOBAL DEFAULT   13 lzma_stream_encoder_mt_memusage@XZ_5.2.2
```

Omitting `-Wl,--fatal-warnings` makes the build succeed with `-fuse-ld=mold` but the symbols are wrong:

```
$ readelf -W --dyn-syms src/liblzma/.libs/liblzma.so.5 \
    | grep lzma_stream_encoder_mt_memusage
    49: 000000000001c690   222 FUNC    GLOBAL DEFAULT   20 lzma_stream_encoder_mt_memusage@@XZ_5.2
    56: 000000000001c690   222 FUNC    GLOBAL DEFAULT   20 lzma_stream_encoder_mt_memusage@XZ_5.2.2@XZ_5.2.2
   104: 000000000001c690   222 FUNC    GLOBAL DEFAULT   20 lzma_stream_encoder_mt_memusage@XZ_5.1.2alpha@XZ_5.1.2alpha
```

Note how the non-default symbols (the last two) have a duplicated suffix. It happens with both GCC and Clang with `-fuse-ld=mold`, mold version 1.11.0. Disabling LTO makes it work. This makes me wonder if mold has a problem when LTO and symbol versioning are used at the same time.

Can you test a git snapshot of mold and if it still doesn't work then discuss it with the mold developers? As far as I understand it, the symbol versioning in liblzma doesn't do anything weird so the problem may affect many other packages too.

Thanks!
","",0,0,"","none","Larhzu",55,"[Bug]: warnings about missing symbols when building with the mold linker and lto","['bug']","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-27 19:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-06-27 19:14:14","1970-01-01 00:00:00","none",0,"","",0,0,"ifunc-crc64-fast-v2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-27 14:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-06-27 14:29:02","1970-01-01 00:00:00","none",0,"","",0,0,"ifunc-crc64-fast-v2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-27 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-06-27 14:43:18","2023-06-27 14:43:17","created",1609651443,"Using ifunc for a static `crc64_func` means that `lzma_crc64` becomes a single-instruction function that just does a jump via PLT:

```
jmp    45a0 <*ABS*+0x15e00@plt>
```

I suppose it's better to make `lzma_crc64` itself the ifunc. This has been done in [v2](https://github.com/tukaani-project/xz/tree/ifunc-crc64-fast-v2) branch. Can you test it and tell if you notice any difference (speed or anything else) compared to your version. Thanks!","",0,0,"","none","Larhzu",53,"Replaced crc64_fast constructor with ifunc","[]","open",0,"","[]",10,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-26 14:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-26 14:45:31","2023-06-26 14:45:30","created",1607641743,"@ved-rivos:
> The initial idea was to use the RVI/RVC hints for this extension but that was not considered acceptable by the architecture review committee as hint are not allowed to modify state which the sspush and sspopchk would do by updating the ssp.

Thank you! This was a detail that I hadn't understood. :-)

I think it would be valuable if the spec had a sentence explaining it near ""The 32-bit instructions are encoded using the `SYSTEM` major opcode"". For example: ""RVI or RVC hints were not used for these instructions because they modify architecturally visible state, for example, `sspush` and `sspopchk` modify `ssp` whose value can be read with `ssprr`.""

Similarly, cfi_forward.adoc could have something like: ""A hint instruction can be used as `lpad` because in any correctly-functioning program it is equivalent to a `nop`. The `ELP` state can only be observed if `lpad` raises an illegal-instruction exception.""

That being said, @sorear explains it well why mixing shadow-stack-unaware code isn't guaranteed to work even with the current spec. In practice it often would but so it would with `sspush` and `sspopchk` being hints.

@sorear:
> > If some (or all) code is built with unlabeled landing pads, then accidental labeled landing pads are a problem if attacker can control both the value of x7 and the function pointer.
>
> I'm unsure if this should be part of the threat model.

Maybe not. Building with unlabeled landing pads is inherently less strict than labeled anyway.

> libQt5WebKit.so.5.212.0 [...] estimate 39941 functions and 156KiB for the landing pads themselves.

For rough comparison: Debian's equivalent x86-64 package has .text size of 30,834,702 bytes but doesn't use landing pads. On Arch Linux, qt5-webkit 5.212.0alpha4-18 has .text size of 31,637,939 bytes and 84,516 `endbr64` landing pads (338,064 bytes).

The Debian packages clang-tools-16 and llvm-16 contain a small amount (under 1 %) of `auipc` uses where the consuming instruction isn't immediately after `auipc` or there may be more than one consumer (like read-modify-write with single `auipc`). So it's like explicit relocs was the default. I wonder how common such code will be in the future, although I understood that with linker support for hazardous instructions it wouldn't be a significant problem. (Off-topic: Knowing this would be valuable to me since it affects handling of RISC-V executables in data compression. Fused `auipc` + `jalr`, `addi`, or I/Zfh/F/D/Q load/store pairs are simple to handle but if a significant amount (5-10 % or more) will be unfused in the future it may need to be taken into account.)

I think I don't have the skills to comment these topics much more. I appreciate the considerate and educating replies from both of you, I have learned quite a few things. Thank you!
","",0,0,"","none","Larhzu",113,"Landing pad encoding update","[]","closed",0,"","[]",15,"COLLABORATOR","2023-06-17 15:58:31","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-25 20:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-25 20:23:15","2023-06-25 20:23:14","created",1606251460,"I agree that `sspush` and `sspopchk` cannot be behind ifunc.

In my previous message I tried to say that perhaps `sspush` and `sspopchk` could be RVI hints, and the compressed version could be RVC hints. For example, these should be available:

  - `add x0, x7, x1` = `sspush x1`
  - `add x0, x7, x5` = `sspush x5`
  - `add x0, x6, x1` = `sspopchk x1`
  - `add x0, x6, x5` = `sspopchk x5`
  - `c.add x0, x1` = `c.sspush x1`
  - `c.mv x0, x1` = `c.sspopchk x1`

Stores have the source register in rs2, including the compressed instructions. This way the compressed push and pop could both use x1, if it is preferred to avoid implicit reads from general purpose registers (or at least it makes things pretty).

Pushes and popchecks differ in one bit only:

  - `sspush` has inst[15]=1 and `sspopchk` has inst[15]=0.
  - `c.sspush x1` has inst[12]=1 and `c.sspopchk x1` has inst[12]=0.

When `xBCFIE = 0` the above instructions would revert to their RVI or RVC behavior. That is, they affect architecturally visible state just like `nop` does.

`ssload x1`, `ssload x5`, `sspinc`, `ssprr`, and `ssamoswap` would be regular new instructions that result in illegal-instruction exception on processors that don't support Zicfisslp. Zimop or Zcmop wouldn't be used. These instructions would be wrapped with ifunc or similar method. I don't know if these need different behavior based on `xBCFIE` or not.

I repeat that I don't have a good understanding about this topic. There might be more than one huge reason why my above text is a useless idea. But I hope that this message clarifies what I tried to say in my previous message.
","",0,0,"","none","Larhzu",113,"Landing pad encoding update","[]","closed",0,"","[]",8,"COLLABORATOR","2023-06-17 15:58:31","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-25 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-06-25 16:02:59","2023-06-25 16:02:58","created",1606143986,"When fixing commits in a patchset / pull request, it usually should be done by editing the original commits instead of adding fix-up commits at the end. For example, in this case the commits first remove a feature and then add it back. This makes it harder to see what changes were _actually_ made in the end. This applies to both reviewing the changes before the merge and to people who read xz's commit log afterwards. I think this should be fixed.

Thanks!","",0,0,"","none","Larhzu",53,"Replaced crc64_fast constructor with ifunc","[]","open",0,"","[]",8,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-25 15:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-25 15:37:35","2023-06-25 15:37:34","created",1606136445,"Thank you for the very exhaustive replies! I learned quite a few things.

It's great that implicit read from x7 is OK in this kind of case.

I agree that requiring 4-byte alignment for landing pads is good. Even if hazardous pairs were made impossible with 16/32-bit instructions, accidental landing pads could still exist inside longer instructions and then alignment can help. The case of J-type instructions is another a good reason.

My motivation for posting was that the implications of ""assembler/linker can force instruction to be aligned to a 4-byte boundary"" in the spec sounded pretty complicated and I wondered if these requirements could be simplified easily enough but I understand that the cost of the simplest solutions is too high.

In addition to the requirements for toolchains, a minor extra thing is that assembly programmers could need to know about it (warnings can help). It's not intuitive that `srai a0, a5, 1` needs to be 4-byte aligned. If optimizing for size, assembler (or even linker) could need to be smart enough so that it won't insert a `c.nop` when `c.mv a0, a5; c.srai a0, 1` would be shorter (at the expense of a longer dependency chain).

New extensions add more accidental landing pads. For example, Zbb has a few good candidates with rs1=a4/a5: `ctz/ctzw`, and with certain immediates `rori`, `roriw`, `bclri`, `bexti`, `binvi`, `bseti`.

I mention two more probably bad ideas for completeness (not proposals):

  - Requiring inst[17:16]=3 (18-bit label) would ensure that accidental landing pads cannot form with 16-bit instructions. Thus jumping into such a landing pad wouldn't immediately synchronize with the instruction stream. I haven't looked at what kind of effect this would have in practice, like how often the instruction after an accidental landing pad is valid.

  - Landing pads with inst[20:16]=0x1F cannot form accidentally with current and (likely) any future standard 16/32-bit instructions. If certain function signatures are especially common for indirect calls then it might help if the hash of popular functions had this kind of values. I guess it's not worth it but I mention this just in case.

Another way to look at accidental landing pads (I see @sorear edited his message so this is now partially duplicate):

1. If all landing pads are labeled and thus all `jalr`, `lui+jalr`, and `auipc+jalr` uses are prefixed with `lui x7` then `lpad` with full 20-bit label is good at the ISA level. Some problematic labels could be banned in the ABI, for example, with @sorear's proposed methods. Then those labels appearing accidentally in the code wouldn't matter. The unlabeled `lpad` is a special case but `auipc x0, 0` seems pretty good since only `c.unimp` can create an accidental unlabeled landing pad with 16/32-bit instructions. This property of `c.unimp` could be good to explain in the specification, even if in practice it might not matter if `-falign-jumps=4` is used because then `jal+c.unimp` cannot be hazardous.

2. If some (or all) code is built with unlabeled landing pads, then accidental labeled landing pads are a problem if attacker can control both the value of x7 and the function pointer. Here ISA restrictions on the possible landing pad labels could help to reduce the number of accidental landing pads (for example, @sorear's proposal 1 could be good as it's both quite effective and simple).

Here are a few commands to count instructions that create accidental landing pads in a particular file. `objdump` is the slowest part so a tempoary file can be a good idea.

```
riscv64-elf-objdump -d -M no-aliases FILENAME \
    | grep '[26ae]:' \
    | grep -E '\b[0-9a-f]017[0-9a-f]{4}\b' \
    | tr -s ' ' | cut -f3 \
    | sort | uniq -c | sort -nr

# Proposal 1, the only difference is 0->1 in ""\b[1-9a-f]"":
riscv64-elf-objdump -d -M no-aliases FILENAME \
    | grep '[26ae]:' \
    | grep -E '\b[1-9a-f]017[0-9a-f]{4}\b' \
    | tr -s ' ' | cut -f3 \
    | sort | uniq -c | sort -nr

# Proposals 1 and 2 combined:
riscv64-elf-objdump -d -M no-aliases FILENAME \
    | grep '[26ae]:' \
    | sed -rn '
        /\b[1-9a-f]017[0-9a-f]{4}\b/{
            N
            /\n.*\b([0-9a-f]{4})?[0-9a-f]{2}([08]3|[08]7|[19]3|[2a]3|[2a]7|[6e]7)\b/!P
            D
        }' \
    | tr -s ' ' | cut -f3 \
    | sort | uniq -c | sort -nr
```

Below is sample output of the first command from libQt5WebKit.so.5.212.0 from Debian. .text is 19,189,602 bytes.

```
   4297 slliw
   1455 addiw
   1258 addi
   1247 slli
    778 andi
    745 ori
    508 sltiu
    457 auipc
    310 srliw
    285 lbu
    281 fcvt.s.d
    176 csrrw       # csrrw zero,fflags,a4 or a5
     91 xori
     80 srli
     45 sraiw
     41 fcvt.wu.s
     39 fcvt.s.wu
     36 srai
      7 fadd.s
      4 jal
      4 fmul.s
      4 fle.s
      3 xor
      2 slti
      2 ld
      2 fsw
      1 sd
      1 lw
      1 lb
      1 feq.s
```

With proposal 1:

```
    281 fcvt.s.d
    102 addi
     45 sraiw
     41 fcvt.wu.s
     39 fcvt.s.wu
     36 srai
      4 jal
      4 fmul.s
      4 fle.s
      1 sd
      1 ori
      1 lbu
      1 feq.s
      1 addiw
```

Proposals 1 and 2 combined:

```
    241 fcvt.s.d
     93 addi
     38 sraiw
     35 fcvt.s.wu
     25 srai
     18 fcvt.wu.s
      4 fmul.s
      4 fle.s
      3 jal
      1 lbu
      1 feq.s
```

About MOPs:

While I understand that maybe-ops can be convenient in general, I didn't understand why they are useful for shadow stack when reading the spec. I got an impression that `sspush`, `sspopchk`, and their RVC counterparts could be RVI/RVC hints as they don't write to any general purpose registers and the shadow stack memory is not available for normal memory access. So those instructions have a kind of invisible effect just like `lpad` has.

Excluding the control stack mode, the rest of the shadow stack instructions are needed in special locations only and thus they could be normal instructions that would be guarded with runtime detection (like `__attribute__(ifunc(...))`. Maybe they wouldn't even need to do the xBCFIE check in hardware.

However, my understanding of this topic is very inadequate and I might be missing several elephants in the room. So it's better that I won't comment MOPs or shadow stack instructions any further. :-)
","",0,0,"","none","Larhzu",113,"Landing pad encoding update","[]","closed",0,"","[]",6,"COLLABORATOR","2023-06-17 15:58:31","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-23 19:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-23 19:07:14","2023-06-23 19:07:14","created",1604746556,"I know this is a little late but I hope it's OK. I'm very much not an expert so if the following doesn't make sense, I apologize for the noise. :-)

1. The 20-bit landing pad label sounds nice and compact. However, it means that `lpad` has an implicit read from x7 which is unusual in RISC-V. Requiring that `lpad` must have x7 in inst[19:15] (auipc_rs1) would avoid this. The label becomes 15 bits though.

2. Concatenation of two instructions can form a landing pad: This can be made less likely or even impossible in common situations. (By the way, in cfi_forward.adoc `?013h` should be `?017h` to match `auipc`.)

As long as there are only 16-bit and 32-bit instructions, it's possible to define a landing pad that cannot be accidentally formed, even if the landing pad is only two-byte aligned. It is still possible to embed a landing pad label and encode the landing pad register in auipc_rs1.

The idea is that the highest 16 bits of the landing pad must be chosen so that compilers will never emit instructions that begin with those bits. For example, `auipc x0, 0` would be such if `c.unimp` (0x0000) was never emitted: even though some 32-bit instructions end with 0x0017, an accidental landing pad cannot form if `c.unimp` is never used (especially valuable for the unlabeled landing pad). Currently Clang/LLVM can emit `c.unimp` in unreachable code (e.g. as padding immediately after `jal`) but GCC doesn't, I think.

For a 6-bit label and auipc_rs1=x28/t3 or x29/t4:

Eight 16-bit hints (`c.mv x0, x3`, `c.mv x0, x7`, ...) could be reserved for use as the high 16 bits of a landing pad. Compilers would never emit these hints so accidental landing pads wouldn't be possible as long as instructions longer than 32 bits aren't present. The eight hints provide a 3-bit label and another three bits are in auipc's [14:12]. But I guess a 6-bit label is unacceptably small.

For a 12/13/14-bit label and auipc_rs1=x30/t5 or x31/t6:

The unprivileged ISA spec has a table showing that instructions with the lowest seven bits set (0x7F) could be used for very long instructions. It's not frozen so it might change. If one is willing to guess that 0x7F prefix is unlikely to be used for popular instructions, it could be interesting for landing pad use instead of reserving 16-bit hints.

```
lui     x31, 0xnnvFw  # nn={00,...,FF}, v={7,F}, w={8,...,F}
                      # (If x30 is better then w={0,...,7}.)
jalr    rs
...
auipc   x0, 0xnnvFw   # Landing pad, compares bits [31:12] in x31.
                      # (Or sign-extend and compare [XLEN:12]?)

|31        23 | 22 20 | 19 16 | 15 | 14 12 | 11  7 | 6     0 |
|    label    |  111  |     rs1    | label |  rd   |  AUIPC  |
| nnnn nnnn v |  111  |  1111   1  |  www  | 00000 | 0010111 |
|                imm[31:12]                |
```

Currently no standard 32-bit instructions have the five lowest bits all set (0x1F is non-frozenly reserved for 48-bit instructions). So even 11 + 3 = 14-bit label (inst[31:21] + inst[14:12]) would fit with this scheme and accidental landing pads would be impossible when only currently-standard 16/32-bit instructions are present. It's not so future-proof in terms of accidental landing pads but perhaps the larger label is overall more valuable.

Comparable to the removed `lpcnl`, it is possible add 12 extra bits with `addi x31, x31, $label_low` and verify it with another hint instruction like `xori x0, x31, $label_low` but the extra code size isn't nice.

Avoiding accidental landing pads is most important with the unlabeled landing pad. All zeros (apart from [22:15] or [20:15]) or ones are the simplest choices but perhaps other patterns are worth considering too. For example, 0x707F at the high bits would be like a beginning of an instruction with opcode=0x7F, rd=x0, funct3=7. But it's impossible to guess what kind of bit patterns will be common inside long instructions in the future.
","",0,0,"","none","Larhzu",113,"Landing pad encoding update","[]","closed",0,"","[]",2,"COLLABORATOR","2023-06-17 15:58:31","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-23 14:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-06-23 14:55:27","2023-06-23 14:55:26","created",1604399958,"4-5 % isn't a huge difference but it's around the threshold where it becomes interesting. Jia and I discussed this and ifunc support is welcome while keeping the constructor attribute as the second choice. Thanks!","",0,0,"","none","Larhzu",53,"Replaced crc64_fast constructor with ifunc","[]","open",0,"","[]",6,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-23 13:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-06-23 13:29:35","2023-06-23 13:29:34","created",1604289182,"I understand that ifunc avoids loading a function pointer and an indirect branch. liblzma uses function pointers a lot so, for (de)compression performance, avoiding one pointer in the call stack likely doesn't matter (but I haven't benchmarked it). Many `lzma_crc64` calls can process a few kilobytes of data per call but I understand that in non-compression uses tiny buffers may be the most common.

How big difference in speed does your patch make with your code? I would like understand the real-world improvement that ifunc can make specifically with `lzma_crc64`.

> In regards to __cplusplus I wasn't sure if liblzma was being compiled with a C++ compiler anywhere. I can remove it if you don't think it's useful.

C++ compiler isn't used so the check should be removed.

By the way, have you checked xxhash if you need a very fast hash?

Thanks!","",0,0,"","none","Larhzu",53,"Replaced crc64_fast constructor with ifunc","[]","open",0,"","[]",4,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-23 12:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-06-23 12:03:35","2023-06-23 12:03:34","created",1604185659,"My understanding is that ifunc is specific to glibc. `__constructor__` works on many ELF platforms, not just GNU/Linux.

According to your link, ifunc is incompatible with `-fsanitize=address`. And indeed it makes `make check` fail with segfaults. (I also see that two tests fail with `-fsanitize=address` before your patch due to memory leaks but no segfaults.)

Also, checking for `__cplusplus` isn't needed as this is C code and not a public header.

How much difference (speed or memory or anything else) does ifunc make in this specific use case? I understand that the function pointer is an extra step on each call but the function itself is more expensive than `memcpy` or such which get called a lot with tiny buffers. Currently I feel the extra complication isn't worth it in liblzma as `__constructor__` is good to keep around too for ELF platforms that lack ifunc support.


Thanks!
","",0,0,"","none","Larhzu",53,"Replaced crc64_fast constructor with ifunc","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-17 12:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-17 12:37:12","2023-06-17 12:37:12","created",1595734160,"The final `)` is missing but otherwise the PR looks correct. The line is then fairly long, I didn't check how it looks as PDF.

Not a real suggestion, just thinking out aloud that it might look good this way:

```
is_lp_expected = ( (JALR || C.JR || C.JALR) &&
                   !(rd == x0 && (rs1 == x1 || rs1 == x5)) &&
                   !(rd == x7 && rs1 == x7) ) ? 1 : 0;
```

But keeping the helper variables is good, for example, if support for software guarded branches was optional. The [issue 84](https://github.com/riscv/riscv-cfi/issues/84) was about adding software guarded branches and it the linked to a [gcc thread](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=104816) and that linked to a [lkml post](https://lkml.org/lkml/2022/3/7/1068) which were good reads. On x86-64 the `notrack` prefix is similar to the software guarded branch but `notrack` support in the processor can be disabled so that a landing pad is always required, making CFI protection stronger. x86-64 Linux intentionally keeps `notrack` disabled in kernel mode. It is possible to create jump tables for `switch` statements with landing pads, and this can help against speculative execution problems better than software guarded branches (speculation may bypass jump table bounds checks).

Reading those links made me feel that the pros and cons of supporting software guarded branches should be understood well. I was reading the Zicfisslp spec for fun only and the value of software guarded branches is beoynd my skills and knowledge. So I won't comment it any further.

Thanks!
","",0,0,"","none","Larhzu",118,"Does the pseudo-instruction CALL require LPAD?","[]","open",0,"","[]",5,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-16 21:00:00","IssueCommentEvent","Larhzu","riscv/riscv-cfi","2023-06-16 21:45:07","2023-06-16 21:45:07","created",1595349081,"According to the RISC-V Unprivileged ISA V20191213 or [RISC-V Assembly Programmer's Manual](https://github.com/riscv-non-isa/riscv-asm-manual/blob/master/riscv-asm.md), an expansion of `call` can look like this:

```
auipc   x1, 0x12345
jalr    x1, 32(x1)
```

So, as you said, `jalr` has rd=x1 but it also has rs1=x1. The current cfi_forward.adoc has this:

```
is_indirect_call_jump = ( (JALR || C.JR || C.JALR) &&
                          (rs1 != x1) && (rs1 != x5) ) ? 1 : 0;
is_sw_guarded_jump = ( JALR && rd == x7 && rs1 == x7 ) ? 1 : 0;
is_lp_expected = is_indirect_call_jump & ~is_sw_guarded_jump;
```

My reading is that `is_lp_expected` will be 0 because rs1=x1. Before the commit 157ebd a landing pad would be expected with `call`.

In contrast, the `tail` pseudoinstruction does currently require `lpad` at the target address since `tail` uses rs1=x6.
","",0,0,"","none","Larhzu",118,"Does the pseudo-instruction CALL require LPAD?","[]","open",0,"","[]",2,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-16 16:00:00","IssuesEvent","Larhzu","riscv/riscv-cfi","2023-06-16 16:00:20","2023-06-16 16:00:19","opened",0,"The expansion of `call` uses `jalr` with rs1=x1. After [the commit 157ebd](https://github.com/riscv/riscv-cfi/commit/157ebdf42e3d3fbad87c4636fa15b459583a1715) this seems to no longer require a landing pad at the target address. I wonder if this is a bug.","",0,0,"","none","Larhzu",118,"Does the pseudo-instruction CALL require LPAD?","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-06-16 16:00:00","IssuesEvent","Larhzu","riscv/riscv-cfi","2023-06-16 16:10:39","2023-06-16 16:10:39","opened",0,"In cfi_intro.adoc:

> A JAL or JALR may be used to perform either a procedure call or a return from a procedure.

Only JALR can be used for returning.

> and a JAL/JALR where rs1 is the conventional link register

JAL doesn't have rs1.","",0,0,"","none","Larhzu",119,"Only JALR can return, and JAL doesn't have rs1","[]","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-05-16 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-05-16 16:05:47","2023-05-16 16:05:47","created",1549960402,"In principle, adding a filter for UTF-8 text files is fine. It just has to be done carefully as decoder support can never be removed (I don't want to end up with ""text filter"", ""a little better text filter"", ""hopefully the best text filter""...).

Old tools cannot decompress new filters but that's just how it is. Once a new filter is official, it takes some time until it can be used widely.

Your example with ukrainskakuhnya1998_djvu.txt uses `CP1124//TRANSLIT` which means that it's not reversible: converting it back to UTF-8 gives 2838134 bytes, 0.8 % smaller than the original file. It still gives an indication how much a filter might help though.

Similarly, the pg70694.html isn't reversible and becomes 739319 bytes when restored to UTF-8, 0.4 % smaller than the original. I guess Finnish, Swedish, German, and such languages likely won't see big enough savings with a filter like this. The amount of non-ASCII characters is fairly low.

Using LZMA2 option `pb=0` tends to help with text files but with these files it makes no significant difference.

Converting to UTF-16BE helps with ukrainskakuhnya1998_djvu.txt (it's 2-byte-aligned data thus `pb=1,lp=1`):

```
$ iconv -f utf8 -tutf16be < ukrainskakuhnya1998_djvu.txt > ukrainskakuhnya1998_djvu.txt.utf16be
$ xz -k --lzma2=pb=1,lp=1 ukrainskakuhnya1998_djvu.txt.utf16be
$ du -b --apparent ukrainskakuhnya1998_djvu.txt*
2860770 ukrainskakuhnya1998_djvu.txt
3343440 ukrainskakuhnya1998_djvu.txt.utf16be
427884  ukrainskakuhnya1998_djvu.txt.utf16be.xz

$ xz -k --lzma2=preset=6e,pb=1,lp=1 ukrainskakuhnya1998_djvu.txt.utf16be
$ du -b --apparent ukrainskakuhnya1998_djvu.txt.utf16be.xz 
426312  ukrainskakuhnya1998_djvu.txt.utf16be.xz
```

So it's not as good as your result but this is completely reversible as long as the original is valid UTF-8. Note that when compressing integers, big endian is usually better input than little endian.

Have you looked at existing Unicode compression schemes like [SCSU](https://www.unicode.org/reports/tr6/tr6-4.html)? It may not be good here but perhaps some ideas can be had still, perhaps not.

I understood that your idea could take a 8-bit codepage as an argument and then convert as much as possible using that, encoding unconvertible binary data via escape sequences or such. This could be fairly simple. On the other hand, it requires user to tell which codepage to use. In any case, character mapping should be done so that the decoder doesn't need to know any codepages: Filter Properties or the filtered raw stream itself should encode the mapping in some compact form instead.

A more advanced idea could be to detect non-ASCII UTF-8 characters as they come in and assign a 8-bit replacement code for them. The advantage would be that then the filter would work with many languages without any configuration from the user. This is much more complex though. It should ensure that the same UTF-8 codepoint consistently gets mapped to the same 8-bit value, otherwise compression could be terrible. It matters if the input file has like 300 codepoints and thus not all of them can have an 8-bit mapping active at the same time. On the other hand, it's acceptable that compression ratio will be good only with certain languages.

On the second thought, perhaps the above is just too complicated. At least some of the languages (where this kind of filter could be useful) need one or perhaps two small contiguous codepoint ranges above ASCII. CP1124 is almost 0x0401-0x045F, only 0x0490-0x0491 are missing.

More random ideas: A two-byte UTF-8 sequence encodes 11-bit codepoint. It could be encoded as 0x10-0x17 followed by any 8-bit byte. Three-byte UTF-8 sequence encodes 16 bits so 0x18 followed by any two bytes would work (same length as in UTF-8). And four-byte UTF-8 could be 0x19 and three bytes. Then 0x80-0xFF could be used for language-specific 8-bit encodings and code points outside the language would still never use more space than in UTF-8 if the repurposed ASCII control codes aren't needed. A few more ASCII control codes would need to be repurposed for escaping binary data (including the repurposed control codes themselves) and possibly for configuring the 0x80-0xFF range (unless only using a static mapping from Filter Properties).

A static mapping in Filter Properties could simply be a list of pairs <start><len>. For example, 0x0400 0x5F 0x0490 0x02 could put 0x0400-0x045F to 0x80-0xDF and 0x0490-0x0491 to 0xE0-0xE1, perhaps leaving 0xE2-0xFF to mean 0xE2-0xFF.

The above are just some quick ideas and better ones likely exist. :-)

When deciding the encoded format of the filter, xz-file-format.txt section 5.2 must be taken into account. Basically, 200 bytes of input to a decoder must produce at least 100 bytes of output for security reasons.

For early prototypes, standalone filter programs that filter from stdin to stdout are probably the most convenient.

If you wish to add prototype filters in .xz, please use a custom filter as described in xz-file-format.txt section 5.4. The small ID numbers must be used for final official filters only.

How to add the actual code: Look how Delta filter hooks into the rest of the code. Delta filter is very simple and doesn't change the size of the data. A text filter would change the size of the data so it would likely need some internal buffering. XZ for Java has cleaner codebase than XZ Utils so, depending on your preferences, Java code might be nicer for prototyping than C in this case.

We can talk on IRC on #tukaani at Libera Chat too, if you wish (and we happen to be online at the same time).
","",0,0,"","none","Larhzu",50,"[Feature Request]: A new filter for better compression of UTF-8 text (primarily Cyrillic, Greek or anything non-English)","[]","open",0,"","[]",1,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-05-05 16:00:00","PushEvent","Larhzu","tukaani-project/xz-java","2023-05-05 16:52:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-05-03 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-05-03 19:58:13","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2023-05-03 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-05-03 19:58:13","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-21 13:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-03-21 13:38:22","1970-01-01 00:00:00","none",0,"","",0,0,"cmake_features_v2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-21 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-21 12:25:48","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",4,4,"","","","none"
"2023-03-21 12:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-21 12:08:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-03-21 11:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2023-03-21 11:29:16","2023-03-21 11:29:15","closed",0,"### Describe the bug

With a plain `./configure` I get:
```
./src/liblzma/.libs/liblzma.a
./src/liblzma/.libs/liblzma.so.5.4.2
./src/liblzma/.libs/liblzma.so.5
./src/liblzma/.libs/liblzma.so
```
but as soon as I add `--disable-threads` the `.so.5.4.2` file and links are missing:
```
./src/liblzma/.libs/liblzma.a
```
Is this the intended behaviour?

### Version

5.4.2

### Operating System

Linux AMD64

### Relevant log output

_No response_","",0,0,"","none","251",45,"[Bug]: `--disable-threads` prevents build of dynamic library","['bug']","closed",0,"","[]",0,"NONE","2023-03-21 11:29:15","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-21 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-21 11:29:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-03-19 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-03-19 20:47:47","2023-03-19 20:47:47","created",1475392503,"Sorry. :-( I added a few warning flags since I thought I had silenced them all.

Arch uses --enable-werror so that's why warnings make the build fail. This is good for testing :-) although it can cause annoyances like this. It was only recently that -Wno-format-truncation could be removed from the PKGBUILD file in Arch.

It's fixed in master and v5.4 now. Thanks!","",0,0,"","none","Larhzu",44,"[Bug]: 5.4.2 fails to build on 32bit","['bug']","closed",0,"","[]",1,"NONE","2023-03-19 20:47:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-19 20:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2023-03-19 20:47:01","2023-03-19 20:47:00","closed",0,"### Describe the bug

Building the multilib package for Arch Linux (https://archlinux.org/packages/multilib/x86_64/lib32-xz/) fails. The lines producing the error did not change recently, but the version before (5.4.1) built without problems (and still builds with current toolchain).

### Version

latest

### Operating System

Arch Linux

### Relevant log output

```shell
In file included from lz/lz_encoder_mf.c:16:
../../src/liblzma/common/memcmplen.h: In function 'lzma_memcmplen':
../../src/liblzma/common/memcmplen.h:92:36: error: conversion to 'uint32_t' {aka 'const unsigned int'} from 'int' may change the sign of the result [-Werror=sign-conversion]
   92 |                 const uint32_t x = 0xFFFF ^ _mm_movemask_epi8(_mm_cmpeq_epi8(
      |                                    ^~~~~~
```
","",0,0,"","none","eworm-de",44,"[Bug]: 5.4.2 fails to build on 32bit","['bug']","closed",0,"","[]",0,"NONE","2023-03-19 20:47:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-19 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-19 20:47:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-19 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-19 20:46:59","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-18 14:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-18 14:01:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-18 13:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-18 13:57:37","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-17 06:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-17 06:55:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-03-16 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-16 22:45:30","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/cmake_cache_features","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",28,4,"","","","none"
"2023-03-16 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-16 22:04:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-03-15 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-15 21:44:32","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/doxygen_install_docs","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-03-15 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-15 17:19:39","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/doxygen_install_docs","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-03-15 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-15 11:42:20","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/doxygen_install_docs","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-03-14 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-14 21:19:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/doxygen_install_docs","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",9,9,"","","","none"
"2023-03-11 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-03-11 20:05:51","2023-03-11 20:05:50","created",1465002769,"In contrast to v5.4, v5.2 (and thus 5.2.10) don't exit if enabling the sandbox fails. v5.2 only displays a message if double-verbose (`xz -vv`). The new stricter behavior was intentionally not backported to v5.2 since it seemed a risky change. So that's why the problem didn't appear until 5.4.x got into FreeBSD. I will discuss with JiaT75, perhaps it's best to not change the Capsicum code in v5.2 at all, we'll see.","",0,0,"","none","Larhzu",43,"xz: Improve compatibility with systems without capability mode support","['bug','5.4.2']","closed",0,"","[]",9,"NONE","2023-03-11 17:56:04","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-11 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-11 20:09:22","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.2","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",21,21,"","","","none"
"2023-03-11 17:00:00","PullRequestEvent","Larhzu","tukaani-project/xz","2023-03-11 17:56:05","2023-03-11 17:56:04","closed",0,"When the kernel is built without capability mode support, or when using an emulator like qemu-user-static that does not translate system calls, these calls will return a negative number and set the errno to ENOSYS. However, this error does not indicate a real programming or runtime error and is generally ignored by base system applications built with capability mode sandboxing.

## Pull request checklist

Please check if your PR fulfills the following requirements:
- [ ] Tests for the changes have been added (for bug fixes / features)
- [ ] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

Please check the type of change your PR introduces:
- [X] Bugfix

## What is the current behavior?

xz would abort execution with `Failed to enable the sandbox` when capability mode system calls failed, regardless if the host system have capability mode support.

It is advisable that binaries with capability mode sandbox enabled to ignore capability mode errors when they are solely because the system does not have the support, this is done on many applications including OpenSSH and base system utilities.  In fact, FreeBSD have a set of macros called [capsicum_helpers(3)](https://man.freebsd.org/cgi/man.cgi?query=capsicum_helpers&sektion=3) which [wraps](https://cgit.freebsd.org/src/tree/lib/libcapsicum/capsicum_helpers.h#n153) this anti-pattern.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=269185


## What is the new behavior?

xz will ignore sandbox failures caused by the kernel lacking support of capsicum mode.

## Does this introduce a breaking change?

- [ ] Yes
- [X] No


## Other information

The proposed patch modified `cap_*` calls to also check if the failure was caused by the lack of support (ENOSYS) and make it ignore it.  If possible, it's probably reasonable to just use `caph_*` calls found in `capsicum_helpers(3)`.","",0,0,"","none","delphij",43,"xz: Improve compatibility with systems without capability mode support","['bug','5.4.2']","closed",0,"","[]",9,"NONE","2023-03-11 17:56:04","1970-01-01 00:00:00","596041a4aa89d935e45f7c5941b764036e9aab29","[]","[]","master","4388d4f845114c1027b65d985332edaf0a86052d","master","f1ab1f6b339d16a53ac53efeb97779ecd2bae70f",0,0,0,"dirty","",0,0,1,6,5,1,"",0,"","",0,0,"","","","none"
"2023-03-11 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-03-11 17:53:00","1970-01-01 00:00:00","none",0,"","",0,0,"capsicum_improvements","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-11 17:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-03-11 17:53:38","1970-01-01 00:00:00","none",0,"","",0,0,"capsicum_improvements_improvements","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-11 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-03-11 17:56:05","2023-03-11 17:56:04","created",1464964791,"I fully agree with your reasoning. A warning message would also break `make check` in test_scripts.sh.

I merged JiaT75's commits to master which remove the warning message and the changing of the exit status. Now master is effectively quite similar to what capsicum_improvements was except that master checks for ENOSYS for all `cap_*` calls.

I squashed the commits to the v5.4 branch already for 5.4.2. It will be in 5.2.11 too.

I think this issue should now have been solved. Thanks!

Also thanks for updating the cap_*(2) man pages!
","",0,0,"","none","Larhzu",43,"xz: Improve compatibility with systems without capability mode support","['bug','5.4.2']","closed",0,"","[]",9,"NONE","2023-03-11 17:56:04","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-11 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-11 17:45:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-03-11 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-11 17:45:14","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,1,"","","","none"
"2023-03-10 23:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-10 23:43:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2023-03-10 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-03-10 21:27:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",10,10,"","","","none"
"2023-03-08 16:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-03-08 16:15:36","2023-03-08 16:15:36","created",1460441163,"@JiaT75: I apologize for the inappropriate harsh message above. I shouldn't post when in bad mood.

@delphij: OK, so avoiding non-zero exit status is essential.

Is a warning message good or bad? I thought it's not good to print a warning on `ENOSYS` since the reason for the error is clearly outside of xz (kernel or emulator not supporting the syscall) and it could be annoying if all Capsicum processes showed such warnings on every invocation. But it can be argued that it's good to inform users about the situation.

If cap_rights_limit(2) can return `ENOSYS` then I suppose it doesn't hurt to check it even after a successful call to cap_enter(2).

Other OSes with Capsicum support I hadn't thought about. So I guess for now it's simplest to avoid capsicum_helpers(3).

I tested the new cap_rights_limit calls on FreeBSD 13.1 and they seem to work even with `sysctl kern.trap_enotcap=1` so I guess they *might* be safe to add even to the next stable release but it can be decided later.","",0,0,"","none","Larhzu",43,"xz: Improve compatibility with systems without capability mode support","['bug','5.4.2']","open",0,"","[]",7,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-08 16:00:00","WatchEvent","Larhzu","tukaani-project/xz","2023-03-08 16:49:51","1970-01-01 00:00:00","started",0,"","",0,0,"","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-07 20:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-03-07 20:32:41","1970-01-01 00:00:00","none",0,"","",0,0,"capsicum_improvements","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-03-07 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-03-07 20:35:58","2023-03-07 20:35:57","created",1458837313,"I think the Capsicum commits went to the master branch a bit hastily:

1. It's not good to spam users with a warning message when their kernel doesn't support Capsicum. Similar spamming issue was fixed in the commit af0fb386ef55db66654ae39e2deec6e04190c4ff.
2. `message_warning()` affects exit status so now xz will exit with status 2 if kernel lacks Capsicum support (unless `--no-warn` (`-Q`) is used). This breaks most use cases still.
3. It seems unncessary to complicate `cap_rights_limit()` calls with checks for `ENOSYS` but I might be wrong.
4. Setting `sandbox_allowed = false;` is OK but not needed as the code will be run only once anyway since Capsicum is used only if there is exactly one input file.

I might have misunderstood the Capsicum API slightly in the past and thus I have put `cap_enter()` as the very last step. Seems that moving it to be the first one makes it easy to detect if Capsicum is supported by the kernel or not. So that idea in the master branch seems good.

[cap_enter(2)](https://man.freebsd.org/cgi/man.cgi?query=cap_enter&apropos=0&sektion=0&manpath=FreeBSD+14.0-CURRENT&arch=default&format=html) mentions `ENOSYS` but [cap_rights_limit(2)](https://man.freebsd.org/cgi/man.cgi?query=cap_rights_limit&sektion=2&apropos=0&manpath=FreeBSD+14.0-CURRENT) doesn't. I wonder if it is a documentation error or if it is intentional to not mention `ENOSYS`. I'm a bit hesitant to add a check for an undocumented `errno` value (I see capsicum_helpers.h does check for `ENOSYS` though).

I put a proposed fix to the branch [capsicum_improvements](https://github.com/tukaani-project/xz/commits/capsicum_improvements). These go before the new commits in the master branch which I think should be reverted so that clean patches can be cherry-picked to stable branches.

I wonder if `STDIN_FILENO` and `STDERR_FILENO` should be restricted too. (`src_fd` may be `STDIN_FILENO`.) I added another commit for those. There is no worry about `EBADF` since xz ensures that the file descriptors are open. But perhaps having only `CAP_WRITE` for `STDERR_FILENO` can be too strict in some cases, I'm not sure. capsicum_helpers.h adds a few other capabilities too but on the other hand xz will only write to standard error with `fprintf` and friends.

Moving to capsicum_helpers(3) could be an option but at this point I'm not sure if it is worth it as I think this should work fine too. Moving to capsicum_helpers(3) would need updating the configure test too for those who build xz from an upstream tarball.

@delphij: What do you think about the commits in capsicum_improvements?

@JiaT75: What kind of change did you have in mind for ax_check_capsicum.m4? One cannot check for kernel support at build time as the binary might be run on a different kernel too. Using capsicum_helpers(3) would need a change so that the build won't fail on FreeBSD 10 or 11 (which are out of support).","",0,0,"","none","Larhzu",43,"xz: Improve compatibility with systems without capability mode support","['bug','5.4.2']","open",0,"","[]",5,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-27 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-02-27 16:38:47","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-02-23 18:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-02-23 18:56:06","2023-02-23 18:56:05","created",1442277117,"It should be fixed now. Thanks!

XZ Embedded has the same problem. The initial plan is to fix it by changing the API documentation to say that the input and output buffer pointers must not be NULL even for empty buffers. First the code in the Linux kernel has to be checked if NULLs are used in xz_dec_* calls.","",0,0,"","none","Larhzu",36,"[Bug]: Undefined behavior: NULL + 0","['bug']","closed",0,"","[]",2,"NONE","2023-02-23 18:56:05","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-23 18:00:00","IssuesEvent","Larhzu","tukaani-project/xz","2023-02-23 18:56:07","2023-02-23 18:56:06","closed",0,"### Describe the bug

When given empty buffers with `next_in == NULL` and `avail_in == 0` (or same for `out`), liblzma sometimes computes `NULL + 0`, which has undefined behavior in C (it is defined in C++).

This gets detected by ubsan.

The following places are affected (possibly more):

https://github.com/tukaani-project/xz/blob/913ddc5572b9455fa0cf299be2e35c708840e922/src/liblzma/common/common.c#L291-L297
The first 3 lines can be guarded with `if (in_pos != 0)`, the last 3 lines can be guarded with `if (out_pos != 0)`.

https://github.com/tukaani-project/xz/blob/75f1a6c26df4ce329da0882786403e3ccf5cd898/src/liblzma/common/block_encoder.c#L81
Write `in_start != 0 ? in + in_start : in`.

### Version

5.4.1

### Operating System

Linux

### Relevant log output

_No response_","",0,0,"","none","QrczakMK",36,"[Bug]: Undefined behavior: NULL + 0","['bug']","closed",0,"","[]",2,"NONE","2023-02-23 18:56:05","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-23 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-02-23 18:48:17","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-02-20 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-02-20 20:26:52","2023-02-20 20:26:52","created",1437514247,"I have read about this a bit now. Sounds like it probably needs to be fixed. Quite a few functions have to be reviewed to spot all such cases as there definitely are more than those you already found. XZ Embedded needs to be reviewed too.

At least with a trivial test program, the method in `in_start != 0 ? in + in_start : in;` seems to be optimized to the same code as `in + in_start`, at least with modern GCC and Clang. So there won't be an extra branch in reality.

To me this seems like a bug in the standard that could have been fixed by adding an extra sentence to explicitly allow null-pointer + 0. Based on search engine results, it seems that it was decided that it's better to change hundreds of codebases instead, hopefully spotting every problematic case. Feels a bit similar to the `memcpy(NULL, NULL, 0)` issue that was (hopefully) fixed in XZ Utils in 2019.

Thanks for reporting this!","",0,0,"","none","Larhzu",36,"[Bug]: Undefined behavior: NULL + 0","['bug']","open",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-20 20:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-02-20 20:56:48","2023-02-20 20:56:48","created",1437534919,"Fixing GCC would be the best but I guess the current GCC versions have to be supported for some time anyway.

I have understood that MicroBlaze is for embedded use so I feel quite OK by making it a special case. The way symbol versioning is used in XZ Utils means that the downsides are very small: it sounds fairly unlikely that the issues caused by the patch from RHEL/CentOS 7 would affect MicroBlaze use cases. So the solution I committed is specific to XZ Utils and not trivially usable for other projects.

Checking for features is obviously better most of the time (instead of checking for CPU/OS/whatever) so in general I don't disagree with you. In this case I feel the problem likely exists on just one platform and a generic test would be more complex than what is currently used on other platforms. If there is a bug in the test for the `__symver__` attribute, then LTO builds can silently break if the fallback is `asm("".symver ..."")` or the compatibility symbols may silently be missing if the fallback is to use `liblzma_generic.map`. The method I committed has lower risk and it's simpler too.

I plan to put the workaround in 5.4.2 and also 5.2.11 at the same time, whenever a new bugfix release will be made. Before that, it's safe to use the commit with both 5.2.10 and 5.4.1.

If GCC is fixed this year, perhaps this workaround can be omitted 2-3 years later when a new major release of XZ Utils is made.

Thanks for reporting the problem and testing!","",0,0,"","none","Larhzu",32,"Detect symver attribute support","['bug','5.4.2']","open",0,"","[]",10,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-17 19:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-02-17 19:00:48","2023-02-17 19:00:48","created",1435105806,"> ```
> vfazio@vfazio2 ~/development/buildroot $ readelf -W --dyn-syms output/build/xz-5.2.10/src/liblzma/.libs/liblzma.so.5.2.10 | grep lzma_stream_encoder_mt_memusage
>    121: 0000f11c   676 FUNC    GLOBAL DEFAULT   12 lzma_stream_encoder_mt_memusage@@XZ_5.2
>    122: 0000f11c   676 FUNC    GLOBAL DEFAULT   12 lzma_stream_encoder_mt_memusage@XZ_5.1.2alpha
>    123: 0000f11c   676 FUNC    GLOBAL DEFAULT   12 lzma_stream_encoder_mt_memusage@XZ_5.2.2
> ```

Thanks! So it's a normal ELF target that supports symbol versioning. It's just the `__symver__` attribute that is broken in GCC on MicroBlaze.

There are two possible solutions:

1. Use the old `asm("".symver ..."")` method on MicroBlaze (and possible other platforms that don't support `__symver__` attribute).
  - With this method LTO (`-flto`) will be silently broken on MicroBlaze.
  - This requires a test in configure.ac and CMakeLists.txt.
2. Only use simple/basic/generic symbol versioning on MicroBlaze.
  - Before the compatibility symbols for the patch from RHEL/CentOS 7 were added, this was the only method. The patch had spread outside CentOS 7 but even then I guess these symbols probably aren't useful on MicroBlaze and omitting them should do no harm.
  - This is simpler than the option 1 above. It sounds likely that MicroBlaze is a special case (GCC issue) so adding a special case for MicroBlaze in configure.ac is OK.
  - This way there is no risk of silent LTO breakage with GCC >= 10 since no test for the `__symver__` attribute is needed in configure.ac or CMakeLists.txt.

I committed a fix using the second method. I didn't do it for CMake-based build but I guess building liblzma with CMake on MicroBlaze isn't so important.

> The patch was largely based on how the check has been adapted other places: [libfuse/libfuse@3aba09a](https://github.com/libfuse/libfuse/commit/3aba09a5c56e017746c5c1652dbc845f4db7374a)
> 
> https://gitlab.com/cryptsetup/cryptsetup/-/merge_requests/275/diffs?commit_id=5f71b3d63181aa88a68f7f71eab8801f2d8d2cde
> 
> https://github.com/smuellerDD/libkcapi/blob/master/m4/ac_check_attribute_symver.m4

My Meson skills are non-existent for now so I don't know if the method in libfuse is correct. If user-supplied `CFLAGS` don't affect the test then it probably is good.

The other two first declare the function and then define it so they work even with `-Wmissing-prototypes` or `-Wmissing-declarations`. The test in this XZ Utils PR missed the declaration and thus it was more fragile (wrong test result and thus broken LTO if `configure` is run with `CFLAGS=-Wmissing-declarations`).

In case Clang some day happened to support the attribute then being future-compatible with `clang -Weverything` would matter too. It gives warnings from what `AC_LANG_SOURCE` outputs. This test doesn't need `AC_LANG_SOURCE` or `AC_LANG_PROGRAM` so a test like the following is enough:

```
AC_COMPILE_IFELSE([
    void foo(void);
    __attribute__((__symver__(""foo@BAR_1.2"")))
    void foo(void) { return; }
], [
    ...
```

A somewhat similar test is already used in XZ Utils for the `__constructor__` attribute. It uses a static function so it doesn't need a separate declaration.

Of course there are multiple slightly different ways to write a working test. One just has to be really careful that the test program will never give a warning about an unrelated thing in the test program which would make the test fail when it shouldn't. Perhaps `-Werror=attributes` instead of `-Werror` would be more robust if the attribute is supported only by compilers that support `-Werror=attributes`. When testing for attributes that are supported by ancient GCC versions (like `__constructor__`) then this doesn't work as the ancient GCC versions don't support `-Werror=attributes`.

> Again, i'm not totally convinced the gcc toolchain itself shouldn't be fixed to include `elfos.h` if it's generating ELF binaries.

I have no idea, sorry.

Thanks!","",0,0,"","none","Larhzu",32,"Detect symver attribute support","['bug','5.4.2']","open",0,"","[]",6,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-17 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-02-17 19:00:18","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-02-16 19:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-02-16 19:09:07","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-02-09 17:00:00","IssueCommentEvent","Larhzu","tukaani-project/xz","2023-02-09 17:10:45","2023-02-09 17:10:44","created",1424531920,"The linked GCC bug 101766 gives an impression that `__has_attribute` is fairly broken and not usable without extra care. However, perhaps it's not the real problem in this case. I need to understand the big picture better first.

The `__symver__` attribute is used when possible because with the traditional `asm("".symver..."")` method link-time optimization (LTO, `-flto`) with GCC breaks in a way that isn't obvious. The build will succeed without warnings but the shared library will have issues which sometimes won't be immediately visible.

It's confusing if GCC doesn't support `__symver__` attribute but the platform still supports `.symver` in the assembly code. Are the binaries in the ELF format? What does `file src/liblzma/.libs/liblzma.*` say about the shared library after a successful build with your patch?

If it is in ELF, what does this print?

```
readelf -W --dyn-syms src/liblzma/.libs/liblzma.so.5 | grep lzma_stream_encoder_mt_memusage
```

It should print three lines whose rightmost column looks like this:

```
lzma_stream_encoder_mt_memusage@@XZ_5.2
lzma_stream_encoder_mt_memusage@XZ_5.1.2alpha
lzma_stream_encoder_mt_memusage@XZ_5.2.2
```

If there are no `@@XZ...` or `@XZ...` then the platform doesn't support symbol versioning and the next few paragraphs aren't interesting.

XZ Utils currently has two variants of symbol versioning:

(1) A GNU/Linux-specific version with extra symbols for compatibility with a broken patch in RHEL/CentOS 7 which has also been copied to a few other places. The `@XZ_5.1.2alpha` and `@XZ_5.2.2` above exist due to this.

(2) A generic version that works on GNU/Linux (without RHEL/CentOS 7 symbols) and FreeBSD (possibly also Solaris but not sure, it's not enabled by default on Solaris). With this the above list only has `@@XZ_5.2`. You can test this (without your patch) by omitting the `linux*)` section in configure.ac (lines 668-700 in XZ Utils 5.2.10; lines 723-755 in XZ Utils 5.4.1).

It sounds very likely that the patch from RHEL/CentOS 7 (which was used somewhere else too) doesn't affect Microblaze users and thus (2) could be good **if** symbol versions are supported. The (2) method doesn't require anything in the C code, so no `__symver__` attribute or `asm("".symver..."")` and thus no LTO build issues.

On the other hand, if symbol versioning isn't supported at all, then the default in configure.ac should be changed so that on Microblaze it's equivalent to `--disable-symbol-versions`. This is easy to do with `case $host_cpu in microblaze*)`. I base this on the configure message `checking host system type... microblaze-buildroot-linux-gnu` from your build log.

The proposed patch has subtle problems:

(1) Autoconf tests that require `-Werror` should be written very carefully. In this case if user has specified enough warning flags in `CFLAGS` (for example, `-Wmissing-prototypes`) then the test will fail even if the compiler supports the `__symver__` attribute. This means that an innocent extra warning flag in `CFLAGS` can silently break `-flto` with GCC!

When writing this kind of tests, Clang's `-Weverything` is convenient for catching many issues like this. (Clang doesn't support `__symver__` so the test will fail for that reason still. `-flto` works with Clang with the traditional `.symver` method already.)

While not too important for this particular test, `clang -Weverything` includes `-Wreserved-macro-identifier` which will warn about the macros added by `AC_LANG_SOURCE`. The test doesn't need anything from `AC_LANG_SOURCE` so it's better to avoid it when `-Werror` is needed. See also how support for `__constructor__` attribute is detected in configure.ac.

(2) The CMake build isn't updated so with this patch CMake-based build will never use the `__symver__` attribute and thus `-flto` with GCC is silently broken again. While CMake-based build is not the primary build method on GNU/Linux, I want to keep the liblzma part of it working well at least on the most common platforms.

Anyway, I want to understand the issue better before worrying about patches. Once the problem is understood, a patch is probably fairly easy to write.","",0,0,"","none","Larhzu",32,"Detect symver attribute support","['bug','5.4.2']","open",0,"","[]",4,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-02-07 17:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-02-07 17:10:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-27 18:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-01-27 18:04:20","1970-01-01 00:00:00","none",0,"","",0,0,"sigtstp_alternative","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-01-27 18:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-01-27 18:12:44","1970-01-01 00:00:00","none",0,"","",0,0,"cleanup_has_warning","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-01-27 18:00:00","DeleteEvent","Larhzu","tukaani-project/xz","2023-01-27 18:12:58","1970-01-01 00:00:00","none",0,"","",0,0,"cleanup_suffix_is_set","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-01-26 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-26 16:33:49","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/sigtstp_alternative","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-26 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-26 15:56:23","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-26 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-26 15:40:03","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-23 21:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-01-23 21:47:49","1970-01-01 00:00:00","none",0,"","",0,0,"cleanup_has_warning","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-01-12 04:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-12 04:06:35","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-12 03:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-12 03:39:04","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-12 02:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-12 02:47:06","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-12 02:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-12 02:18:52","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",7,7,"","","","none"
"2023-01-11 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-11 15:51:37","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-11 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-11 15:13:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/NEWS_update_5.4.1","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-11 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-01-11 14:11:54","2023-01-11 14:11:55","created",1067038681,"This triggers -Wsign-conversion. Here it doesn't matter if i is signed or unsigned so perhaps unsigned int would be better. (If i starts 2 to then i + 2 isn't needed, both are fine.)","tests/test_index.c",432,0,"","none","Larhzu",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,564 +16,1028 @@
 
 #include ""tests.h""
 
+// liblzma internal header file needed for:
+// UNPADDED_SIZE_MIN
+// UNPADDED_SIZE_MAX
+// vli_ceil4
+#include ""common/index.h""
+
+
 #define MEMLIMIT (LZMA_VLI_C(1) << 20)
 
-#define SMALL_COUNT 3
-#define BIG_COUNT 5555
+static uint8_t *decode_buffer;
+static size_t decode_buffer_size = 0;
+static lzma_index *decode_test_index;
+
+
+static void
+test_lzma_index_memusage(void)
+{
+	// The return value from lzma_index_memusage is an approximation
+	// of the amount of memory needed to hold the index meta data for
+	// a given amount of streams and blocks. It will be an upperbound,
+	// so this test will mostly sanity check and error check the
+	// function
+
+	// The maximum number of streams should be UINT32_MAX
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX + 1, 1), UINT64_MAX);
+
+	// The maximum number of blocks should be LZMA_VLI_MAX
+	assert_uint_eq(lzma_index_memusage(1, LZMA_VLI_MAX), UINT64_MAX);
+
+	// Number of streams must be non zero
+	assert_uint_eq(lzma_index_memusage(0, 1), UINT64_MAX);
+
+	// Number of blocks CAN be zero
+	assert_uint(lzma_index_memusage(1, 0), !=, UINT64_MAX);
+
+	// Arbitrary values for stream and block should work without error
+	// and should always increase
+	uint64_t previous = 1;
+	lzma_vli streams = 1;
+	lzma_vli blocks = 1;
+	// Test 100 different increasing values for streams and block
+	for (int i = 0; i < 100; i++) {
+		uint64_t current = lzma_index_memusage(streams, blocks);
+		assert_uint(current, >, previous);
+		previous = current;
+		streams += 29;
+		blocks += 107;
+	}
+
+	// Force integer overflow in calculation (should result in error)
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX, LZMA_VLI_MAX),
+			UINT64_MAX);
+}
 
 
-static lzma_index *
-create_empty(void)
+static void
+test_lzma_index_memused(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-	return i;
+	// Very similar to test_lzma_index_memusage above since
+	// lzma_index_memused is essentially a wrapper for
+	// lzma_index_memusage
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Should pass since an empty index since initizlization creates
+	// 1 stream
+	assert_uint(lzma_index_memused(index), <, UINT64_MAX);
+
+	// Append small blocks and then test again (should pass)
+	for (int i = 0; i < 10; i++)
+		assert_lzma_ret(lzma_index_append(index, NULL,
+				UNPADDED_SIZE_MIN, 1), LZMA_OK);
+
+	assert_uint(lzma_index_memused(index), <, UINT64_MAX);
+
+	lzma_index_end(index, NULL);
 }
 
 
-static lzma_index *
-create_small(void)
+static void
+test_lzma_index_append(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-	expect(lzma_index_append(i, NULL, 101, 555) == LZMA_OK);
-	expect(lzma_index_append(i, NULL, 602, 777) == LZMA_OK);
-	expect(lzma_index_append(i, NULL, 804, 999) == LZMA_OK);
-	return i;
+	// Basic input-ouput test done here.
+	// Less trivial tests for this function are done throughout
+	// other tests.
+
+	// First test with NULL index
+	assert_lzma_ret(lzma_index_append(NULL, NULL, UNPADDED_SIZE_MIN,
+			1), LZMA_PROG_ERROR);
+
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Test with invalid unpadded size
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN - 1, 1), LZMA_PROG_ERROR);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MAX + 1, 1), LZMA_PROG_ERROR);
+
+	// Test with invalid uncompressed size
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MAX, LZMA_VLI_MAX + 1),
+			LZMA_PROG_ERROR);
+
+	// Test expected successful block appends
+	assert_lzma_ret(lzma_index_append(index, NULL, UNPADDED_SIZE_MIN,
+			1), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN * 2,
+			2), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN * 3,
+			3), LZMA_OK);
+
+	lzma_index_end(index, NULL);
+
+	// Test uncompressed size growing too large.
+	// Should result in LZMA_DATA_ERROR
+	index = lzma_index_init(NULL);
+
+	assert_lzma_ret(lzma_index_append(index, NULL, UNPADDED_SIZE_MAX,
+			1), LZMA_DATA_ERROR);
+
+	// Test compressed size growing too large.
+	// Should result in LZMA_DATA_ERROR
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN, LZMA_VLI_MAX), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN, 1), LZMA_DATA_ERROR);
+
+	// Currently not testing for error case when the size of the index
+	// grows too large to be stored. This was not practical to test for
+	// since too many blocks needed to be created to cause this.
+
+	lzma_index_end(index, NULL);
 }
 
 
-static lzma_index *
-create_big(void)
+static void
+test_lzma_index_stream_flags(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-
-	lzma_vli total_size = 0;
-	lzma_vli uncompressed_size = 0;
-
-	// Add pseudo-random sizes (but always the same size values).
-	uint32_t n = 11;
-	for (size_t j = 0; j < BIG_COUNT; ++j) {
-		n = 7019 * n + 7607;
-		const uint32_t t = n * 3011;
-		expect(lzma_index_append(i, NULL, t, n) == LZMA_OK);
-		total_size += (t + 3) & ~LZMA_VLI_C(3);
-		uncompressed_size += n;
-	}
+	// Only trivial tests done here testing for basic functionality.
+	// More in-depth testing for this function will be done in
+	// test_lzma_index_checks
+
+	// Testing for NULL inputs
+	assert_lzma_ret(lzma_index_stream_flags(NULL, NULL),
+			LZMA_PROG_ERROR);
+
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
 
-	expect(lzma_index_block_count(i) == BIG_COUNT);
-	expect(lzma_index_total_size(i) == total_size);
-	expect(lzma_index_uncompressed_size(i) == uncompressed_size);
-	expect(lzma_index_total_size(i) + lzma_index_size(i)
-				+ 2 * LZMA_STREAM_HEADER_SIZE
-			== lzma_index_stream_size(i));
+	assert_lzma_ret(lzma_index_stream_flags(index, NULL),
+			LZMA_PROG_ERROR);
 
-	return i;
+	lzma_stream_flags stream_flags = {
+		.backward_size = LZMA_BACKWARD_SIZE_MIN,
+		.check = LZMA_CHECK_CRC32
+	};
+
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+
+	lzma_index_end(index, NULL);
 }
 
 
-static bool
-is_equal(const lzma_index *a, const lzma_index *b)
+static void
+test_lzma_index_checks(void)
 {
-	// Compare only the Stream and Block sizes and offsets.
-	lzma_index_iter ra, rb;
-	lzma_index_iter_init(&ra, a);
-	lzma_index_iter_init(&rb, b);
+	// Tests should still pass, even if some of the checks
+	// are disabled.
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
 
-	while (true) {
-		bool reta = lzma_index_iter_next(&ra, LZMA_INDEX_ITER_ANY);
-		bool retb = lzma_index_iter_next(&rb, LZMA_INDEX_ITER_ANY);
-		if (reta)
-			return !(reta ^ retb);
+	lzma_stream_flags stream_flags = {
+		.backward_size = LZMA_BACKWARD_SIZE_MIN,
+		.check = LZMA_CHECK_NONE
+	};
 
-		if (ra.stream.number != rb.stream.number
-				|| ra.stream.block_count
-					!= rb.stream.block_count
-				|| ra.stream.compressed_offset
-					!= rb.stream.compressed_offset
-				|| ra.stream.uncompressed_offset
-					!= rb.stream.uncompressed_offset
-				|| ra.stream.compressed_size
-					!= rb.stream.compressed_size
-				|| ra.stream.uncompressed_size
-					!= rb.stream.uncompressed_size
-				|| ra.stream.padding
-					!= rb.stream.padding)
-			return false;
+	// First set the check to be none
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_NONE);
+
+	// Set flags to be crc32 and repeat
+	stream_flags.check = LZMA_CHECK_CRC32;
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_CRC32);
+
+	// Set flags to be crc64 and repeat
+	stream_flags.check = LZMA_CHECK_CRC64;
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_CRC64);
+
+	// Set flags to be SHA256 and repeat
+	stream_flags.check = LZMA_CHECK_SHA256;
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_SHA256);
+
+	// Create second index and cat to first
+	lzma_index *second = lzma_index_init(NULL);
+	assert_true(second != NULL);
+
+	// Set the check to CRC32 for the second index
+	stream_flags.check = LZMA_CHECK_CRC32;
+	assert_lzma_ret(lzma_index_stream_flags(second, &stream_flags),
+			LZMA_OK);
+
+	assert_uint_eq(lzma_index_checks(second),
+			LZMA_INDEX_CHECK_MASK_CRC32);
+
+	assert_lzma_ret(lzma_index_cat(index, second, NULL), LZMA_OK);
+
+	// Index should now have both CRC32 and SHA256
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_CRC32 |
+			LZMA_INDEX_CHECK_MASK_SHA256);
+
+	// Change stream flags of second stream to be SHA256
+	stream_flags.check = LZMA_CHECK_SHA256;
+	assert_lzma_ret(lzma_index_stream_flags(index, &stream_flags),
+			LZMA_OK);
+
+	// Index should now have only SHA256
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_SHA256);
+
+	// Test with a third stream
+	lzma_index *third = lzma_index_init(NULL);
+	assert_true(third != NULL);
+
+	stream_flags.check = LZMA_CHECK_CRC64;
+	assert_lzma_ret(lzma_index_stream_flags(third, &stream_flags),
+			LZMA_OK);
+
+	assert_uint_eq(lzma_index_checks(third),
+			LZMA_INDEX_CHECK_MASK_CRC64);
+
+	assert_lzma_ret(lzma_index_cat(index, third, NULL), LZMA_OK);
+
+	// Index should now have CRC64 and SHA256
+	assert_uint_eq(lzma_index_checks(index),
+			LZMA_INDEX_CHECK_MASK_CRC64 |
+			LZMA_INDEX_CHECK_MASK_SHA256);
+
+	lzma_index_end(index, NULL);
+}
 
-		if (ra.stream.block_count == 0)
-			continue;
 
-		if (ra.block.number_in_file != rb.block.number_in_file
-				|| ra.block.compressed_file_offset
-					!= rb.block.compressed_file_offset
-				|| ra.block.uncompressed_file_offset
-					!= rb.block.uncompressed_file_offset
-				|| ra.block.number_in_stream
-					!= rb.block.number_in_stream
-				|| ra.block.compressed_stream_offset
-					!= rb.block.compressed_stream_offset
-				|| ra.block.uncompressed_stream_offset
-					!= rb.block.uncompressed_stream_offset
-				|| ra.block.uncompressed_size
-					!= rb.block.uncompressed_size
-				|| ra.block.unpadded_size
-					!= rb.block.unpadded_size
-				|| ra.block.total_size
-					!= rb.block.total_size)
-			return false;
-	}
+static void
+test_lzma_index_stream_padding(void)
+{
+	// Test NULL index
+	assert_lzma_ret(lzma_index_stream_padding(NULL, 0),
+			LZMA_PROG_ERROR);
+
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Test stream padding not a multiple of 4
+	assert_lzma_ret(lzma_index_stream_padding(index, 3),
+			LZMA_PROG_ERROR);
+
+	// Test stream padding too large
+	assert_lzma_ret(lzma_index_stream_padding(index, LZMA_VLI_MAX + 1),
+			LZMA_PROG_ERROR);
+
+	// Test stream padding valid
+	assert_lzma_ret(lzma_index_stream_padding(index, 0x1000),
+			LZMA_OK);
+	assert_lzma_ret(lzma_index_stream_padding(index, 4),
+			LZMA_OK);
+	assert_lzma_ret(lzma_index_stream_padding(index, 0),
+			LZMA_OK);
+
+	// Test stream padding causing the file size to grow too large
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			LZMA_VLI_MAX - 0x1000, 1), LZMA_OK);
+	assert_lzma_ret(lzma_index_stream_padding(index, 0x1000),
+			LZMA_DATA_ERROR);
+
+	lzma_index_end(index, NULL);
 }
 
 
 static void
-test_equal(void)
+test_lzma_index_stream_count(void)
 {
-	lzma_index *a = create_empty();
-	lzma_index *b = create_small();
-	lzma_index *c = create_big();
-	expect(a && b && c);
-
-	expect(is_equal(a, a));
-	expect(is_equal(b, b));
-	expect(is_equal(c, c));
-
-	expect(!is_equal(a, b));
-	expect(!is_equal(a, c));
-	expect(!is_equal(b, c));
-
-	lzma_index_end(a, NULL);
-	lzma_index_end(b, NULL);
-	lzma_index_end(c, NULL);
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	assert_uint_eq(lzma_index_stream_count(index), 1);
+
+	// Appending blocks should not change the stream count value
+	assert_lzma_ret(lzma_index_append(index, NULL, UNPADDED_SIZE_MIN,
+			1), LZMA_OK);
+
+	assert_uint_eq(lzma_index_stream_count(index), 1);
+
+	// Test with multiple streams
+	for (int i = 0; i < 100; i++) {
+		lzma_index *idx = lzma_index_init(NULL);
+		assert_true(idx != NULL);
+		assert_lzma_ret(lzma_index_cat(index, idx, NULL), LZMA_OK);
+		assert_uint_eq(lzma_index_stream_count(index), i + 2);",432,"3e2f0572826a4d7a76fead34939bab161e71ca0e","98c2958c137de306b3d8f3ed31a2a7f57a3497a2",0,0,"","","","none"
"2023-01-11 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-01-11 14:11:55","2023-01-11 14:11:55","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [X] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
The current test_index.c is using the old test format and is largely incomplete.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
- Creates helpful mask macros for return values from lzma_index_checks()
- Refactors test_index.c to use tuktest and cover more API functions
- Allow test_index.c to function properly if encoders or decoders are not built

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-01-11 13:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-01-11 13:21:25","2023-01-11 13:21:25","created",1066985528,"Language and typos","tests/test_index.c",90,84,"","none","Larhzu",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,564 +16,1028 @@
 
 #include ""tests.h""
 
+// liblzma internal header file needed for:
+// UNPADDED_SIZE_MIN
+// UNPADDED_SIZE_MAX
+// vli_ceil4
+#include ""common/index.h""
+
+
 #define MEMLIMIT (LZMA_VLI_C(1) << 20)
 
-#define SMALL_COUNT 3
-#define BIG_COUNT 5555
+static uint8_t *decode_buffer;
+static size_t decode_buffer_size = 0;
+static lzma_index *decode_test_index;
+
+
+static void
+test_lzma_index_memusage(void)
+{
+	// The return value from lzma_index_memusage is an approximation
+	// of the amount of memory needed to hold the index meta data for
+	// a given amount of streams and blocks. It will be an upperbound,
+	// so this test will mostly sanity check and error check the
+	// function
+
+	// The maximum number of streams should be UINT32_MAX
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX + 1, 1), UINT64_MAX);
+
+	// The maximum number of blocks should be LZMA_VLI_MAX
+	assert_uint_eq(lzma_index_memusage(1, LZMA_VLI_MAX), UINT64_MAX);
+
+	// Number of streams must be non zero
+	assert_uint_eq(lzma_index_memusage(0, 1), UINT64_MAX);
+
+	// Number of blocks CAN be zero
+	assert_uint(lzma_index_memusage(1, 0), !=, UINT64_MAX);
+
+	// Arbitrary values for stream and block should work without error
+	// and should always increase
+	uint64_t previous = 1;
+	lzma_vli streams = 1;
+	lzma_vli blocks = 1;
+	// Test 100 different increasing values for streams and block
+	for (int i = 0; i < 100; i++) {
+		uint64_t current = lzma_index_memusage(streams, blocks);
+		assert_uint(current, >, previous);
+		previous = current;
+		streams += 29;
+		blocks += 107;
+	}
+
+	// Force integer overflow in calculation (should result in error)
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX, LZMA_VLI_MAX),
+			UINT64_MAX);
+}
 
 
-static lzma_index *
-create_empty(void)
+static void
+test_lzma_index_memused(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-	return i;
+	// Very similar to test_lzma_index_memusage above since
+	// lzma_index_memused is essentially a wrapper for
+	// lzma_index_memusage
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Should pass since an empty index since initizlization creates
+	// 1 stream",90,"3e2f0572826a4d7a76fead34939bab161e71ca0e","98c2958c137de306b3d8f3ed31a2a7f57a3497a2",0,0,"","","","none"
"2023-01-11 13:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2023-01-11 13:35:33","2023-01-11 13:35:33","created",1066999641,"While the only valid value for .version is currently 0 and implicit initalization sets it to 0, it's good to explicitly set .version = 0.

The functions in index.c don't care about .backward_size but it is fine to set it here still.","tests/test_index.c",215,177,"","none","Larhzu",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -12,564 +16,1028 @@
 
 #include ""tests.h""
 
+// liblzma internal header file needed for:
+// UNPADDED_SIZE_MIN
+// UNPADDED_SIZE_MAX
+// vli_ceil4
+#include ""common/index.h""
+
+
 #define MEMLIMIT (LZMA_VLI_C(1) << 20)
 
-#define SMALL_COUNT 3
-#define BIG_COUNT 5555
+static uint8_t *decode_buffer;
+static size_t decode_buffer_size = 0;
+static lzma_index *decode_test_index;
+
+
+static void
+test_lzma_index_memusage(void)
+{
+	// The return value from lzma_index_memusage is an approximation
+	// of the amount of memory needed to hold the index meta data for
+	// a given amount of streams and blocks. It will be an upperbound,
+	// so this test will mostly sanity check and error check the
+	// function
+
+	// The maximum number of streams should be UINT32_MAX
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX + 1, 1), UINT64_MAX);
+
+	// The maximum number of blocks should be LZMA_VLI_MAX
+	assert_uint_eq(lzma_index_memusage(1, LZMA_VLI_MAX), UINT64_MAX);
+
+	// Number of streams must be non zero
+	assert_uint_eq(lzma_index_memusage(0, 1), UINT64_MAX);
+
+	// Number of blocks CAN be zero
+	assert_uint(lzma_index_memusage(1, 0), !=, UINT64_MAX);
+
+	// Arbitrary values for stream and block should work without error
+	// and should always increase
+	uint64_t previous = 1;
+	lzma_vli streams = 1;
+	lzma_vli blocks = 1;
+	// Test 100 different increasing values for streams and block
+	for (int i = 0; i < 100; i++) {
+		uint64_t current = lzma_index_memusage(streams, blocks);
+		assert_uint(current, >, previous);
+		previous = current;
+		streams += 29;
+		blocks += 107;
+	}
+
+	// Force integer overflow in calculation (should result in error)
+	assert_uint_eq(lzma_index_memusage(UINT32_MAX, LZMA_VLI_MAX),
+			UINT64_MAX);
+}
 
 
-static lzma_index *
-create_empty(void)
+static void
+test_lzma_index_memused(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-	return i;
+	// Very similar to test_lzma_index_memusage above since
+	// lzma_index_memused is essentially a wrapper for
+	// lzma_index_memusage
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Should pass since an empty index since initizlization creates
+	// 1 stream
+	assert_uint(lzma_index_memused(index), <, UINT64_MAX);
+
+	// Append small blocks and then test again (should pass)
+	for (int i = 0; i < 10; i++)
+		assert_lzma_ret(lzma_index_append(index, NULL,
+				UNPADDED_SIZE_MIN, 1), LZMA_OK);
+
+	assert_uint(lzma_index_memused(index), <, UINT64_MAX);
+
+	lzma_index_end(index, NULL);
 }
 
 
-static lzma_index *
-create_small(void)
+static void
+test_lzma_index_append(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-	expect(lzma_index_append(i, NULL, 101, 555) == LZMA_OK);
-	expect(lzma_index_append(i, NULL, 602, 777) == LZMA_OK);
-	expect(lzma_index_append(i, NULL, 804, 999) == LZMA_OK);
-	return i;
+	// Basic input-ouput test done here.
+	// Less trivial tests for this function are done throughout
+	// other tests.
+
+	// First test with NULL index
+	assert_lzma_ret(lzma_index_append(NULL, NULL, UNPADDED_SIZE_MIN,
+			1), LZMA_PROG_ERROR);
+
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
+
+	// Test with invalid unpadded size
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN - 1, 1), LZMA_PROG_ERROR);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MAX + 1, 1), LZMA_PROG_ERROR);
+
+	// Test with invalid uncompressed size
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MAX, LZMA_VLI_MAX + 1),
+			LZMA_PROG_ERROR);
+
+	// Test expected successful block appends
+	assert_lzma_ret(lzma_index_append(index, NULL, UNPADDED_SIZE_MIN,
+			1), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN * 2,
+			2), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN * 3,
+			3), LZMA_OK);
+
+	lzma_index_end(index, NULL);
+
+	// Test uncompressed size growing too large.
+	// Should result in LZMA_DATA_ERROR
+	index = lzma_index_init(NULL);
+
+	assert_lzma_ret(lzma_index_append(index, NULL, UNPADDED_SIZE_MAX,
+			1), LZMA_DATA_ERROR);
+
+	// Test compressed size growing too large.
+	// Should result in LZMA_DATA_ERROR
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN, LZMA_VLI_MAX), LZMA_OK);
+	assert_lzma_ret(lzma_index_append(index, NULL,
+			UNPADDED_SIZE_MIN, 1), LZMA_DATA_ERROR);
+
+	// Currently not testing for error case when the size of the index
+	// grows too large to be stored. This was not practical to test for
+	// since too many blocks needed to be created to cause this.
+
+	lzma_index_end(index, NULL);
 }
 
 
-static lzma_index *
-create_big(void)
+static void
+test_lzma_index_stream_flags(void)
 {
-	lzma_index *i = lzma_index_init(NULL);
-	expect(i != NULL);
-
-	lzma_vli total_size = 0;
-	lzma_vli uncompressed_size = 0;
-
-	// Add pseudo-random sizes (but always the same size values).
-	uint32_t n = 11;
-	for (size_t j = 0; j < BIG_COUNT; ++j) {
-		n = 7019 * n + 7607;
-		const uint32_t t = n * 3011;
-		expect(lzma_index_append(i, NULL, t, n) == LZMA_OK);
-		total_size += (t + 3) & ~LZMA_VLI_C(3);
-		uncompressed_size += n;
-	}
+	// Only trivial tests done here testing for basic functionality.
+	// More in-depth testing for this function will be done in
+	// test_lzma_index_checks
+
+	// Testing for NULL inputs
+	assert_lzma_ret(lzma_index_stream_flags(NULL, NULL),
+			LZMA_PROG_ERROR);
+
+	lzma_index *index = lzma_index_init(NULL);
+	assert_true(index != NULL);
 
-	expect(lzma_index_block_count(i) == BIG_COUNT);
-	expect(lzma_index_total_size(i) == total_size);
-	expect(lzma_index_uncompressed_size(i) == uncompressed_size);
-	expect(lzma_index_total_size(i) + lzma_index_size(i)
-				+ 2 * LZMA_STREAM_HEADER_SIZE
-			== lzma_index_stream_size(i));
+	assert_lzma_ret(lzma_index_stream_flags(index, NULL),
+			LZMA_PROG_ERROR);
 
-	return i;
+	lzma_stream_flags stream_flags = {
+		.backward_size = LZMA_BACKWARD_SIZE_MIN,
+		.check = LZMA_CHECK_CRC32
+	};",215,"3e2f0572826a4d7a76fead34939bab161e71ca0e","98c2958c137de306b3d8f3ed31a2a7f57a3497a2",0,0,"","","","none"
"2023-01-11 13:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-01-11 13:21:26","2023-01-11 13:21:25","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [X] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
The current test_index.c is using the old test format and is largely incomplete.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
- Creates helpful mask macros for return values from lzma_index_checks()
- Refactors test_index.c to use tuktest and cover more API functions
- Allow test_index.c to function properly if encoders or decoders are not built

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-01-11 13:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-01-11 13:35:34","2023-01-11 13:35:33","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [X] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
The current test_index.c is using the old test format and is largely incomplete.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
- Creates helpful mask macros for return values from lzma_index_checks()
- Refactors test_index.c to use tuktest and cover more API functions
- Allow test_index.c to function properly if encoders or decoders are not built

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-01-11 13:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2023-01-11 13:57:32","2023-01-11 13:57:31","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [X] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [ ] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [X] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [ ] Other (please describe): 


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
The current test_index.c is using the old test format and is largely incomplete.

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: 


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
- Creates helpful mask macros for return values from lzma_index_checks()
- Refactors test_index.c to use tuktest and cover more API functions
- Allow test_index.c to function properly if encoders or decoders are not built

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",8,"Refactor tests in test_index.c","['5.4.1','test']","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","7424d82b3ad79bd444f4611aa673ecd9fb12439f","[]","[]","tuktest_index","3e2f0572826a4d7a76fead34939bab161e71ca0e","master","8d372bd94066b1a5b0570b2550f83c2868486adf",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2023-01-10 20:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 20:17:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-10 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 11:22:36","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-10 11:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 11:11:29","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-10 09:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 09:58:57","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-10 09:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 09:57:02","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-10 08:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 08:26:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-10 06:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 06:50:53","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-10 06:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-10 06:38:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-09 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-09 22:04:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-09 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-09 22:35:30","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-09 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-09 15:05:09","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",16,16,"","","","none"
"2023-01-09 10:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-09 10:23:17","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-07 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-07 22:32:44","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-07 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-07 22:25:45","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",6,6,"","","","none"
"2023-01-07 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-07 22:13:19","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_filter_flags","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",5,5,"","","","none"
"2023-01-06 22:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-06 22:11:33","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_filter_flags","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-01-06 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-06 15:59:01","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index_hash","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-06 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-06 15:55:34","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index_hash","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-01-06 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-06 15:44:41","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index_hash","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-06 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-06 15:38:32","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/tuktest_index_hash","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",3,3,"","","","none"
"2023-01-05 20:00:00","CreateEvent","Larhzu","tukaani-project/xz","2023-01-05 20:40:14","1970-01-01 00:00:00","none",0,"","",0,0,"filter_to_str2","branch","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","none"
"2023-01-04 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-04 21:19:16","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/v5.4","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2023-01-04 21:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-04 21:19:12","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2023-01-02 15:00:00","PushEvent","Larhzu","tukaani-project/xz","2023-01-02 15:45:11","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2022-12-30 18:00:00","PushEvent","Larhzu","tukaani-project/xz","2022-12-30 18:16:36","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",2,2,"","","","none"
"2022-12-16 16:00:00","PushEvent","Larhzu","tukaani-project/xz","2022-12-16 16:31:50","1970-01-01 00:00:00","none",0,"","",0,0,"refs/heads/master","none","",0,"","[]","none",0,"","[]",0,"NONE","1970-01-01 00:00:00","1970-01-01 00:00:00","","[]","[]","","","","",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",1,1,"","","","none"
"2022-12-16 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-16 14:23:25","2022-12-16 14:23:25","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","2d680ab6fdaec2b379e153ea18ca8137a1ee1210","[]","[]","tuktest_lzip_decoder","141ba5bb05d67565280c67a7b4b60a8b05ab4c48","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 16:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 16:45:33","2022-12-15 16:45:34","created",1049893100,"I don't disagree, it's just that I feel it's not that important for these specific tests to be extremely paranoid. Using lzma_crc32() here after decompression to check the uncompressed data might work too? I mostly would like to avoid the need to have the full uncompressed file content in the C code but since that is fairly short I suppose it's OK too, it just has to be in hex so that it survives conversion to EBCDIC. So if you prefer that it's OK.","tests/test_lzip_decoder.c",0,0,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",",78,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 16:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 16:45:34","2022-12-15 16:45:34","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 15:17:53","2022-12-15 15:17:54","created",1049768778,"Content checking is done by test_files.sh thanks to CRC32, that part is good enough. The return value isn't checked by test_files.sh, that is true. I'm not sure how important it is but it's true it's not much code to check it here to be sure.","tests/test_lzip_decoder.c",0,0,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",",78,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 15:19:03","2022-12-15 15:19:04","created",1049770205,"That's exactly what I tried to say.","tests/test_lzip_decoder.c",394,394,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+static void
+test_v1_decode(void) {
+	// This tests decoding a basic lzip v1 file
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+// Helper function to decode a good file with trailing bytes after
+// the lzip stream
+static void
+trailing_helper(const char* src, const uint8_t *expected_result,
+		size_t expected_size, const uint8_t *expected_trailing,
+		size_t expected_trailing_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_in = file_size;
+	strm.avail_out = expected_size;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+	assert_uint(strm.total_in, <, file_size);
+	assert_uint_eq(strm.total_out, expected_size);
+	assert_array_eq(output_buffer, expected_result,
+			strm.total_out);
+
+	// Trailing data should be readable from strm.next_in
+	assert_uint_eq(strm.avail_in, expected_trailing_size);
+	assert_array_eq(strm.next_in, expected_trailing, strm.avail_in);
+	lzma_end(&strm);
+}
+
+
+// Helper function to decode a bad file and compare to returned error to
+// what the caller expects
+static void
+decode_expect_error(const char* src, lzma_ret expected_error)
+{
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	lzma_ret ret = LZMA_OK;
+
+	while (ret == LZMA_OK) {
+		// Discard output since we are only looking for errors
+		strm.next_out = output_buffer;
+		strm.avail_out = DECODE_CHUNK_SIZE;
+		if (strm.avail_in == 0)
+			ret = lzma_code(&strm, LZMA_FINISH);
+		else
+			ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, expected_error);
+	lzma_end(&strm);
+}
+
+
+static void
+test_v0_trailing(void) {
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	const char expected_trailing_data[] = ""Trailing garbage\n"";
+	trailing_helper(""files/good-1-v0-trailing-1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+}
+
+
+static void
+test_v1_trailing(void) {
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	const char expected_trailing_data[] = ""Trailing garbage\n"";
+	trailing_helper(""files/good-1-v1-trailing-1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+
+	// The second files/good-1-v1-trailing-2.lz will have the same
+	// expected output and trailing output as
+	// files/good-1-v1-trailing-1.lz, but this tests if the prefix
+	// to the trailing data contains lzip magic bytes.
+	// When this happens, the expected behavior is to silently ignore
+	// the magic byte prefix and consume it from the input file.
+	trailing_helper(""files/good-1-v1-trailing-2.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+
+	// Expect LZMA_BUF error if a file ends with the lzip magic bytes
+	// but does not contain any data after
+	decode_expect_error(""files/bad-1-v1-trailing-magic.lz"",
+			LZMA_BUF_ERROR);
+}
+
+
+static void
+test_concatentated(void)
+{
+	// First test a file with one v0 member and one v1 member
+	// The first member should contain ""Hello\n"" and
+	// the second member should contain ""World!\n""
+	const char expected_result[] = ""Hello\nWorld!\n"";
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *v0_v1 = tuktest_file_from_srcdir(""files/good-2-v0-v1.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+	strm.avail_in = file_size;
+	strm.next_in = v0_v1;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// The second file contains one v1 member and one v2 member
+	uint8_t *v1_v0 = tuktest_file_from_srcdir(""files/good-2-v1-v0.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = v1_v0;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// The third file contains 2 v1 members
+	uint8_t *v1_v1 = tuktest_file_from_srcdir(""files/good-2-v1-v1.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = v1_v1;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	lzma_end(&strm);
+}
+
+
+static void
+test_crc(void) {
+	// Test invalid checksum
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(""files/bad-1-v1-crc32.lz"",
+			&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	uint8_t output_buffer[sizeof(expected_result) - 1];
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_DATA_ERROR);
+
+	// Test ignoring the checksum value - should decode successfully
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED | LZMA_IGNORE_CHECK), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// Test tell check
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED | LZMA_TELL_ANY_CHECK), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_GET_CHECK);
+	assert_uint_eq(lzma_get_check(&strm), LZMA_CHECK_CRC32);
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_DATA_ERROR);
+	lzma_end(&strm);
+}
+
+
+static void
+test_invalid_magic_bytes(void) {
+	uint8_t lzip_id_string[] = { 0x4C, 0x5A, 0x49, 0x50 };
+	lzma_stream strm = LZMA_STREAM_INIT;
+
+	for (uint32_t i = 0; i < ARRAY_SIZE(lzip_id_string); i++) {
+		// Corrupt magic bytes
+		lzip_id_string[i] ^= 1;
+		uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+		assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0),
+				LZMA_OK);
+
+		strm.next_in = lzip_id_string;
+		strm.avail_in = sizeof(lzip_id_string);
+		strm.next_out = output_buffer;
+		strm.avail_out = DECODE_CHUNK_SIZE;
+
+		assert_lzma_ret(lzma_code(&strm, LZMA_RUN),
+				LZMA_FORMAT_ERROR);
+
+		// Reset magic bytes
+		lzip_id_string[i] ^= 1;
+	}
+
+	lzma_end(&strm);
+}
+
+
+static void
+test_invalid_version(void)
+{
+	// The file contains a version number that is not 0 or 1,
+	// so it should cause an error
+	decode_expect_error(""files/unsupported-1-v234.lz"",
+			LZMA_OPTIONS_ERROR);
+}
+
+
+static void
+test_invalid_dictionary_size(void) {
+	// First file has too small dictionary size field
+	decode_expect_error(""files/bad-1-v1-dict-1.lz"", LZMA_DATA_ERROR);
+	
+	// Second file has too large dictionary size field
+	decode_expect_error(""files/bad-1-v1-dict-2.lz"", LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_uncomp_size(void) {
+	// Test invalid v0 lzip file uncomp size
+	decode_expect_error(""files/bad-1-v0-uncomp-size.lz"",
+			LZMA_DATA_ERROR);
+	
+	// Test invalid v1 lzip file uncomp size
+	decode_expect_error(""files/bad-1-v1-uncomp-size.lz"",
+			LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_member_size(void) {
+	decode_expect_error(""files/bad-1-v1-member-size.lz"",
+			LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_memlimit(void) {",393,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 15:23:21","2022-12-15 15:23:21","created",1049775373,"Putting ASCII chars as separate chars instead of as a string doesn't change anything. On EBCDIC systems the source files are mass-converted from ASCII to EBCDIC before compilation and thus the characters map to different byte values. I think it's enough to check for trailing garbage string and that can be done by comparing CRC32 value, that is, compare the length of the garbage and use lzma_crc32() and compare against known hardcoded value (no need for a #define for the hardcoded value). It's ugly but then it's portable and there's no need for a ASCII string in hex representation.","tests/test_lzip_decoder.c",29,29,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT (1U << 20)
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Avoiding using the ASCII string because of potential EBCDIC system
+// compatibility. The string is: ""Hello\nWorld!\n""
+static const char hello_world[] = {'H', 'e', 'l', 'l', 'o', '\n',
+			'W', 'o', 'r', 'l', 'd', '!', '\n', 0};
+// The string is ""Trailing garbage\n""
+static const char trailing_garbage[] = {'T', 'r', 'a', 'i', 'l', 'i',
+		'n', 'g', ' ', 'g', 'a', 'r', 'b', 'a', 'g', 'e', '\n', 0};
+",29,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","de69d098e860c456bf7fc2dfd1b8e03d9e94700f",0,0,"","","","none"
"2022-12-15 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 15:26:01","2022-12-15 15:26:02","created",1049778511,"I wonder if it's not useful to repeat the version numbers of the other tool here as things might change and they aren't relevant for liblzma testing. They are described in the tests/files/README in detail already.","tests/test_lzip_decoder.c",84,84,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT (1U << 20)
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Avoiding using the ASCII string because of potential EBCDIC system
+// compatibility. The string is: ""Hello\nWorld!\n""
+static const char hello_world[] = {'H', 'e', 'l', 'l', 'o', '\n',
+			'W', 'o', 'r', 'l', 'd', '!', '\n', 0};
+// The string is ""Trailing garbage\n""
+static const char trailing_garbage[] = {'T', 'r', 'a', 'i', 'l', 'i',
+		'n', 'g', ' ', 'g', 'a', 'r', 'b', 'a', 'g', 'e', '\n', 0};
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char *src, const uint8_t *expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decompress this, but lzip 1.18",84,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","de69d098e860c456bf7fc2dfd1b8e03d9e94700f",0,0,"","","","none"
"2022-12-15 15:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 15:26:35","2022-12-15 15:26:35","created",1049779143,"Style: No space after cast. (const char *)hello_world,","tests/test_lzip_decoder.c",87,87,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT (1U << 20)
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Avoiding using the ASCII string because of potential EBCDIC system
+// compatibility. The string is: ""Hello\nWorld!\n""
+static const char hello_world[] = {'H', 'e', 'l', 'l', 'o', '\n',
+			'W', 'o', 'r', 'l', 'd', '!', '\n', 0};
+// The string is ""Trailing garbage\n""
+static const char trailing_garbage[] = {'T', 'r', 'a', 'i', 'l', 'i',
+		'n', 'g', ' ', 'g', 'a', 'r', 'b', 'a', 'g', 'e', '\n', 0};
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char *src, const uint8_t *expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decompress this, but lzip 1.18
+	// and newer can no longer decode these files.
+	basic_lzip_decode(""files/good-1-v0.lz"",
+			(const uint8_t *) hello_world,",87,"de69d098e860c456bf7fc2dfd1b8e03d9e94700f","de69d098e860c456bf7fc2dfd1b8e03d9e94700f",0,0,"","","","none"
"2022-12-15 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 15:17:54","2022-12-15 15:17:54","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 15:19:04","2022-12-15 15:19:04","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 15:23:22","2022-12-15 15:23:21","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 15:26:02","2022-12-15 15:26:02","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 15:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 15:26:36","2022-12-15 15:26:35","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","5b9b1104932cc045edadebeb35ffbd61d2af8895","[]","[]","tuktest_lzip_decoder","de69d098e860c456bf7fc2dfd1b8e03d9e94700f","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:17:47","2022-12-15 14:17:47","created",1049694193,"Parenthesis are needed, unsigned value might be nicer but doesn't matter. #define MEMLIMIT (1U << 20)","tests/test_lzip_decoder.c",18,18,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20",18,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:22:04","2022-12-15 14:22:04","created",1049699887,"""decompress"" typo","tests/test_lzip_decoder.c",75,75,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18",75,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:24:00","2022-12-15 14:24:00","created",1049702013,"ASCII strings aren't portable to EBCDIC systems and thus cannot be used when looking for byte-exact results.","tests/test_lzip_decoder.c",77,77,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";",77,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:24:34","2022-12-15 14:24:34","created",1049702650,"The test files are tested by test_files.sh already. Replacing test_files.sh by something else is one question but duplicating the test here doesn't seem useful.","tests/test_lzip_decoder.c",78,78,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",",78,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:26:26","2022-12-15 14:26:26","created",1049704855,"This test is useful as it's not done by test_files.sh.","tests/test_lzip_decoder.c",119,119,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+static void
+test_v1_decode(void) {
+	// This tests decoding a basic lzip v1 file
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+// Helper function to decode a good file with trailing bytes after
+// the lzip stream
+static void
+trailing_helper(const char* src, const uint8_t *expected_result,
+		size_t expected_size, const uint8_t *expected_trailing,
+		size_t expected_trailing_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_in = file_size;
+	strm.avail_out = expected_size;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+	assert_uint(strm.total_in, <, file_size);
+	assert_uint_eq(strm.total_out, expected_size);
+	assert_array_eq(output_buffer, expected_result,
+			strm.total_out);
+
+	// Trailing data should be readable from strm.next_in",119,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewCommentEvent","Larhzu","tukaani-project/xz","2022-12-15 14:44:42","2022-12-15 14:44:42","created",1049728075,"Perhaps this test is useful but for portability it could be simplified so that it doesn't check the output content or even size, the CRC32 will catch some errors anyway. That is, just focus on the memlimit testing only.","tests/test_lzip_decoder.c",393,393,"","none","Larhzu",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"@@ -0,0 +1,454 @@
+///////////////////////////////////////////////////////////////////////////////
+//
+/// \file       test_lzip_decoder.c
+/// \brief      Tests decoding lzip data
+//
+//  Author:     Jia Tan
+//
+//  This file has been put into the public domain.
+//  You can do whatever you want with this file.
+//
+///////////////////////////////////////////////////////////////////////////////
+
+#include ""tests.h""
+
+#ifdef HAVE_LZIP_DECODER
+
+// Memlimit large enough to pass all of the test files
+#define MEMLIMIT 1 << 20
+#define DECODE_CHUNK_SIZE 1024
+
+
+// Helper function to decode a good file with no flags and plenty
+// high memlimit
+static void
+basic_lzip_decode(const char* src, const uint8_t* expected_result,
+		size_t expected_result_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_result_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_out = expected_result_size;
+
+	// Feed 1 byte at a time to the decoder to look for any bugs
+	// when switching between decoding sequences
+	lzma_ret ret = LZMA_OK;
+	while (ret == LZMA_OK) {
+		strm.avail_in = 1;
+		ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, expected_result_size);
+	assert_array_eq(output_buffer, expected_result,
+			expected_result_size);
+	lzma_end(&strm);
+}
+
+
+static void
+test_options(void)
+{
+	// Test NULL stream
+	assert_lzma_ret(lzma_lzip_decoder(NULL, MEMLIMIT, 0),
+			LZMA_PROG_ERROR);
+
+	// Test invalid flags
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, UINT32_MAX),
+			LZMA_OPTIONS_ERROR);
+	// Memlimit tests are done elsewhere
+}
+
+
+static void
+test_v0_decode(void) {
+	// This tests if liblzma can decode lzip version 0 files.
+	// lzip 1.17 and older can decomperss this, but lzip 1.18
+	// and newer can no longer decode these files.
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+static void
+test_v1_decode(void) {
+	// This tests decoding a basic lzip v1 file
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	basic_lzip_decode(""files/good-1-v1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1);
+}
+
+
+// Helper function to decode a good file with trailing bytes after
+// the lzip stream
+static void
+trailing_helper(const char* src, const uint8_t *expected_result,
+		size_t expected_size, const uint8_t *expected_trailing,
+		size_t expected_trailing_size) {
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+	lzma_stream strm = LZMA_STREAM_INIT;
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t *output_buffer = tuktest_malloc(expected_size);
+
+	strm.next_in = data;
+	strm.next_out = output_buffer;
+	strm.avail_in = file_size;
+	strm.avail_out = expected_size;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+	assert_uint(strm.total_in, <, file_size);
+	assert_uint_eq(strm.total_out, expected_size);
+	assert_array_eq(output_buffer, expected_result,
+			strm.total_out);
+
+	// Trailing data should be readable from strm.next_in
+	assert_uint_eq(strm.avail_in, expected_trailing_size);
+	assert_array_eq(strm.next_in, expected_trailing, strm.avail_in);
+	lzma_end(&strm);
+}
+
+
+// Helper function to decode a bad file and compare to returned error to
+// what the caller expects
+static void
+decode_expect_error(const char* src, lzma_ret expected_error)
+{
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(src, &file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	lzma_ret ret = LZMA_OK;
+
+	while (ret == LZMA_OK) {
+		// Discard output since we are only looking for errors
+		strm.next_out = output_buffer;
+		strm.avail_out = DECODE_CHUNK_SIZE;
+		if (strm.avail_in == 0)
+			ret = lzma_code(&strm, LZMA_FINISH);
+		else
+			ret = lzma_code(&strm, LZMA_RUN);
+	}
+
+	assert_lzma_ret(ret, expected_error);
+	lzma_end(&strm);
+}
+
+
+static void
+test_v0_trailing(void) {
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	const char expected_trailing_data[] = ""Trailing garbage\n"";
+	trailing_helper(""files/good-1-v0-trailing-1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+}
+
+
+static void
+test_v1_trailing(void) {
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	const char expected_trailing_data[] = ""Trailing garbage\n"";
+	trailing_helper(""files/good-1-v1-trailing-1.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+
+	// The second files/good-1-v1-trailing-2.lz will have the same
+	// expected output and trailing output as
+	// files/good-1-v1-trailing-1.lz, but this tests if the prefix
+	// to the trailing data contains lzip magic bytes.
+	// When this happens, the expected behavior is to silently ignore
+	// the magic byte prefix and consume it from the input file.
+	trailing_helper(""files/good-1-v1-trailing-2.lz"",
+			(const uint8_t *) expected_result,
+			sizeof(expected_result) - 1,
+			(const uint8_t *) expected_trailing_data,
+			sizeof(expected_trailing_data) - 1);
+
+	// Expect LZMA_BUF error if a file ends with the lzip magic bytes
+	// but does not contain any data after
+	decode_expect_error(""files/bad-1-v1-trailing-magic.lz"",
+			LZMA_BUF_ERROR);
+}
+
+
+static void
+test_concatentated(void)
+{
+	// First test a file with one v0 member and one v1 member
+	// The first member should contain ""Hello\n"" and
+	// the second member should contain ""World!\n""
+	const char expected_result[] = ""Hello\nWorld!\n"";
+
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *v0_v1 = tuktest_file_from_srcdir(""files/good-2-v0-v1.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+	strm.avail_in = file_size;
+	strm.next_in = v0_v1;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// The second file contains one v1 member and one v2 member
+	uint8_t *v1_v0 = tuktest_file_from_srcdir(""files/good-2-v1-v0.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = v1_v0;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// The third file contains 2 v1 members
+	uint8_t *v1_v1 = tuktest_file_from_srcdir(""files/good-2-v1-v1.lz"",
+		&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = v1_v1;
+	strm.avail_out = DECODE_CHUNK_SIZE;
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	lzma_end(&strm);
+}
+
+
+static void
+test_crc(void) {
+	// Test invalid checksum
+	lzma_stream strm = LZMA_STREAM_INIT;
+	size_t file_size;
+	uint8_t *data = tuktest_file_from_srcdir(""files/bad-1-v1-crc32.lz"",
+			&file_size);
+
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED), LZMA_OK);
+
+	const char expected_result[] = ""Hello\nWorld!\n"";
+	uint8_t output_buffer[sizeof(expected_result) - 1];
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_DATA_ERROR);
+
+	// Test ignoring the checksum value - should decode successfully
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED | LZMA_IGNORE_CHECK), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_STREAM_END);
+
+	assert_uint_eq(strm.total_in, file_size);
+	assert_uint_eq(strm.total_out, sizeof(expected_result) - 1);
+	assert_array_eq(output_buffer, expected_result, strm.total_out);
+
+	// Test tell check
+	assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT,
+			LZMA_CONCATENATED | LZMA_TELL_ANY_CHECK), LZMA_OK);
+
+	strm.avail_in = file_size;
+	strm.next_in = data;
+	strm.avail_out = sizeof(output_buffer);
+	strm.next_out = output_buffer;
+
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_GET_CHECK);
+	assert_uint_eq(lzma_get_check(&strm), LZMA_CHECK_CRC32);
+	assert_lzma_ret(lzma_code(&strm, LZMA_FINISH), LZMA_DATA_ERROR);
+	lzma_end(&strm);
+}
+
+
+static void
+test_invalid_magic_bytes(void) {
+	uint8_t lzip_id_string[] = { 0x4C, 0x5A, 0x49, 0x50 };
+	lzma_stream strm = LZMA_STREAM_INIT;
+
+	for (uint32_t i = 0; i < ARRAY_SIZE(lzip_id_string); i++) {
+		// Corrupt magic bytes
+		lzip_id_string[i] ^= 1;
+		uint8_t output_buffer[DECODE_CHUNK_SIZE];
+
+		assert_lzma_ret(lzma_lzip_decoder(&strm, MEMLIMIT, 0),
+				LZMA_OK);
+
+		strm.next_in = lzip_id_string;
+		strm.avail_in = sizeof(lzip_id_string);
+		strm.next_out = output_buffer;
+		strm.avail_out = DECODE_CHUNK_SIZE;
+
+		assert_lzma_ret(lzma_code(&strm, LZMA_RUN),
+				LZMA_FORMAT_ERROR);
+
+		// Reset magic bytes
+		lzip_id_string[i] ^= 1;
+	}
+
+	lzma_end(&strm);
+}
+
+
+static void
+test_invalid_version(void)
+{
+	// The file contains a version number that is not 0 or 1,
+	// so it should cause an error
+	decode_expect_error(""files/unsupported-1-v234.lz"",
+			LZMA_OPTIONS_ERROR);
+}
+
+
+static void
+test_invalid_dictionary_size(void) {
+	// First file has too small dictionary size field
+	decode_expect_error(""files/bad-1-v1-dict-1.lz"", LZMA_DATA_ERROR);
+	
+	// Second file has too large dictionary size field
+	decode_expect_error(""files/bad-1-v1-dict-2.lz"", LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_uncomp_size(void) {
+	// Test invalid v0 lzip file uncomp size
+	decode_expect_error(""files/bad-1-v0-uncomp-size.lz"",
+			LZMA_DATA_ERROR);
+	
+	// Test invalid v1 lzip file uncomp size
+	decode_expect_error(""files/bad-1-v1-uncomp-size.lz"",
+			LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_member_size(void) {
+	decode_expect_error(""files/bad-1-v1-member-size.lz"",
+			LZMA_DATA_ERROR);
+}
+
+
+static void
+test_invalid_memlimit(void) {",393,"6d96d4584f165b191e4d70618e18a2910c5be423","6d96d4584f165b191e4d70618e18a2910c5be423",0,0,"","","","none"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:17:48","2022-12-15 14:17:47","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:18:22","2022-12-15 14:18:22","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:24:01","2022-12-15 14:24:00","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:24:35","2022-12-15 14:24:34","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:26:26","2022-12-15 14:26:26","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
"2022-12-15 14:00:00","PullRequestReviewEvent","Larhzu","tukaani-project/xz","2022-12-15 14:44:42","2022-12-15 14:44:42","created",0,"## Pull request checklist

Please check if your PR fulfills the following requirements:
- [x] Tests for the changes have been added (for bug fixes / features)
- [X] Docs have been reviewed and added / updated if needed (for bug fixes / features)
- [X] Build was run locally and without warnings or errors
- [X] All previous and new tests pass


## Pull request type

<!-- Please try to limit your pull request to one type, submit multiple
pull requests if needed. --> 

Please check the type of change your PR introduces:
- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, renaming, typo fix)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] Documentation content changes
- [X] Other (please describe): Test for recently added feature


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying. -->
This PR does not alter behavior

<!-- Related issue this PR addresses, if applicable -->
Related Issue URL: N/A


## What is the new behavior?
<!-- Please describe the behavior or changes that are being added by this
PR. -->
N/A

## Does this introduce a breaking change?

- [ ] Yes
- [X] No

<!-- If this introduces a breaking change, please describe the impact and
migration path for existing applications below. -->


## Other information

<!-- Any other information that is important to this PR. -->","",0,0,"","none","JiaT75",1,"Tests: Adds lzip decoder tests","[]","open",0,"","[]",0,"MEMBER","1970-01-01 00:00:00","1970-01-01 00:00:00","3f2ef947ff54eeeee8ea8c78cd61d2e14a2540c8","[]","[]","tuktest_lzip_decoder","6d96d4584f165b191e4d70618e18a2910c5be423","master","b69da6d4bb6bb11fc0cf066920791990d2b22a06",0,0,0,"unknown","",0,0,0,0,0,0,"",0,"","",0,0,"","","","commented"
